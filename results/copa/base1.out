Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
12/07/2022 13:24:36 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
12/07/2022 13:24:36 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=None,
evaluation_strategy=IntervalStrategy.EPOCH,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.009,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=checkpoints/copa-roberta/runs/Dec07_13-24-36_p0304.ten.osc.edu,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=120.0,
output_dir=checkpoints/copa-roberta/,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=checkpoints/copa-roberta/,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.NO,
save_total_limit=None,
seed=11,
sharded_ddp=[],
skip_memory_metrics=True,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
[INFO|tokenization_auto.py:334] 2022-12-07 13:24:37,018 >> Could not locate the tokenizer configuration file, will try to use the model config instead.
[INFO|configuration_utils.py:583] 2022-12-07 13:24:37,133 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /users/PAS2318/evanhuang117/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
[INFO|configuration_utils.py:620] 2022-12-07 13:24:37,134 >> Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|tokenization_utils_base.py:1741] 2022-12-07 13:24:38,016 >> loading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /users/PAS2318/evanhuang117/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab
[INFO|tokenization_utils_base.py:1741] 2022-12-07 13:24:38,016 >> loading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /users/PAS2318/evanhuang117/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b
[INFO|tokenization_utils_base.py:1741] 2022-12-07 13:24:38,017 >> loading file https://huggingface.co/roberta-large/resolve/main/tokenizer.json from cache at /users/PAS2318/evanhuang117/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730
[INFO|tokenization_utils_base.py:1741] 2022-12-07 13:24:38,017 >> loading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:1741] 2022-12-07 13:24:38,017 >> loading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:1741] 2022-12-07 13:24:38,017 >> loading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None
[INFO|configuration_utils.py:583] 2022-12-07 13:24:38,147 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /users/PAS2318/evanhuang117/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
[INFO|configuration_utils.py:620] 2022-12-07 13:24:38,149 >> Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

12/07/2022 13:24:39 - INFO - datasets.info - Loading Dataset Infos from /users/PAS2318/evanhuang117/.cache/huggingface/modules/datasets_modules/datasets/super_glue/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7
12/07/2022 13:24:39 - INFO - datasets.builder - Overwrite dataset info from restored data version.
12/07/2022 13:24:39 - INFO - datasets.info - Loading Dataset info from /users/PAS2318/evanhuang117/.cache/huggingface/datasets/super_glue/copa/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7
12/07/2022 13:24:39 - WARNING - datasets.builder - Reusing dataset super_glue (/users/PAS2318/evanhuang117/.cache/huggingface/datasets/super_glue/copa/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7)
12/07/2022 13:24:39 - INFO - datasets.info - Loading Dataset info from /users/PAS2318/evanhuang117/.cache/huggingface/datasets/super_glue/copa/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 33.08it/s]12/07/2022 13:24:39 - WARNING - datasets.fingerprint - Parameter 'function'=<function SuperGlueDataset.preprocess_function at 0x2b8c9a1043a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
12/07/2022 13:24:39 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /users/PAS2318/evanhuang117/.cache/huggingface/datasets/super_glue/copa/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-dda1494c73cf256d.arrow
12/07/2022 13:24:39 - INFO - datasets.fingerprint - Parameter 'function'=<function SuperGlueDataset.preprocess_function at 0x2b8c9a104430> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.
12/07/2022 13:24:39 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /users/PAS2318/evanhuang117/.cache/huggingface/datasets/super_glue/copa/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-db5b5fab8f4d3e27.arrow
12/07/2022 13:24:39 - INFO - datasets.fingerprint - Parameter 'function'=<function SuperGlueDataset.preprocess_function at 0x2b8c9a1043a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.
12/07/2022 13:24:39 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /users/PAS2318/evanhuang117/.cache/huggingface/datasets/super_glue/copa/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-c7fde805ec99108d.arrow
12/07/2022 13:24:40 - INFO - tasks.superglue.get_trainer - Sample 238 of the training set: {'premise': 'A fistfight broke out in the hall of the school.', 'choice1': 'The principal suspended the students involved.', 'choice2': 'The principal called off classes for the day.', 'question': 'effect', 'idx': 238, 'label': 0, 'text_a': 'A fistfight broke out in the hall of the school. so', 'input_ids': [[0, 250, 19033, 16695, 2263, 66, 11, 5, 5179, 9, 5, 334, 4, 98, 2, 2, 133, 5402, 3456, 5, 521, 963, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 250, 19033, 16695, 2263, 66, 11, 5, 5179, 9, 5, 334, 4, 98, 2, 2, 133, 5402, 373, 160, 4050, 13, 5, 183, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}.
12/07/2022 13:24:40 - INFO - tasks.superglue.get_trainer - Sample 231 of the training set: {'premise': 'The woman visited her family.', 'choice1': 'She distrusted them.', 'choice2': 'She missed them.', 'question': 'cause', 'idx': 231, 'label': 1, 'text_a': 'The woman visited her family. because', 'input_ids': [[0, 133, 693, 3790, 69, 284, 4, 142, 2, 2, 2515, 7018, 338, 15876, 106, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 133, 693, 3790, 69, 284, 4, 142, 2, 2, 2515, 2039, 106, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}.
12/07/2022 13:24:40 - INFO - tasks.superglue.get_trainer - Sample 260 of the training set: {'premise': 'The police officer pulled over the celebrity.', 'choice1': 'The celebrity offered the officer a bribe.', 'choice2': 'The celebrity sued the police officer.', 'question': 'effect', 'idx': 260, 'label': 0, 'text_a': 'The police officer pulled over the celebrity. so', 'input_ids': [[0, 133, 249, 1036, 2468, 81, 5, 6794, 4, 98, 2, 2, 133, 6794, 1661, 5, 1036, 10, 25677, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 133, 249, 1036, 2468, 81, 5, 6794, 4, 98, 2, 2, 133, 6794, 8124, 5, 249, 1036, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}.

[INFO|configuration_utils.py:583] 2022-12-07 13:24:40,373 >> loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /users/PAS2318/evanhuang117/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373
[INFO|configuration_utils.py:620] 2022-12-07 13:24:40,375 >> Model config RobertaConfig {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "finetuning_task": "copa",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 1024,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "label2id": {
    "LABEL_0": 0
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 16,
  "num_hidden_layers": 24,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.3",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

[INFO|modeling_utils.py:1323] 2022-12-07 13:24:40,501 >> loading weights file https://huggingface.co/roberta-large/resolve/main/pytorch_model.bin from cache at /users/PAS2318/evanhuang117/.cache/huggingface/transformers/8e36ec2f5052bec1e79e139b84c2c3089cb647694ba0f4f634fec7b8258f7c89.c43841d8c5cd23c435408295164cda9525270aa42cd0cc9200911570c0342352
[WARNING|modeling_utils.py:1579] 2022-12-07 13:24:48,730 >> Some weights of the model checkpoint at roberta-large were not used when initializing RobertaPrefixForMultipleChoice: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
- This IS expected if you are initializing RobertaPrefixForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaPrefixForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1590] 2022-12-07 13:24:48,730 >> Some weights of RobertaPrefixForMultipleChoice were not initialized from the model checkpoint at roberta-large and are newly initialized: ['prefix_encoder.embedding.weight', 'classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|trainer.py:540] 2022-12-07 13:24:55,951 >> The following columns in the training set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:1196] 2022-12-07 13:24:55,968 >> ***** Running training *****
[INFO|trainer.py:1197] 2022-12-07 13:24:55,969 >>   Num examples = 400
[INFO|trainer.py:1198] 2022-12-07 13:24:55,969 >>   Num Epochs = 120
[INFO|trainer.py:1199] 2022-12-07 13:24:55,969 >>   Instantaneous batch size per device = 16
[INFO|trainer.py:1200] 2022-12-07 13:24:55,969 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:1201] 2022-12-07 13:24:55,969 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1202] 2022-12-07 13:24:55,969 >>   Total optimization steps = 3000
total param is 394241
  0%|          | 0/3000 [00:00<?, ?it/s]  0%|          | 1/3000 [00:02<1:47:26,  2.15s/it]  0%|          | 2/3000 [00:02<57:50,  1.16s/it]    0%|          | 3/3000 [00:03<41:58,  1.19it/s]  0%|          | 4/3000 [00:03<34:34,  1.44it/s]  0%|          | 5/3000 [00:04<30:29,  1.64it/s]  0%|          | 6/3000 [00:04<28:00,  1.78it/s]  0%|          | 7/3000 [00:04<26:24,  1.89it/s]  0%|          | 8/3000 [00:05<25:19,  1.97it/s]  0%|          | 9/3000 [00:05<24:38,  2.02it/s]  0%|          | 10/3000 [00:06<24:18,  2.05it/s]  0%|          | 11/3000 [00:06<23:53,  2.09it/s]  0%|          | 12/3000 [00:07<23:40,  2.10it/s]  0%|          | 13/3000 [00:07<23:33,  2.11it/s]  0%|          | 14/3000 [00:08<23:22,  2.13it/s]  0%|          | 15/3000 [00:08<23:17,  2.14it/s]  1%|          | 16/3000 [00:09<23:15,  2.14it/s]  1%|          | 17/3000 [00:09<23:17,  2.13it/s]  1%|          | 18/3000 [00:10<23:11,  2.14it/s]  1%|          | 19/3000 [00:10<23:07,  2.15it/s]  1%|          | 20/3000 [00:10<23:09,  2.14it/s]  1%|          | 21/3000 [00:11<23:10,  2.14it/s]  1%|          | 22/3000 [00:11<23:06,  2.15it/s]  1%|          | 23/3000 [00:12<23:02,  2.15it/s]  1%|          | 24/3000 [00:12<23:01,  2.15it/s]  1%|          | 25/3000 [00:13<23:03,  2.15it/s][INFO|trainer.py:540] 2022-12-07 13:25:09,281 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:25:09,283 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:25:09,284 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:25:09,284 >>   Batch size = 8

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.81it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.61it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.48it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  9.03it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.89it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.78it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.68it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.62it/s][A12/07/2022 13:25:10 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                 
                                               [A  1%|          | 25/3000 [00:14<23:03,  2.15it/s]
100%|██████████| 13/13 [00:01<00:00,  8.62it/s][A
                                               [A{'eval_loss': 0.6896939277648926, 'eval_accuracy': 0.52, 'eval_runtime': 1.5589, 'eval_samples_per_second': 64.147, 'eval_steps_per_second': 8.339, 'epoch': 1.0}
12/07/2022 13:25:10 - INFO - training.trainer_base - ***** Epoch 0: Best results *****
12/07/2022 13:25:10 - INFO - training.trainer_base - best_epoch = 0
12/07/2022 13:25:10 - INFO - training.trainer_base - best_eval_accuracy = 0.52
                                                   1%|          | 25/3000 [00:14<23:03,  2.15it/s]  1%|          | 26/3000 [00:15<46:31,  1.07it/s]  1%|          | 27/3000 [00:15<39:27,  1.26it/s]  1%|          | 28/3000 [00:16<34:32,  1.43it/s]  1%|          | 29/3000 [00:16<31:05,  1.59it/s]  1%|          | 30/3000 [00:17<28:41,  1.73it/s]  1%|          | 31/3000 [00:17<27:01,  1.83it/s]  1%|          | 32/3000 [00:18<25:48,  1.92it/s]  1%|          | 33/3000 [00:18<24:55,  1.98it/s]  1%|          | 34/3000 [00:19<24:21,  2.03it/s]  1%|          | 35/3000 [00:19<23:58,  2.06it/s]  1%|          | 36/3000 [00:20<23:39,  2.09it/s]  1%|          | 37/3000 [00:20<23:27,  2.11it/s]  1%|▏         | 38/3000 [00:20<23:21,  2.11it/s]  1%|▏         | 39/3000 [00:21<23:17,  2.12it/s]  1%|▏         | 40/3000 [00:21<23:09,  2.13it/s]  1%|▏         | 41/3000 [00:22<23:04,  2.14it/s]  1%|▏         | 42/3000 [00:22<23:02,  2.14it/s]  1%|▏         | 43/3000 [00:23<23:01,  2.14it/s]  1%|▏         | 44/3000 [00:23<23:01,  2.14it/s]  2%|▏         | 45/3000 [00:24<22:59,  2.14it/s]  2%|▏         | 46/3000 [00:24<22:58,  2.14it/s]  2%|▏         | 47/3000 [00:25<22:59,  2.14it/s]  2%|▏         | 48/3000 [00:25<22:59,  2.14it/s]  2%|▏         | 49/3000 [00:26<22:58,  2.14it/s]  2%|▏         | 50/3000 [00:26<22:57,  2.14it/s][INFO|trainer.py:540] 2022-12-07 13:25:22,516 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:25:22,518 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:25:22,518 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:25:22,518 >>   Batch size = 8
OrderedDict([('best_epoch', 0), ('best_eval_accuracy', 0.52), ('epoch', 1.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.80it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.59it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.44it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  9.00it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.86it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.72it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.63it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.57it/s][A12/07/2022 13:25:24 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                 
                                               [A  2%|▏         | 50/3000 [00:28<22:57,  2.14it/s]
100%|██████████| 13/13 [00:01<00:00,  8.57it/s][A
                                               [A{'eval_loss': 0.6924521923065186, 'eval_accuracy': 0.53, 'eval_runtime': 1.5045, 'eval_samples_per_second': 66.467, 'eval_steps_per_second': 8.641, 'epoch': 2.0}
12/07/2022 13:25:24 - INFO - training.trainer_base - ***** Epoch 1: Best results *****
12/07/2022 13:25:24 - INFO - training.trainer_base - best_epoch = 1
12/07/2022 13:25:24 - INFO - training.trainer_base - best_eval_accuracy = 0.53
12/07/2022 13:25:24 - INFO - training.trainer_base - epoch = 1.0
                                                   2%|▏         | 50/3000 [00:28<22:57,  2.14it/s]  2%|▏         | 51/3000 [00:28<45:13,  1.09it/s]  2%|▏         | 52/3000 [00:28<38:31,  1.28it/s]  2%|▏         | 53/3000 [00:29<33:49,  1.45it/s]  2%|▏         | 54/3000 [00:29<30:33,  1.61it/s]  2%|▏         | 55/3000 [00:30<28:18,  1.73it/s]  2%|▏         | 56/3000 [00:30<26:43,  1.84it/s]  2%|▏         | 57/3000 [00:31<25:35,  1.92it/s]  2%|▏         | 58/3000 [00:31<24:46,  1.98it/s]  2%|▏         | 59/3000 [00:32<24:16,  2.02it/s]  2%|▏         | 60/3000 [00:32<23:53,  2.05it/s]  2%|▏         | 61/3000 [00:33<23:35,  2.08it/s]  2%|▏         | 62/3000 [00:33<23:20,  2.10it/s]  2%|▏         | 63/3000 [00:34<23:13,  2.11it/s]  2%|▏         | 64/3000 [00:34<23:10,  2.11it/s]  2%|▏         | 65/3000 [00:35<23:05,  2.12it/s]  2%|▏         | 66/3000 [00:35<22:59,  2.13it/s]  2%|▏         | 67/3000 [00:36<22:56,  2.13it/s]  2%|▏         | 68/3000 [00:36<22:55,  2.13it/s]  2%|▏         | 69/3000 [00:36<22:56,  2.13it/s]  2%|▏         | 70/3000 [00:37<22:53,  2.13it/s]  2%|▏         | 71/3000 [00:37<22:53,  2.13it/s]  2%|▏         | 72/3000 [00:38<22:52,  2.13it/s]  2%|▏         | 73/3000 [00:38<22:55,  2.13it/s]  2%|▏         | 74/3000 [00:39<22:51,  2.13it/s]  2%|▎         | 75/3000 [00:39<22:51,  2.13it/s][INFO|trainer.py:540] 2022-12-07 13:25:35,738 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:25:35,740 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:25:35,740 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:25:35,740 >>   Batch size = 8
OrderedDict([('best_epoch', 1), ('best_eval_accuracy', 0.53), ('epoch', 2.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.75it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.49it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.39it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.95it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.82it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.71it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.62it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.54it/s][A12/07/2022 13:25:37 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                 
                                               [A  2%|▎         | 75/3000 [00:41<22:51,  2.13it/s]
100%|██████████| 13/13 [00:01<00:00,  8.54it/s][A
                                               [A{'eval_loss': 0.6935933828353882, 'eval_accuracy': 0.47, 'eval_runtime': 1.5082, 'eval_samples_per_second': 66.306, 'eval_steps_per_second': 8.62, 'epoch': 3.0}
12/07/2022 13:25:37 - INFO - training.trainer_base - ***** Epoch 2: Best results *****
12/07/2022 13:25:37 - INFO - training.trainer_base - best_epoch = 1
12/07/2022 13:25:37 - INFO - training.trainer_base - best_eval_accuracy = 0.53
12/07/2022 13:25:37 - INFO - training.trainer_base - epoch = 2.0
                                                   2%|▎         | 75/3000 [00:41<22:51,  2.13it/s]  3%|▎         | 76/3000 [00:41<45:02,  1.08it/s]  3%|▎         | 77/3000 [00:42<38:21,  1.27it/s]  3%|▎         | 78/3000 [00:42<33:40,  1.45it/s]  3%|▎         | 79/3000 [00:43<30:27,  1.60it/s]  3%|▎         | 80/3000 [00:43<28:12,  1.73it/s]  3%|▎         | 81/3000 [00:44<26:35,  1.83it/s]  3%|▎         | 82/3000 [00:44<25:29,  1.91it/s]  3%|▎         | 83/3000 [00:45<24:43,  1.97it/s]  3%|▎         | 84/3000 [00:45<24:13,  2.01it/s]  3%|▎         | 85/3000 [00:45<23:47,  2.04it/s]  3%|▎         | 86/3000 [00:46<23:27,  2.07it/s]  3%|▎         | 87/3000 [00:46<23:14,  2.09it/s]  3%|▎         | 88/3000 [00:47<23:06,  2.10it/s]  3%|▎         | 89/3000 [00:47<23:05,  2.10it/s]  3%|▎         | 90/3000 [00:48<22:56,  2.11it/s]  3%|▎         | 91/3000 [00:48<22:52,  2.12it/s]  3%|▎         | 92/3000 [00:49<22:51,  2.12it/s]  3%|▎         | 93/3000 [00:49<22:50,  2.12it/s]  3%|▎         | 94/3000 [00:50<22:52,  2.12it/s]  3%|▎         | 95/3000 [00:50<22:51,  2.12it/s]  3%|▎         | 96/3000 [00:51<22:50,  2.12it/s]  3%|▎         | 97/3000 [00:51<22:47,  2.12it/s]  3%|▎         | 98/3000 [00:52<22:48,  2.12it/s]  3%|▎         | 99/3000 [00:52<22:51,  2.12it/s]  3%|▎         | 100/3000 [00:53<22:50,  2.12it/s][INFO|trainer.py:540] 2022-12-07 13:25:49,028 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:25:49,030 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:25:49,030 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:25:49,030 >>   Batch size = 8
OrderedDict([('best_epoch', 1), ('best_eval_accuracy', 0.53), ('epoch', 3.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.68it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.51it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.39it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.93it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.79it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.66it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.57it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.48it/s][A12/07/2022 13:25:50 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A  3%|▎         | 100/3000 [00:54<22:50,  2.12it/s]
100%|██████████| 13/13 [00:01<00:00,  8.48it/s][A
                                               [A{'eval_loss': 0.693724513053894, 'eval_accuracy': 0.47, 'eval_runtime': 1.5159, 'eval_samples_per_second': 65.968, 'eval_steps_per_second': 8.576, 'epoch': 4.0}
12/07/2022 13:25:50 - INFO - training.trainer_base - ***** Epoch 3: Best results *****
12/07/2022 13:25:50 - INFO - training.trainer_base - best_epoch = 1
12/07/2022 13:25:50 - INFO - training.trainer_base - best_eval_accuracy = 0.53
12/07/2022 13:25:50 - INFO - training.trainer_base - epoch = 3.0
                                                    3%|▎         | 100/3000 [00:54<22:50,  2.12it/s]  3%|▎         | 101/3000 [00:55<44:52,  1.08it/s]  3%|▎         | 102/3000 [00:55<38:12,  1.26it/s]  3%|▎         | 103/3000 [00:55<33:33,  1.44it/s]  3%|▎         | 104/3000 [00:56<30:21,  1.59it/s]  4%|▎         | 105/3000 [00:56<28:03,  1.72it/s]  4%|▎         | 106/3000 [00:57<26:28,  1.82it/s]  4%|▎         | 107/3000 [00:57<25:21,  1.90it/s]  4%|▎         | 108/3000 [00:58<24:32,  1.96it/s]  4%|▎         | 109/3000 [00:58<24:03,  2.00it/s]  4%|▎         | 110/3000 [00:59<23:37,  2.04it/s]  4%|▎         | 111/3000 [00:59<23:19,  2.06it/s]  4%|▎         | 112/3000 [01:00<23:08,  2.08it/s]  4%|▍         | 113/3000 [01:00<23:00,  2.09it/s]  4%|▍         | 114/3000 [01:01<22:57,  2.10it/s]  4%|▍         | 115/3000 [01:01<22:49,  2.11it/s]  4%|▍         | 116/3000 [01:02<22:45,  2.11it/s]  4%|▍         | 117/3000 [01:02<22:44,  2.11it/s]  4%|▍         | 118/3000 [01:03<22:43,  2.11it/s]  4%|▍         | 119/3000 [01:03<22:42,  2.11it/s]  4%|▍         | 120/3000 [01:04<22:39,  2.12it/s]  4%|▍         | 121/3000 [01:04<22:38,  2.12it/s]  4%|▍         | 122/3000 [01:04<22:37,  2.12it/s]  4%|▍         | 123/3000 [01:05<22:38,  2.12it/s]  4%|▍         | 124/3000 [01:05<22:37,  2.12it/s]  4%|▍         | 125/3000 [01:06<22:34,  2.12it/s][INFO|trainer.py:540] 2022-12-07 13:26:02,342 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:26:02,344 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:26:02,344 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:26:02,344 >>   Batch size = 8
OrderedDict([('best_epoch', 1), ('best_eval_accuracy', 0.53), ('epoch', 4.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.56it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.40it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.33it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.87it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.73it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.61it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.52it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.48it/s][A12/07/2022 13:26:03 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A  4%|▍         | 125/3000 [01:07<22:34,  2.12it/s]
100%|██████████| 13/13 [00:01<00:00,  8.48it/s][A
                                               [A{'eval_loss': 0.693227231502533, 'eval_accuracy': 0.55, 'eval_runtime': 1.5222, 'eval_samples_per_second': 65.694, 'eval_steps_per_second': 8.54, 'epoch': 5.0}
12/07/2022 13:26:03 - INFO - training.trainer_base - ***** Epoch 4: Best results *****
12/07/2022 13:26:03 - INFO - training.trainer_base - best_epoch = 4
12/07/2022 13:26:03 - INFO - training.trainer_base - best_eval_accuracy = 0.55
12/07/2022 13:26:03 - INFO - training.trainer_base - epoch = 4.0
                                                    4%|▍         | 125/3000 [01:07<22:34,  2.12it/s]  4%|▍         | 126/3000 [01:08<44:29,  1.08it/s]  4%|▍         | 127/3000 [01:08<37:54,  1.26it/s]  4%|▍         | 128/3000 [01:09<33:18,  1.44it/s]  4%|▍         | 129/3000 [01:09<30:09,  1.59it/s]  4%|▍         | 130/3000 [01:10<27:51,  1.72it/s]  4%|▍         | 131/3000 [01:10<26:14,  1.82it/s]  4%|▍         | 132/3000 [01:11<25:09,  1.90it/s]  4%|▍         | 133/3000 [01:11<24:25,  1.96it/s]  4%|▍         | 134/3000 [01:12<23:54,  2.00it/s]  4%|▍         | 135/3000 [01:12<23:32,  2.03it/s]  5%|▍         | 136/3000 [01:13<23:13,  2.05it/s]  5%|▍         | 137/3000 [01:13<23:01,  2.07it/s]  5%|▍         | 138/3000 [01:14<22:50,  2.09it/s]  5%|▍         | 139/3000 [01:14<22:47,  2.09it/s]  5%|▍         | 140/3000 [01:14<22:43,  2.10it/s]  5%|▍         | 141/3000 [01:15<22:37,  2.11it/s]  5%|▍         | 142/3000 [01:15<22:36,  2.11it/s]  5%|▍         | 143/3000 [01:16<22:33,  2.11it/s]  5%|▍         | 144/3000 [01:16<22:33,  2.11it/s]  5%|▍         | 145/3000 [01:17<22:33,  2.11it/s]  5%|▍         | 146/3000 [01:17<22:33,  2.11it/s]  5%|▍         | 147/3000 [01:18<22:30,  2.11it/s]  5%|▍         | 148/3000 [01:18<22:33,  2.11it/s]  5%|▍         | 149/3000 [01:19<22:35,  2.10it/s]  5%|▌         | 150/3000 [01:19<22:34,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:26:15,707 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:26:15,709 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:26:15,709 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:26:15,709 >>   Batch size = 8
OrderedDict([('best_epoch', 4), ('best_eval_accuracy', 0.55), ('epoch', 5.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.52it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.41it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.30it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:26:17 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A  5%|▌         | 150/3000 [01:21<22:34,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6928726434707642, 'eval_accuracy': 0.58, 'eval_runtime': 1.528, 'eval_samples_per_second': 65.444, 'eval_steps_per_second': 8.508, 'epoch': 6.0}
12/07/2022 13:26:17 - INFO - training.trainer_base - ***** Epoch 5: Best results *****
12/07/2022 13:26:17 - INFO - training.trainer_base - best_epoch = 5
12/07/2022 13:26:17 - INFO - training.trainer_base - best_eval_accuracy = 0.58
12/07/2022 13:26:17 - INFO - training.trainer_base - epoch = 5.0
                                                    5%|▌         | 150/3000 [01:21<22:34,  2.10it/s]  5%|▌         | 151/3000 [01:21<44:25,  1.07it/s]  5%|▌         | 152/3000 [01:22<37:47,  1.26it/s]  5%|▌         | 153/3000 [01:22<33:09,  1.43it/s]  5%|▌         | 154/3000 [01:23<29:59,  1.58it/s]  5%|▌         | 155/3000 [01:23<27:48,  1.71it/s]  5%|▌         | 156/3000 [01:24<26:12,  1.81it/s]  5%|▌         | 157/3000 [01:24<25:01,  1.89it/s]  5%|▌         | 158/3000 [01:25<24:14,  1.95it/s]  5%|▌         | 159/3000 [01:25<23:41,  2.00it/s]  5%|▌         | 160/3000 [01:26<23:17,  2.03it/s]  5%|▌         | 161/3000 [01:26<23:02,  2.05it/s]  5%|▌         | 162/3000 [01:26<22:48,  2.07it/s]  5%|▌         | 163/3000 [01:27<22:43,  2.08it/s]  5%|▌         | 164/3000 [01:27<22:39,  2.09it/s]  6%|▌         | 165/3000 [01:28<22:34,  2.09it/s]  6%|▌         | 166/3000 [01:28<22:30,  2.10it/s]  6%|▌         | 167/3000 [01:29<22:26,  2.10it/s]  6%|▌         | 168/3000 [01:29<22:23,  2.11it/s]  6%|▌         | 169/3000 [01:30<22:23,  2.11it/s]  6%|▌         | 170/3000 [01:30<22:23,  2.11it/s]  6%|▌         | 171/3000 [01:31<22:26,  2.10it/s]  6%|▌         | 172/3000 [01:31<22:23,  2.11it/s]  6%|▌         | 173/3000 [01:32<22:20,  2.11it/s]  6%|▌         | 174/3000 [01:32<22:19,  2.11it/s]  6%|▌         | 175/3000 [01:33<22:18,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:26:29,094 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:26:29,095 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:26:29,095 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:26:29,096 >>   Batch size = 8
OrderedDict([('best_epoch', 5), ('best_eval_accuracy', 0.58), ('epoch', 6.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.44it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.39it/s][A12/07/2022 13:26:30 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A  6%|▌         | 175/3000 [01:34<22:18,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.39it/s][A
                                               [A{'eval_loss': 0.6927624344825745, 'eval_accuracy': 0.6, 'eval_runtime': 1.5324, 'eval_samples_per_second': 65.259, 'eval_steps_per_second': 8.484, 'epoch': 7.0}
12/07/2022 13:26:30 - INFO - training.trainer_base - ***** Epoch 6: Best results *****
12/07/2022 13:26:30 - INFO - training.trainer_base - best_epoch = 6
12/07/2022 13:26:30 - INFO - training.trainer_base - best_eval_accuracy = 0.6
12/07/2022 13:26:30 - INFO - training.trainer_base - epoch = 6.0
                                                    6%|▌         | 175/3000 [01:34<22:18,  2.11it/s]  6%|▌         | 176/3000 [01:35<44:04,  1.07it/s]  6%|▌         | 177/3000 [01:35<37:30,  1.25it/s]  6%|▌         | 178/3000 [01:36<32:53,  1.43it/s]  6%|▌         | 179/3000 [01:36<29:40,  1.58it/s]  6%|▌         | 180/3000 [01:37<27:28,  1.71it/s]  6%|▌         | 181/3000 [01:37<25:55,  1.81it/s]  6%|▌         | 182/3000 [01:37<24:51,  1.89it/s]  6%|▌         | 183/3000 [01:38<24:04,  1.95it/s]  6%|▌         | 184/3000 [01:38<23:30,  2.00it/s]  6%|▌         | 185/3000 [01:39<23:10,  2.02it/s]  6%|▌         | 186/3000 [01:39<22:55,  2.05it/s]  6%|▌         | 187/3000 [01:40<22:44,  2.06it/s]  6%|▋         | 188/3000 [01:40<22:31,  2.08it/s]  6%|▋         | 189/3000 [01:41<22:27,  2.09it/s]  6%|▋         | 190/3000 [01:41<22:23,  2.09it/s]  6%|▋         | 191/3000 [01:42<22:21,  2.09it/s]  6%|▋         | 192/3000 [01:42<22:17,  2.10it/s]  6%|▋         | 193/3000 [01:43<22:16,  2.10it/s]  6%|▋         | 194/3000 [01:43<22:15,  2.10it/s]  6%|▋         | 195/3000 [01:44<22:12,  2.11it/s]  7%|▋         | 196/3000 [01:44<22:12,  2.10it/s]  7%|▋         | 197/3000 [01:45<22:07,  2.11it/s]  7%|▋         | 198/3000 [01:45<22:06,  2.11it/s]  7%|▋         | 199/3000 [01:46<22:09,  2.11it/s]  7%|▋         | 200/3000 [01:46<22:11,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:26:42,499 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:26:42,501 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:26:42,501 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:26:42,501 >>   Batch size = 8
OrderedDict([('best_epoch', 6), ('best_eval_accuracy', 0.6), ('epoch', 7.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.53it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.39it/s][A12/07/2022 13:26:44 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A  7%|▋         | 200/3000 [01:48<22:11,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.39it/s][A
                                               [A{'eval_loss': 0.6934470534324646, 'eval_accuracy': 0.5, 'eval_runtime': 1.5317, 'eval_samples_per_second': 65.288, 'eval_steps_per_second': 8.487, 'epoch': 8.0}
12/07/2022 13:26:44 - INFO - training.trainer_base - ***** Epoch 7: Best results *****
12/07/2022 13:26:44 - INFO - training.trainer_base - best_epoch = 6
12/07/2022 13:26:44 - INFO - training.trainer_base - best_eval_accuracy = 0.6
12/07/2022 13:26:44 - INFO - training.trainer_base - epoch = 7.0
                                                    7%|▋         | 200/3000 [01:48<22:11,  2.10it/s]  7%|▋         | 201/3000 [01:48<43:41,  1.07it/s]  7%|▋         | 202/3000 [01:49<37:12,  1.25it/s]  7%|▋         | 203/3000 [01:49<32:41,  1.43it/s]  7%|▋         | 204/3000 [01:49<29:35,  1.57it/s]  7%|▋         | 205/3000 [01:50<27:22,  1.70it/s]  7%|▋         | 206/3000 [01:50<25:45,  1.81it/s]  7%|▋         | 207/3000 [01:51<24:38,  1.89it/s]  7%|▋         | 208/3000 [01:51<23:53,  1.95it/s]  7%|▋         | 209/3000 [01:52<23:24,  1.99it/s]  7%|▋         | 210/3000 [01:52<23:03,  2.02it/s]  7%|▋         | 211/3000 [01:53<22:46,  2.04it/s]  7%|▋         | 212/3000 [01:53<22:31,  2.06it/s]  7%|▋         | 213/3000 [01:54<22:23,  2.08it/s]  7%|▋         | 214/3000 [01:54<22:18,  2.08it/s]  7%|▋         | 215/3000 [01:55<22:16,  2.08it/s]  7%|▋         | 216/3000 [01:55<22:15,  2.09it/s]  7%|▋         | 217/3000 [01:56<22:11,  2.09it/s]  7%|▋         | 218/3000 [01:56<22:07,  2.10it/s]  7%|▋         | 219/3000 [01:57<22:06,  2.10it/s]  7%|▋         | 220/3000 [01:57<22:04,  2.10it/s]  7%|▋         | 221/3000 [01:58<22:06,  2.09it/s]  7%|▋         | 222/3000 [01:58<22:03,  2.10it/s]  7%|▋         | 223/3000 [01:59<22:02,  2.10it/s]  7%|▋         | 224/3000 [01:59<21:59,  2.10it/s]  8%|▊         | 225/3000 [01:59<21:59,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:26:55,939 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:26:55,941 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:26:55,941 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:26:55,941 >>   Batch size = 8
OrderedDict([('best_epoch', 6), ('best_eval_accuracy', 0.6), ('epoch', 8.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.46it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.80it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.67it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:26:57 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A  8%|▊         | 225/3000 [02:01<21:59,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.6939803957939148, 'eval_accuracy': 0.52, 'eval_runtime': 1.5325, 'eval_samples_per_second': 65.255, 'eval_steps_per_second': 8.483, 'epoch': 9.0}
12/07/2022 13:26:57 - INFO - training.trainer_base - ***** Epoch 8: Best results *****
12/07/2022 13:26:57 - INFO - training.trainer_base - best_epoch = 6
12/07/2022 13:26:57 - INFO - training.trainer_base - best_eval_accuracy = 0.6
12/07/2022 13:26:57 - INFO - training.trainer_base - epoch = 8.0
                                                    8%|▊         | 225/3000 [02:01<21:59,  2.10it/s]  8%|▊         | 226/3000 [02:01<43:16,  1.07it/s]  8%|▊         | 227/3000 [02:02<36:55,  1.25it/s]  8%|▊         | 228/3000 [02:02<32:30,  1.42it/s]  8%|▊         | 229/3000 [02:03<29:21,  1.57it/s]  8%|▊         | 230/3000 [02:03<27:05,  1.70it/s]  8%|▊         | 231/3000 [02:04<25:31,  1.81it/s]  8%|▊         | 232/3000 [02:04<24:28,  1.88it/s]  8%|▊         | 233/3000 [02:05<23:43,  1.94it/s]  8%|▊         | 234/3000 [02:05<23:16,  1.98it/s]  8%|▊         | 235/3000 [02:06<22:50,  2.02it/s]  8%|▊         | 236/3000 [02:06<22:33,  2.04it/s]  8%|▊         | 237/3000 [02:07<22:22,  2.06it/s]  8%|▊         | 238/3000 [02:07<22:15,  2.07it/s]  8%|▊         | 239/3000 [02:08<22:09,  2.08it/s]  8%|▊         | 240/3000 [02:08<22:08,  2.08it/s]  8%|▊         | 241/3000 [02:09<22:01,  2.09it/s]  8%|▊         | 242/3000 [02:09<21:56,  2.10it/s]  8%|▊         | 243/3000 [02:10<21:53,  2.10it/s]  8%|▊         | 244/3000 [02:10<21:53,  2.10it/s]  8%|▊         | 245/3000 [02:11<21:52,  2.10it/s]  8%|▊         | 246/3000 [02:11<21:49,  2.10it/s]  8%|▊         | 247/3000 [02:11<21:48,  2.10it/s]  8%|▊         | 248/3000 [02:12<21:49,  2.10it/s]  8%|▊         | 249/3000 [02:12<21:49,  2.10it/s]  8%|▊         | 250/3000 [02:13<21:50,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:27:09,389 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:27:09,390 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:27:09,390 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:27:09,390 >>   Batch size = 8
OrderedDict([('best_epoch', 6), ('best_eval_accuracy', 0.6), ('epoch', 9.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.41it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.34it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.46it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.40it/s][A12/07/2022 13:27:10 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A  8%|▊         | 250/3000 [02:14<21:50,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.40it/s][A
                                               [A{'eval_loss': 0.6930921077728271, 'eval_accuracy': 0.56, 'eval_runtime': 1.5316, 'eval_samples_per_second': 65.293, 'eval_steps_per_second': 8.488, 'epoch': 10.0}
12/07/2022 13:27:10 - INFO - training.trainer_base - ***** Epoch 9: Best results *****
12/07/2022 13:27:10 - INFO - training.trainer_base - best_epoch = 6
12/07/2022 13:27:10 - INFO - training.trainer_base - best_eval_accuracy = 0.6
12/07/2022 13:27:10 - INFO - training.trainer_base - epoch = 9.0
                                                    8%|▊         | 250/3000 [02:14<21:50,  2.10it/s]  8%|▊         | 251/3000 [02:15<42:59,  1.07it/s]  8%|▊         | 252/3000 [02:15<36:38,  1.25it/s]  8%|▊         | 253/3000 [02:16<32:08,  1.42it/s]  8%|▊         | 254/3000 [02:16<29:00,  1.58it/s]  8%|▊         | 255/3000 [02:17<26:47,  1.71it/s]  9%|▊         | 256/3000 [02:17<25:16,  1.81it/s]  9%|▊         | 257/3000 [02:18<24:14,  1.89it/s]  9%|▊         | 258/3000 [02:18<23:27,  1.95it/s]  9%|▊         | 259/3000 [02:19<22:55,  1.99it/s]  9%|▊         | 260/3000 [02:19<22:34,  2.02it/s]  9%|▊         | 261/3000 [02:20<22:20,  2.04it/s]  9%|▊         | 262/3000 [02:20<22:13,  2.05it/s]  9%|▉         | 263/3000 [02:21<22:06,  2.06it/s]  9%|▉         | 264/3000 [02:21<21:58,  2.08it/s]  9%|▉         | 265/3000 [02:22<21:50,  2.09it/s]  9%|▉         | 266/3000 [02:22<21:46,  2.09it/s]  9%|▉         | 267/3000 [02:23<21:44,  2.09it/s]  9%|▉         | 268/3000 [02:23<21:44,  2.09it/s]  9%|▉         | 269/3000 [02:24<21:43,  2.10it/s]  9%|▉         | 270/3000 [02:24<21:39,  2.10it/s]  9%|▉         | 271/3000 [02:24<21:36,  2.10it/s]  9%|▉         | 272/3000 [02:25<21:38,  2.10it/s]  9%|▉         | 273/3000 [02:25<21:38,  2.10it/s]  9%|▉         | 274/3000 [02:26<21:39,  2.10it/s]  9%|▉         | 275/3000 [02:26<21:36,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:27:22,827 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:27:22,828 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:27:22,828 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:27:22,828 >>   Batch size = 8
OrderedDict([('best_epoch', 6), ('best_eval_accuracy', 0.6), ('epoch', 10.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.54it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.39it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:27:24 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A  9%|▉         | 275/3000 [02:28<21:36,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6932674646377563, 'eval_accuracy': 0.56, 'eval_runtime': 1.5303, 'eval_samples_per_second': 65.348, 'eval_steps_per_second': 8.495, 'epoch': 11.0}
12/07/2022 13:27:24 - INFO - training.trainer_base - ***** Epoch 10: Best results *****
12/07/2022 13:27:24 - INFO - training.trainer_base - best_epoch = 6
12/07/2022 13:27:24 - INFO - training.trainer_base - best_eval_accuracy = 0.6
12/07/2022 13:27:24 - INFO - training.trainer_base - epoch = 10.0
                                                    9%|▉         | 275/3000 [02:28<21:36,  2.10it/s]  9%|▉         | 276/3000 [02:28<42:27,  1.07it/s]  9%|▉         | 277/3000 [02:29<36:09,  1.26it/s]  9%|▉         | 278/3000 [02:29<31:48,  1.43it/s]  9%|▉         | 279/3000 [02:30<28:47,  1.58it/s]  9%|▉         | 280/3000 [02:30<26:40,  1.70it/s]  9%|▉         | 281/3000 [02:31<25:08,  1.80it/s]  9%|▉         | 282/3000 [02:31<24:03,  1.88it/s]  9%|▉         | 283/3000 [02:32<23:16,  1.95it/s]  9%|▉         | 284/3000 [02:32<22:44,  1.99it/s] 10%|▉         | 285/3000 [02:33<22:22,  2.02it/s] 10%|▉         | 286/3000 [02:33<22:08,  2.04it/s] 10%|▉         | 287/3000 [02:34<21:54,  2.06it/s] 10%|▉         | 288/3000 [02:34<21:44,  2.08it/s] 10%|▉         | 289/3000 [02:35<21:41,  2.08it/s] 10%|▉         | 290/3000 [02:35<21:37,  2.09it/s] 10%|▉         | 291/3000 [02:36<21:36,  2.09it/s] 10%|▉         | 292/3000 [02:36<21:32,  2.10it/s] 10%|▉         | 293/3000 [02:36<21:31,  2.10it/s] 10%|▉         | 294/3000 [02:37<21:30,  2.10it/s] 10%|▉         | 295/3000 [02:37<21:33,  2.09it/s] 10%|▉         | 296/3000 [02:38<21:34,  2.09it/s] 10%|▉         | 297/3000 [02:38<21:29,  2.10it/s] 10%|▉         | 298/3000 [02:39<21:24,  2.10it/s] 10%|▉         | 299/3000 [02:39<21:23,  2.10it/s] 10%|█         | 300/3000 [02:40<21:23,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:27:36,263 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:27:36,264 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:27:36,264 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:27:36,264 >>   Batch size = 8
OrderedDict([('best_epoch', 6), ('best_eval_accuracy', 0.6), ('epoch', 11.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.36it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.33it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.24it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.81it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.67it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.55it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:27:37 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 10%|█         | 300/3000 [02:41<21:23,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.692313015460968, 'eval_accuracy': 0.55, 'eval_runtime': 1.5333, 'eval_samples_per_second': 65.217, 'eval_steps_per_second': 8.478, 'epoch': 12.0}
12/07/2022 13:27:37 - INFO - training.trainer_base - ***** Epoch 11: Best results *****
12/07/2022 13:27:37 - INFO - training.trainer_base - best_epoch = 6
12/07/2022 13:27:37 - INFO - training.trainer_base - best_eval_accuracy = 0.6
12/07/2022 13:27:37 - INFO - training.trainer_base - epoch = 11.0
                                                   10%|█         | 300/3000 [02:41<21:23,  2.10it/s] 10%|█         | 301/3000 [02:42<42:10,  1.07it/s] 10%|█         | 302/3000 [02:42<35:59,  1.25it/s] 10%|█         | 303/3000 [02:43<31:35,  1.42it/s] 10%|█         | 304/3000 [02:43<28:30,  1.58it/s] 10%|█         | 305/3000 [02:44<26:22,  1.70it/s] 10%|█         | 306/3000 [02:44<24:54,  1.80it/s] 10%|█         | 307/3000 [02:45<23:52,  1.88it/s] 10%|█         | 308/3000 [02:45<23:06,  1.94it/s] 10%|█         | 309/3000 [02:46<22:32,  1.99it/s] 10%|█         | 310/3000 [02:46<22:11,  2.02it/s] 10%|█         | 311/3000 [02:47<21:56,  2.04it/s] 10%|█         | 312/3000 [02:47<21:45,  2.06it/s] 10%|█         | 313/3000 [02:48<21:35,  2.07it/s] 10%|█         | 314/3000 [02:48<21:28,  2.09it/s] 10%|█         | 315/3000 [02:48<21:23,  2.09it/s] 11%|█         | 316/3000 [02:49<21:21,  2.10it/s] 11%|█         | 317/3000 [02:49<21:21,  2.09it/s] 11%|█         | 318/3000 [02:50<21:21,  2.09it/s] 11%|█         | 319/3000 [02:50<21:17,  2.10it/s] 11%|█         | 320/3000 [02:51<21:14,  2.10it/s] 11%|█         | 321/3000 [02:51<21:13,  2.10it/s] 11%|█         | 322/3000 [02:52<21:15,  2.10it/s] 11%|█         | 323/3000 [02:52<21:16,  2.10it/s] 11%|█         | 324/3000 [02:53<21:14,  2.10it/s] 11%|█         | 325/3000 [02:53<21:13,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:27:49,706 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:27:49,708 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:27:49,708 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:27:49,708 >>   Batch size = 8
OrderedDict([('best_epoch', 6), ('best_eval_accuracy', 0.6), ('epoch', 12.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.41it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.33it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:27:51 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 11%|█         | 325/3000 [02:55<21:13,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6891343593597412, 'eval_accuracy': 0.55, 'eval_runtime': 1.5303, 'eval_samples_per_second': 65.345, 'eval_steps_per_second': 8.495, 'epoch': 13.0}
12/07/2022 13:27:51 - INFO - training.trainer_base - ***** Epoch 12: Best results *****
12/07/2022 13:27:51 - INFO - training.trainer_base - best_epoch = 6
12/07/2022 13:27:51 - INFO - training.trainer_base - best_eval_accuracy = 0.6
12/07/2022 13:27:51 - INFO - training.trainer_base - epoch = 12.0
                                                   11%|█         | 325/3000 [02:55<21:13,  2.10it/s] 11%|█         | 326/3000 [02:55<41:43,  1.07it/s] 11%|█         | 327/3000 [02:56<35:33,  1.25it/s] 11%|█         | 328/3000 [02:56<31:16,  1.42it/s] 11%|█         | 329/3000 [02:57<28:16,  1.57it/s] 11%|█         | 330/3000 [02:57<26:04,  1.71it/s] 11%|█         | 331/3000 [02:58<24:36,  1.81it/s] 11%|█         | 332/3000 [02:58<23:35,  1.89it/s] 11%|█         | 333/3000 [02:59<22:52,  1.94it/s] 11%|█         | 334/3000 [02:59<22:20,  1.99it/s] 11%|█         | 335/3000 [03:00<21:56,  2.02it/s] 11%|█         | 336/3000 [03:00<21:43,  2.04it/s] 11%|█         | 337/3000 [03:00<21:33,  2.06it/s] 11%|█▏        | 338/3000 [03:01<21:26,  2.07it/s] 11%|█▏        | 339/3000 [03:01<21:21,  2.08it/s] 11%|█▏        | 340/3000 [03:02<21:16,  2.08it/s] 11%|█▏        | 341/3000 [03:02<21:11,  2.09it/s] 11%|█▏        | 342/3000 [03:03<21:11,  2.09it/s] 11%|█▏        | 343/3000 [03:03<21:11,  2.09it/s] 11%|█▏        | 344/3000 [03:04<21:11,  2.09it/s] 12%|█▏        | 345/3000 [03:04<21:09,  2.09it/s] 12%|█▏        | 346/3000 [03:05<21:05,  2.10it/s] 12%|█▏        | 347/3000 [03:05<21:02,  2.10it/s] 12%|█▏        | 348/3000 [03:06<21:02,  2.10it/s] 12%|█▏        | 349/3000 [03:06<21:04,  2.10it/s] 12%|█▏        | 350/3000 [03:07<21:05,  2.09it/s][INFO|trainer.py:540] 2022-12-07 13:28:03,158 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:28:03,159 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:28:03,159 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:28:03,159 >>   Batch size = 8
OrderedDict([('best_epoch', 6), ('best_eval_accuracy', 0.6), ('epoch', 13.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.36it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.67it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:28:04 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 12%|█▏        | 350/3000 [03:08<21:05,  2.09it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.6850361824035645, 'eval_accuracy': 0.57, 'eval_runtime': 1.5354, 'eval_samples_per_second': 65.128, 'eval_steps_per_second': 8.467, 'epoch': 14.0}
12/07/2022 13:28:04 - INFO - training.trainer_base - ***** Epoch 13: Best results *****
12/07/2022 13:28:04 - INFO - training.trainer_base - best_epoch = 6
12/07/2022 13:28:04 - INFO - training.trainer_base - best_eval_accuracy = 0.6
12/07/2022 13:28:04 - INFO - training.trainer_base - epoch = 13.0
                                                   12%|█▏        | 350/3000 [03:08<21:05,  2.09it/s] 12%|█▏        | 351/3000 [03:09<41:29,  1.06it/s] 12%|█▏        | 352/3000 [03:09<35:18,  1.25it/s] 12%|█▏        | 353/3000 [03:10<30:57,  1.43it/s] 12%|█▏        | 354/3000 [03:10<27:57,  1.58it/s] 12%|█▏        | 355/3000 [03:11<25:53,  1.70it/s] 12%|█▏        | 356/3000 [03:11<24:27,  1.80it/s] 12%|█▏        | 357/3000 [03:12<23:23,  1.88it/s] 12%|█▏        | 358/3000 [03:12<22:37,  1.95it/s] 12%|█▏        | 359/3000 [03:13<22:04,  1.99it/s] 12%|█▏        | 360/3000 [03:13<21:44,  2.02it/s] 12%|█▏        | 361/3000 [03:13<21:29,  2.05it/s] 12%|█▏        | 362/3000 [03:14<21:22,  2.06it/s] 12%|█▏        | 363/3000 [03:14<21:13,  2.07it/s] 12%|█▏        | 364/3000 [03:15<21:07,  2.08it/s] 12%|█▏        | 365/3000 [03:15<21:02,  2.09it/s] 12%|█▏        | 366/3000 [03:16<20:58,  2.09it/s] 12%|█▏        | 367/3000 [03:16<20:59,  2.09it/s] 12%|█▏        | 368/3000 [03:17<20:56,  2.09it/s] 12%|█▏        | 369/3000 [03:17<20:52,  2.10it/s] 12%|█▏        | 370/3000 [03:18<20:50,  2.10it/s] 12%|█▏        | 371/3000 [03:18<20:49,  2.10it/s] 12%|█▏        | 372/3000 [03:19<20:50,  2.10it/s] 12%|█▏        | 373/3000 [03:19<20:52,  2.10it/s] 12%|█▏        | 374/3000 [03:20<20:50,  2.10it/s] 12%|█▎        | 375/3000 [03:20<20:48,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:28:16,595 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:28:16,597 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:28:16,597 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:28:16,597 >>   Batch size = 8
OrderedDict([('best_epoch', 6), ('best_eval_accuracy', 0.6), ('epoch', 14.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.44it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.36it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.81it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.40it/s][A12/07/2022 13:28:18 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 12%|█▎        | 375/3000 [03:22<20:48,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.40it/s][A
                                               [A{'eval_loss': 0.6725215315818787, 'eval_accuracy': 0.56, 'eval_runtime': 1.5317, 'eval_samples_per_second': 65.288, 'eval_steps_per_second': 8.487, 'epoch': 15.0}
12/07/2022 13:28:18 - INFO - training.trainer_base - ***** Epoch 14: Best results *****
12/07/2022 13:28:18 - INFO - training.trainer_base - best_epoch = 6
12/07/2022 13:28:18 - INFO - training.trainer_base - best_eval_accuracy = 0.6
12/07/2022 13:28:18 - INFO - training.trainer_base - epoch = 14.0
                                                   12%|█▎        | 375/3000 [03:22<20:48,  2.10it/s] 13%|█▎        | 376/3000 [03:22<40:57,  1.07it/s] 13%|█▎        | 377/3000 [03:23<34:51,  1.25it/s] 13%|█▎        | 378/3000 [03:23<30:37,  1.43it/s] 13%|█▎        | 379/3000 [03:24<27:40,  1.58it/s] 13%|█▎        | 380/3000 [03:24<25:40,  1.70it/s] 13%|█▎        | 381/3000 [03:25<24:12,  1.80it/s] 13%|█▎        | 382/3000 [03:25<23:07,  1.89it/s] 13%|█▎        | 383/3000 [03:25<22:22,  1.95it/s] 13%|█▎        | 384/3000 [03:26<21:52,  1.99it/s] 13%|█▎        | 385/3000 [03:26<21:33,  2.02it/s] 13%|█▎        | 386/3000 [03:27<21:23,  2.04it/s] 13%|█▎        | 387/3000 [03:27<21:10,  2.06it/s] 13%|█▎        | 388/3000 [03:28<21:00,  2.07it/s] 13%|█▎        | 389/3000 [03:28<20:53,  2.08it/s] 13%|█▎        | 390/3000 [03:29<20:51,  2.09it/s] 13%|█▎        | 391/3000 [03:29<20:49,  2.09it/s] 13%|█▎        | 392/3000 [03:30<20:48,  2.09it/s] 13%|█▎        | 393/3000 [03:30<20:43,  2.10it/s] 13%|█▎        | 394/3000 [03:31<20:41,  2.10it/s] 13%|█▎        | 395/3000 [03:31<20:40,  2.10it/s] 13%|█▎        | 396/3000 [03:32<20:40,  2.10it/s] 13%|█▎        | 397/3000 [03:32<20:41,  2.10it/s] 13%|█▎        | 398/3000 [03:33<20:40,  2.10it/s] 13%|█▎        | 399/3000 [03:33<20:37,  2.10it/s] 13%|█▎        | 400/3000 [03:34<20:36,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:28:30,034 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:28:30,035 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:28:30,035 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:28:30,035 >>   Batch size = 8
OrderedDict([('best_epoch', 6), ('best_eval_accuracy', 0.6), ('epoch', 15.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.45it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.35it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:28:31 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 13%|█▎        | 400/3000 [03:35<20:36,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6460223197937012, 'eval_accuracy': 0.62, 'eval_runtime': 1.5317, 'eval_samples_per_second': 65.288, 'eval_steps_per_second': 8.487, 'epoch': 16.0}
12/07/2022 13:28:31 - INFO - training.trainer_base - ***** Epoch 15: Best results *****
12/07/2022 13:28:31 - INFO - training.trainer_base - best_epoch = 15
12/07/2022 13:28:31 - INFO - training.trainer_base - best_eval_accuracy = 0.62
12/07/2022 13:28:31 - INFO - training.trainer_base - epoch = 15.0
                                                   13%|█▎        | 400/3000 [03:35<20:36,  2.10it/s] 13%|█▎        | 401/3000 [03:36<40:33,  1.07it/s] 13%|█▎        | 402/3000 [03:36<34:33,  1.25it/s] 13%|█▎        | 403/3000 [03:37<30:24,  1.42it/s] 13%|█▎        | 404/3000 [03:37<27:25,  1.58it/s] 14%|█▎        | 405/3000 [03:37<25:22,  1.70it/s] 14%|█▎        | 406/3000 [03:38<23:56,  1.81it/s] 14%|█▎        | 407/3000 [03:38<22:58,  1.88it/s] 14%|█▎        | 408/3000 [03:39<22:15,  1.94it/s] 14%|█▎        | 409/3000 [03:39<21:45,  1.99it/s] 14%|█▎        | 410/3000 [03:40<21:22,  2.02it/s] 14%|█▎        | 411/3000 [03:40<21:05,  2.05it/s] 14%|█▎        | 412/3000 [03:41<20:54,  2.06it/s] 14%|█▍        | 413/3000 [03:41<20:50,  2.07it/s] 14%|█▍        | 414/3000 [03:42<20:46,  2.07it/s] 14%|█▍        | 415/3000 [03:42<20:40,  2.08it/s] 14%|█▍        | 416/3000 [03:43<20:35,  2.09it/s] 14%|█▍        | 417/3000 [03:43<20:33,  2.09it/s] 14%|█▍        | 418/3000 [03:44<20:34,  2.09it/s] 14%|█▍        | 419/3000 [03:44<20:32,  2.09it/s] 14%|█▍        | 420/3000 [03:45<20:31,  2.10it/s] 14%|█▍        | 421/3000 [03:45<20:28,  2.10it/s] 14%|█▍        | 422/3000 [03:46<20:26,  2.10it/s] 14%|█▍        | 423/3000 [03:46<20:26,  2.10it/s] 14%|█▍        | 424/3000 [03:47<20:25,  2.10it/s] 14%|█▍        | 425/3000 [03:47<20:25,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:28:43,479 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:28:43,480 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:28:43,480 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:28:43,480 >>   Batch size = 8
OrderedDict([('best_epoch', 15), ('best_eval_accuracy', 0.62), ('epoch', 16.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.24it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.29it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.22it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.78it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.65it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.55it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.46it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.38it/s][A12/07/2022 13:28:45 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 14%|█▍        | 425/3000 [03:49<20:25,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.38it/s][A
                                               [A{'eval_loss': 0.571392297744751, 'eval_accuracy': 0.72, 'eval_runtime': 1.5373, 'eval_samples_per_second': 65.05, 'eval_steps_per_second': 8.456, 'epoch': 17.0}
12/07/2022 13:28:45 - INFO - training.trainer_base - ***** Epoch 16: Best results *****
12/07/2022 13:28:45 - INFO - training.trainer_base - best_epoch = 16
12/07/2022 13:28:45 - INFO - training.trainer_base - best_eval_accuracy = 0.72
12/07/2022 13:28:45 - INFO - training.trainer_base - epoch = 16.0
                                                   14%|█▍        | 425/3000 [03:49<20:25,  2.10it/s] 14%|█▍        | 426/3000 [03:49<40:15,  1.07it/s] 14%|█▍        | 427/3000 [03:49<34:16,  1.25it/s] 14%|█▍        | 428/3000 [03:50<30:05,  1.42it/s] 14%|█▍        | 429/3000 [03:50<27:11,  1.58it/s] 14%|█▍        | 430/3000 [03:51<25:07,  1.70it/s] 14%|█▍        | 431/3000 [03:51<23:41,  1.81it/s] 14%|█▍        | 432/3000 [03:52<22:40,  1.89it/s] 14%|█▍        | 433/3000 [03:52<21:57,  1.95it/s] 14%|█▍        | 434/3000 [03:53<21:28,  1.99it/s] 14%|█▍        | 435/3000 [03:53<21:08,  2.02it/s] 15%|█▍        | 436/3000 [03:54<20:56,  2.04it/s] 15%|█▍        | 437/3000 [03:54<20:43,  2.06it/s] 15%|█▍        | 438/3000 [03:55<20:33,  2.08it/s] 15%|█▍        | 439/3000 [03:55<20:28,  2.09it/s] 15%|█▍        | 440/3000 [03:56<20:25,  2.09it/s] 15%|█▍        | 441/3000 [03:56<20:23,  2.09it/s] 15%|█▍        | 442/3000 [03:57<20:21,  2.09it/s] 15%|█▍        | 443/3000 [03:57<20:14,  2.10it/s] 15%|█▍        | 444/3000 [03:58<20:14,  2.10it/s] 15%|█▍        | 445/3000 [03:58<20:13,  2.11it/s] 15%|█▍        | 446/3000 [03:59<20:15,  2.10it/s] 15%|█▍        | 447/3000 [03:59<20:14,  2.10it/s] 15%|█▍        | 448/3000 [03:59<20:12,  2.11it/s] 15%|█▍        | 449/3000 [04:00<20:13,  2.10it/s] 15%|█▌        | 450/3000 [04:00<20:16,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:28:56,911 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:28:56,913 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:28:56,913 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:28:56,913 >>   Batch size = 8
OrderedDict([('best_epoch', 16), ('best_eval_accuracy', 0.72), ('epoch', 17.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.39it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.31it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.60it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:28:58 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 15%|█▌        | 450/3000 [04:02<20:16,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.5598668456077576, 'eval_accuracy': 0.76, 'eval_runtime': 1.5291, 'eval_samples_per_second': 65.398, 'eval_steps_per_second': 8.502, 'epoch': 18.0}
12/07/2022 13:28:58 - INFO - training.trainer_base - ***** Epoch 17: Best results *****
12/07/2022 13:28:58 - INFO - training.trainer_base - best_epoch = 17
12/07/2022 13:28:58 - INFO - training.trainer_base - best_eval_accuracy = 0.76
12/07/2022 13:28:58 - INFO - training.trainer_base - epoch = 17.0
                                                   15%|█▌        | 450/3000 [04:02<20:16,  2.10it/s] 15%|█▌        | 451/3000 [04:02<39:50,  1.07it/s] 15%|█▌        | 452/3000 [04:03<33:53,  1.25it/s] 15%|█▌        | 453/3000 [04:03<29:44,  1.43it/s] 15%|█▌        | 454/3000 [04:04<26:52,  1.58it/s] 15%|█▌        | 455/3000 [04:04<24:52,  1.71it/s] 15%|█▌        | 456/3000 [04:05<23:25,  1.81it/s] 15%|█▌        | 457/3000 [04:05<22:24,  1.89it/s] 15%|█▌        | 458/3000 [04:06<21:42,  1.95it/s] 15%|█▌        | 459/3000 [04:06<21:14,  1.99it/s] 15%|█▌        | 460/3000 [04:07<20:56,  2.02it/s] 15%|█▌        | 461/3000 [04:07<20:40,  2.05it/s] 15%|█▌        | 462/3000 [04:08<20:27,  2.07it/s] 15%|█▌        | 463/3000 [04:08<20:22,  2.08it/s] 15%|█▌        | 464/3000 [04:09<20:15,  2.09it/s] 16%|█▌        | 465/3000 [04:09<20:16,  2.08it/s] 16%|█▌        | 466/3000 [04:10<20:12,  2.09it/s] 16%|█▌        | 467/3000 [04:10<20:08,  2.10it/s] 16%|█▌        | 468/3000 [04:11<20:06,  2.10it/s] 16%|█▌        | 469/3000 [04:11<20:04,  2.10it/s] 16%|█▌        | 470/3000 [04:11<20:04,  2.10it/s] 16%|█▌        | 471/3000 [04:12<20:07,  2.09it/s] 16%|█▌        | 472/3000 [04:12<20:04,  2.10it/s] 16%|█▌        | 473/3000 [04:13<20:01,  2.10it/s] 16%|█▌        | 474/3000 [04:13<19:59,  2.11it/s] 16%|█▌        | 475/3000 [04:14<20:01,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:29:10,331 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:29:10,333 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:29:10,333 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:29:10,333 >>   Batch size = 8
OrderedDict([('best_epoch', 17), ('best_eval_accuracy', 0.76), ('epoch', 18.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.51it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.36it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.55it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.40it/s][A12/07/2022 13:29:11 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 16%|█▌        | 475/3000 [04:15<20:01,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.40it/s][A
                                               [A{'eval_loss': 0.49872300028800964, 'eval_accuracy': 0.8, 'eval_runtime': 1.5313, 'eval_samples_per_second': 65.303, 'eval_steps_per_second': 8.489, 'epoch': 19.0}
12/07/2022 13:29:11 - INFO - training.trainer_base - ***** Epoch 18: Best results *****
12/07/2022 13:29:11 - INFO - training.trainer_base - best_epoch = 18
12/07/2022 13:29:11 - INFO - training.trainer_base - best_eval_accuracy = 0.8
12/07/2022 13:29:11 - INFO - training.trainer_base - epoch = 18.0
                                                   16%|█▌        | 475/3000 [04:15<20:01,  2.10it/s] 16%|█▌        | 476/3000 [04:16<39:22,  1.07it/s] 16%|█▌        | 477/3000 [04:16<33:33,  1.25it/s] 16%|█▌        | 478/3000 [04:17<29:26,  1.43it/s] 16%|█▌        | 479/3000 [04:17<26:34,  1.58it/s] 16%|█▌        | 480/3000 [04:18<24:32,  1.71it/s] 16%|█▌        | 481/3000 [04:18<23:08,  1.81it/s] 16%|█▌        | 482/3000 [04:19<22:11,  1.89it/s] 16%|█▌        | 483/3000 [04:19<21:31,  1.95it/s] 16%|█▌        | 484/3000 [04:20<21:02,  1.99it/s] 16%|█▌        | 485/3000 [04:20<20:40,  2.03it/s] 16%|█▌        | 486/3000 [04:21<20:26,  2.05it/s] 16%|█▌        | 487/3000 [04:21<20:17,  2.06it/s] 16%|█▋        | 488/3000 [04:22<20:12,  2.07it/s] 16%|█▋        | 489/3000 [04:22<20:09,  2.08it/s] 16%|█▋        | 490/3000 [04:23<20:04,  2.08it/s] 16%|█▋        | 491/3000 [04:23<19:56,  2.10it/s] 16%|█▋        | 492/3000 [04:23<19:54,  2.10it/s] 16%|█▋        | 493/3000 [04:24<19:54,  2.10it/s] 16%|█▋        | 494/3000 [04:24<19:54,  2.10it/s] 16%|█▋        | 495/3000 [04:25<19:54,  2.10it/s] 17%|█▋        | 496/3000 [04:25<19:52,  2.10it/s] 17%|█▋        | 497/3000 [04:26<19:50,  2.10it/s] 17%|█▋        | 498/3000 [04:26<19:52,  2.10it/s] 17%|█▋        | 499/3000 [04:27<19:51,  2.10it/s] 17%|█▋        | 500/3000 [04:27<19:53,  2.10it/s]                                                   17%|█▋        | 500/3000 [04:27<19:53,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:29:23,756 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:29:23,758 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:29:23,758 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:29:23,758 >>   Batch size = 8
OrderedDict([('best_epoch', 18), ('best_eval_accuracy', 0.8), ('epoch', 19.0)])
{'loss': 0.6874, 'learning_rate': 0.0075, 'epoch': 20.0}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.40it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.39it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:29:25 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 17%|█▋        | 500/3000 [04:29<19:53,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.43214863538742065, 'eval_accuracy': 0.8, 'eval_runtime': 1.5285, 'eval_samples_per_second': 65.425, 'eval_steps_per_second': 8.505, 'epoch': 20.0}
12/07/2022 13:29:25 - INFO - training.trainer_base - ***** Epoch 19: Best results *****
12/07/2022 13:29:25 - INFO - training.trainer_base - best_epoch = 18
12/07/2022 13:29:25 - INFO - training.trainer_base - best_eval_accuracy = 0.8
12/07/2022 13:29:25 - INFO - training.trainer_base - epoch = 19.0
                                                   17%|█▋        | 500/3000 [04:29<19:53,  2.10it/s] 17%|█▋        | 501/3000 [04:29<39:00,  1.07it/s] 17%|█▋        | 502/3000 [04:30<33:12,  1.25it/s] 17%|█▋        | 503/3000 [04:30<29:11,  1.43it/s] 17%|█▋        | 504/3000 [04:31<26:21,  1.58it/s] 17%|█▋        | 505/3000 [04:31<24:22,  1.71it/s] 17%|█▋        | 506/3000 [04:32<23:01,  1.81it/s] 17%|█▋        | 507/3000 [04:32<22:04,  1.88it/s] 17%|█▋        | 508/3000 [04:33<21:21,  1.95it/s] 17%|█▋        | 509/3000 [04:33<20:51,  1.99it/s] 17%|█▋        | 510/3000 [04:34<20:33,  2.02it/s] 17%|█▋        | 511/3000 [04:34<20:19,  2.04it/s] 17%|█▋        | 512/3000 [04:35<20:11,  2.05it/s] 17%|█▋        | 513/3000 [04:35<20:00,  2.07it/s] 17%|█▋        | 514/3000 [04:35<19:51,  2.09it/s] 17%|█▋        | 515/3000 [04:36<19:47,  2.09it/s] 17%|█▋        | 516/3000 [04:36<19:45,  2.09it/s] 17%|█▋        | 517/3000 [04:37<19:46,  2.09it/s] 17%|█▋        | 518/3000 [04:37<19:45,  2.09it/s] 17%|█▋        | 519/3000 [04:38<19:40,  2.10it/s] 17%|█▋        | 520/3000 [04:38<19:38,  2.10it/s] 17%|█▋        | 521/3000 [04:39<19:40,  2.10it/s] 17%|█▋        | 522/3000 [04:39<19:40,  2.10it/s] 17%|█▋        | 523/3000 [04:40<19:40,  2.10it/s] 17%|█▋        | 524/3000 [04:40<19:37,  2.10it/s] 18%|█▊        | 525/3000 [04:41<19:35,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:29:37,184 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:29:37,186 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:29:37,186 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:29:37,186 >>   Batch size = 8
OrderedDict([('best_epoch', 18), ('best_eval_accuracy', 0.8), ('epoch', 20.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.50it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.35it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:29:38 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 18%|█▊        | 525/3000 [04:42<19:35,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.41149330139160156, 'eval_accuracy': 0.79, 'eval_runtime': 1.533, 'eval_samples_per_second': 65.23, 'eval_steps_per_second': 8.48, 'epoch': 21.0}
12/07/2022 13:29:38 - INFO - training.trainer_base - ***** Epoch 20: Best results *****
12/07/2022 13:29:38 - INFO - training.trainer_base - best_epoch = 18
12/07/2022 13:29:38 - INFO - training.trainer_base - best_eval_accuracy = 0.8
12/07/2022 13:29:38 - INFO - training.trainer_base - epoch = 20.0
                                                   18%|█▊        | 525/3000 [04:42<19:35,  2.10it/s] 18%|█▊        | 526/3000 [04:43<38:37,  1.07it/s] 18%|█▊        | 527/3000 [04:43<32:57,  1.25it/s] 18%|█▊        | 528/3000 [04:44<28:58,  1.42it/s] 18%|█▊        | 529/3000 [04:44<26:10,  1.57it/s] 18%|█▊        | 530/3000 [04:45<24:12,  1.70it/s] 18%|█▊        | 531/3000 [04:45<22:47,  1.81it/s] 18%|█▊        | 532/3000 [04:46<21:46,  1.89it/s] 18%|█▊        | 533/3000 [04:46<21:08,  1.95it/s] 18%|█▊        | 534/3000 [04:47<20:41,  1.99it/s] 18%|█▊        | 535/3000 [04:47<20:21,  2.02it/s] 18%|█▊        | 536/3000 [04:47<20:03,  2.05it/s] 18%|█▊        | 537/3000 [04:48<19:51,  2.07it/s] 18%|█▊        | 538/3000 [04:48<19:42,  2.08it/s] 18%|█▊        | 539/3000 [04:49<19:38,  2.09it/s] 18%|█▊        | 540/3000 [04:49<19:39,  2.09it/s] 18%|█▊        | 541/3000 [04:50<19:39,  2.08it/s] 18%|█▊        | 542/3000 [04:50<19:35,  2.09it/s] 18%|█▊        | 543/3000 [04:51<19:30,  2.10it/s] 18%|█▊        | 544/3000 [04:51<19:29,  2.10it/s] 18%|█▊        | 545/3000 [04:52<19:28,  2.10it/s] 18%|█▊        | 546/3000 [04:52<19:29,  2.10it/s] 18%|█▊        | 547/3000 [04:53<19:29,  2.10it/s] 18%|█▊        | 548/3000 [04:53<19:27,  2.10it/s] 18%|█▊        | 549/3000 [04:54<19:25,  2.10it/s] 18%|█▊        | 550/3000 [04:54<19:24,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:29:50,623 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:29:50,624 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:29:50,624 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:29:50,624 >>   Batch size = 8
OrderedDict([('best_epoch', 18), ('best_eval_accuracy', 0.8), ('epoch', 21.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.48it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.30it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:29:52 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 18%|█▊        | 550/3000 [04:56<19:24,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.3859686255455017, 'eval_accuracy': 0.8, 'eval_runtime': 1.5283, 'eval_samples_per_second': 65.431, 'eval_steps_per_second': 8.506, 'epoch': 22.0}
12/07/2022 13:29:52 - INFO - training.trainer_base - ***** Epoch 21: Best results *****
12/07/2022 13:29:52 - INFO - training.trainer_base - best_epoch = 18
12/07/2022 13:29:52 - INFO - training.trainer_base - best_eval_accuracy = 0.8
12/07/2022 13:29:52 - INFO - training.trainer_base - epoch = 21.0
                                                   18%|█▊        | 550/3000 [04:56<19:24,  2.10it/s] 18%|█▊        | 551/3000 [04:56<38:08,  1.07it/s] 18%|█▊        | 552/3000 [04:57<32:32,  1.25it/s] 18%|█▊        | 553/3000 [04:57<28:34,  1.43it/s] 18%|█▊        | 554/3000 [04:58<25:47,  1.58it/s] 18%|█▊        | 555/3000 [04:58<23:50,  1.71it/s] 19%|█▊        | 556/3000 [04:59<22:28,  1.81it/s] 19%|█▊        | 557/3000 [04:59<21:32,  1.89it/s] 19%|█▊        | 558/3000 [04:59<20:54,  1.95it/s] 19%|█▊        | 559/3000 [05:00<20:27,  1.99it/s] 19%|█▊        | 560/3000 [05:00<20:08,  2.02it/s] 19%|█▊        | 561/3000 [05:01<19:54,  2.04it/s] 19%|█▊        | 562/3000 [05:01<19:46,  2.05it/s] 19%|█▉        | 563/3000 [05:02<19:39,  2.07it/s] 19%|█▉        | 564/3000 [05:02<19:33,  2.08it/s] 19%|█▉        | 565/3000 [05:03<19:27,  2.09it/s] 19%|█▉        | 566/3000 [05:03<19:26,  2.09it/s] 19%|█▉        | 567/3000 [05:04<19:25,  2.09it/s] 19%|█▉        | 568/3000 [05:04<19:26,  2.09it/s] 19%|█▉        | 569/3000 [05:05<19:20,  2.10it/s] 19%|█▉        | 570/3000 [05:05<19:17,  2.10it/s] 19%|█▉        | 571/3000 [05:06<19:18,  2.10it/s] 19%|█▉        | 572/3000 [05:06<19:17,  2.10it/s] 19%|█▉        | 573/3000 [05:07<19:17,  2.10it/s] 19%|█▉        | 574/3000 [05:07<19:17,  2.10it/s] 19%|█▉        | 575/3000 [05:08<19:14,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:30:04,063 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:30:04,065 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:30:04,065 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:30:04,065 >>   Batch size = 8
OrderedDict([('best_epoch', 18), ('best_eval_accuracy', 0.8), ('epoch', 22.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.33it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.23it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.80it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.67it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.45it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.39it/s][A12/07/2022 13:30:05 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 19%|█▉        | 575/3000 [05:09<19:14,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.39it/s][A
                                               [A{'eval_loss': 0.4263538420200348, 'eval_accuracy': 0.82, 'eval_runtime': 1.5345, 'eval_samples_per_second': 65.169, 'eval_steps_per_second': 8.472, 'epoch': 23.0}
12/07/2022 13:30:05 - INFO - training.trainer_base - ***** Epoch 22: Best results *****
12/07/2022 13:30:05 - INFO - training.trainer_base - best_epoch = 22
12/07/2022 13:30:05 - INFO - training.trainer_base - best_eval_accuracy = 0.82
12/07/2022 13:30:05 - INFO - training.trainer_base - epoch = 22.0
                                                   19%|█▉        | 575/3000 [05:09<19:14,  2.10it/s] 19%|█▉        | 576/3000 [05:10<37:53,  1.07it/s] 19%|█▉        | 577/3000 [05:10<32:18,  1.25it/s] 19%|█▉        | 578/3000 [05:11<28:23,  1.42it/s] 19%|█▉        | 579/3000 [05:11<25:36,  1.58it/s] 19%|█▉        | 580/3000 [05:12<23:38,  1.71it/s] 19%|█▉        | 581/3000 [05:12<22:19,  1.81it/s] 19%|█▉        | 582/3000 [05:12<21:24,  1.88it/s] 19%|█▉        | 583/3000 [05:13<20:45,  1.94it/s] 19%|█▉        | 584/3000 [05:13<20:15,  1.99it/s] 20%|█▉        | 585/3000 [05:14<19:54,  2.02it/s] 20%|█▉        | 586/3000 [05:14<19:40,  2.04it/s] 20%|█▉        | 587/3000 [05:15<19:31,  2.06it/s] 20%|█▉        | 588/3000 [05:15<19:26,  2.07it/s] 20%|█▉        | 589/3000 [05:16<19:20,  2.08it/s] 20%|█▉        | 590/3000 [05:16<19:14,  2.09it/s] 20%|█▉        | 591/3000 [05:17<19:13,  2.09it/s] 20%|█▉        | 592/3000 [05:17<19:10,  2.09it/s] 20%|█▉        | 593/3000 [05:18<19:09,  2.09it/s] 20%|█▉        | 594/3000 [05:18<19:06,  2.10it/s] 20%|█▉        | 595/3000 [05:19<19:05,  2.10it/s] 20%|█▉        | 596/3000 [05:19<19:03,  2.10it/s] 20%|█▉        | 597/3000 [05:20<19:02,  2.10it/s] 20%|█▉        | 598/3000 [05:20<19:03,  2.10it/s] 20%|█▉        | 599/3000 [05:21<19:05,  2.10it/s] 20%|██        | 600/3000 [05:21<19:06,  2.09it/s][INFO|trainer.py:540] 2022-12-07 13:30:17,514 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:30:17,516 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:30:17,517 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:30:17,517 >>   Batch size = 8
OrderedDict([('best_epoch', 22), ('best_eval_accuracy', 0.82), ('epoch', 23.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.62it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.35it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.72it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:30:19 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 20%|██        | 600/3000 [05:23<19:06,  2.09it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.4759376049041748, 'eval_accuracy': 0.81, 'eval_runtime': 1.5295, 'eval_samples_per_second': 65.38, 'eval_steps_per_second': 8.499, 'epoch': 24.0}
12/07/2022 13:30:19 - INFO - training.trainer_base - ***** Epoch 23: Best results *****
12/07/2022 13:30:19 - INFO - training.trainer_base - best_epoch = 22
12/07/2022 13:30:19 - INFO - training.trainer_base - best_eval_accuracy = 0.82
12/07/2022 13:30:19 - INFO - training.trainer_base - epoch = 23.0
                                                   20%|██        | 600/3000 [05:23<19:06,  2.09it/s] 20%|██        | 601/3000 [05:23<37:31,  1.07it/s] 20%|██        | 602/3000 [05:24<31:56,  1.25it/s] 20%|██        | 603/3000 [05:24<27:59,  1.43it/s] 20%|██        | 604/3000 [05:24<25:18,  1.58it/s] 20%|██        | 605/3000 [05:25<23:25,  1.70it/s] 20%|██        | 606/3000 [05:25<22:04,  1.81it/s] 20%|██        | 607/3000 [05:26<21:07,  1.89it/s] 20%|██        | 608/3000 [05:26<20:27,  1.95it/s] 20%|██        | 609/3000 [05:27<19:58,  1.99it/s] 20%|██        | 610/3000 [05:27<19:40,  2.02it/s] 20%|██        | 611/3000 [05:28<19:29,  2.04it/s] 20%|██        | 612/3000 [05:28<19:16,  2.06it/s] 20%|██        | 613/3000 [05:29<19:07,  2.08it/s] 20%|██        | 614/3000 [05:29<19:02,  2.09it/s] 20%|██        | 615/3000 [05:30<19:00,  2.09it/s] 21%|██        | 616/3000 [05:30<19:00,  2.09it/s] 21%|██        | 617/3000 [05:31<18:59,  2.09it/s] 21%|██        | 618/3000 [05:31<18:54,  2.10it/s] 21%|██        | 619/3000 [05:32<18:50,  2.11it/s] 21%|██        | 620/3000 [05:32<18:50,  2.11it/s] 21%|██        | 621/3000 [05:33<18:51,  2.10it/s] 21%|██        | 622/3000 [05:33<18:53,  2.10it/s] 21%|██        | 623/3000 [05:34<18:53,  2.10it/s] 21%|██        | 624/3000 [05:34<18:49,  2.10it/s] 21%|██        | 625/3000 [05:34<18:46,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:30:30,930 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:30:30,931 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:30:30,931 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:30:30,931 >>   Batch size = 8
OrderedDict([('best_epoch', 22), ('best_eval_accuracy', 0.82), ('epoch', 24.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.51it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.67it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:30:32 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 21%|██        | 625/3000 [05:36<18:46,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.4076060950756073, 'eval_accuracy': 0.84, 'eval_runtime': 1.5299, 'eval_samples_per_second': 65.363, 'eval_steps_per_second': 8.497, 'epoch': 25.0}
12/07/2022 13:30:32 - INFO - training.trainer_base - ***** Epoch 24: Best results *****
12/07/2022 13:30:32 - INFO - training.trainer_base - best_epoch = 24
12/07/2022 13:30:32 - INFO - training.trainer_base - best_eval_accuracy = 0.84
12/07/2022 13:30:32 - INFO - training.trainer_base - epoch = 24.0
                                                   21%|██        | 625/3000 [05:36<18:46,  2.11it/s] 21%|██        | 626/3000 [05:36<36:58,  1.07it/s] 21%|██        | 627/3000 [05:37<31:32,  1.25it/s] 21%|██        | 628/3000 [05:37<27:45,  1.42it/s] 21%|██        | 629/3000 [05:38<25:05,  1.58it/s] 21%|██        | 630/3000 [05:38<23:10,  1.70it/s] 21%|██        | 631/3000 [05:39<21:50,  1.81it/s] 21%|██        | 632/3000 [05:39<20:57,  1.88it/s] 21%|██        | 633/3000 [05:40<20:19,  1.94it/s] 21%|██        | 634/3000 [05:40<19:48,  1.99it/s] 21%|██        | 635/3000 [05:41<19:27,  2.03it/s] 21%|██        | 636/3000 [05:41<19:12,  2.05it/s] 21%|██        | 637/3000 [05:42<19:03,  2.07it/s] 21%|██▏       | 638/3000 [05:42<18:56,  2.08it/s] 21%|██▏       | 639/3000 [05:43<18:54,  2.08it/s] 21%|██▏       | 640/3000 [05:43<18:49,  2.09it/s] 21%|██▏       | 641/3000 [05:44<18:45,  2.10it/s] 21%|██▏       | 642/3000 [05:44<18:41,  2.10it/s] 21%|██▏       | 643/3000 [05:45<18:40,  2.10it/s] 21%|██▏       | 644/3000 [05:45<18:41,  2.10it/s] 22%|██▏       | 645/3000 [05:46<18:43,  2.10it/s] 22%|██▏       | 646/3000 [05:46<18:42,  2.10it/s] 22%|██▏       | 647/3000 [05:46<18:39,  2.10it/s] 22%|██▏       | 648/3000 [05:47<18:36,  2.11it/s] 22%|██▏       | 649/3000 [05:47<18:36,  2.11it/s] 22%|██▏       | 650/3000 [05:48<18:37,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:30:44,355 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:30:44,356 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:30:44,356 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:30:44,356 >>   Batch size = 8
OrderedDict([('best_epoch', 24), ('best_eval_accuracy', 0.84), ('epoch', 25.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.30it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.34it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.24it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.81it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.67it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:30:45 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 22%|██▏       | 650/3000 [05:49<18:37,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.3874576985836029, 'eval_accuracy': 0.83, 'eval_runtime': 1.5324, 'eval_samples_per_second': 65.257, 'eval_steps_per_second': 8.483, 'epoch': 26.0}
12/07/2022 13:30:45 - INFO - training.trainer_base - ***** Epoch 25: Best results *****
12/07/2022 13:30:45 - INFO - training.trainer_base - best_epoch = 24
12/07/2022 13:30:45 - INFO - training.trainer_base - best_eval_accuracy = 0.84
12/07/2022 13:30:45 - INFO - training.trainer_base - epoch = 25.0
                                                   22%|██▏       | 650/3000 [05:49<18:37,  2.10it/s] 22%|██▏       | 651/3000 [05:50<36:41,  1.07it/s] 22%|██▏       | 652/3000 [05:50<31:14,  1.25it/s] 22%|██▏       | 653/3000 [05:51<27:22,  1.43it/s] 22%|██▏       | 654/3000 [05:51<24:43,  1.58it/s] 22%|██▏       | 655/3000 [05:52<22:52,  1.71it/s] 22%|██▏       | 656/3000 [05:52<21:37,  1.81it/s] 22%|██▏       | 657/3000 [05:53<20:42,  1.89it/s] 22%|██▏       | 658/3000 [05:53<20:01,  1.95it/s] 22%|██▏       | 659/3000 [05:54<19:35,  1.99it/s] 22%|██▏       | 660/3000 [05:54<19:16,  2.02it/s] 22%|██▏       | 661/3000 [05:55<19:03,  2.05it/s] 22%|██▏       | 662/3000 [05:55<18:55,  2.06it/s] 22%|██▏       | 663/3000 [05:56<18:48,  2.07it/s] 22%|██▏       | 664/3000 [05:56<18:41,  2.08it/s] 22%|██▏       | 665/3000 [05:57<18:35,  2.09it/s] 22%|██▏       | 666/3000 [05:57<18:33,  2.10it/s] 22%|██▏       | 667/3000 [05:58<18:34,  2.09it/s] 22%|██▏       | 668/3000 [05:58<18:32,  2.10it/s] 22%|██▏       | 669/3000 [05:58<18:28,  2.10it/s] 22%|██▏       | 670/3000 [05:59<18:26,  2.11it/s] 22%|██▏       | 671/3000 [05:59<18:26,  2.10it/s] 22%|██▏       | 672/3000 [06:00<18:28,  2.10it/s] 22%|██▏       | 673/3000 [06:00<18:26,  2.10it/s] 22%|██▏       | 674/3000 [06:01<18:24,  2.11it/s] 22%|██▎       | 675/3000 [06:01<18:21,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:30:57,769 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:30:57,770 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:30:57,770 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:30:57,770 >>   Batch size = 8
OrderedDict([('best_epoch', 24), ('best_eval_accuracy', 0.84), ('epoch', 26.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.49it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.81it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.66it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.53it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.43it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.37it/s][A12/07/2022 13:30:59 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 22%|██▎       | 675/3000 [06:03<18:21,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.37it/s][A
                                               [A{'eval_loss': 0.41675865650177, 'eval_accuracy': 0.81, 'eval_runtime': 1.5343, 'eval_samples_per_second': 65.178, 'eval_steps_per_second': 8.473, 'epoch': 27.0}
12/07/2022 13:30:59 - INFO - training.trainer_base - ***** Epoch 26: Best results *****
12/07/2022 13:30:59 - INFO - training.trainer_base - best_epoch = 24
12/07/2022 13:30:59 - INFO - training.trainer_base - best_eval_accuracy = 0.84
12/07/2022 13:30:59 - INFO - training.trainer_base - epoch = 26.0
                                                   22%|██▎       | 675/3000 [06:03<18:21,  2.11it/s] 23%|██▎       | 676/3000 [06:03<36:13,  1.07it/s] 23%|██▎       | 677/3000 [06:04<30:53,  1.25it/s] 23%|██▎       | 678/3000 [06:04<27:11,  1.42it/s] 23%|██▎       | 679/3000 [06:05<24:32,  1.58it/s] 23%|██▎       | 680/3000 [06:05<22:40,  1.71it/s] 23%|██▎       | 681/3000 [06:06<21:19,  1.81it/s] 23%|██▎       | 682/3000 [06:06<20:25,  1.89it/s] 23%|██▎       | 683/3000 [06:07<19:49,  1.95it/s] 23%|██▎       | 684/3000 [06:07<19:22,  1.99it/s] 23%|██▎       | 685/3000 [06:08<19:01,  2.03it/s] 23%|██▎       | 686/3000 [06:08<18:49,  2.05it/s] 23%|██▎       | 687/3000 [06:09<18:42,  2.06it/s] 23%|██▎       | 688/3000 [06:09<18:38,  2.07it/s] 23%|██▎       | 689/3000 [06:09<18:30,  2.08it/s] 23%|██▎       | 690/3000 [06:10<18:24,  2.09it/s] 23%|██▎       | 691/3000 [06:10<18:21,  2.10it/s] 23%|██▎       | 692/3000 [06:11<18:18,  2.10it/s] 23%|██▎       | 693/3000 [06:11<18:18,  2.10it/s] 23%|██▎       | 694/3000 [06:12<18:19,  2.10it/s] 23%|██▎       | 695/3000 [06:12<18:16,  2.10it/s] 23%|██▎       | 696/3000 [06:13<18:15,  2.10it/s] 23%|██▎       | 697/3000 [06:13<18:15,  2.10it/s] 23%|██▎       | 698/3000 [06:14<18:15,  2.10it/s] 23%|██▎       | 699/3000 [06:14<18:15,  2.10it/s] 23%|██▎       | 700/3000 [06:15<18:13,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:31:11,194 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:31:11,195 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:31:11,195 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:31:11,195 >>   Batch size = 8
OrderedDict([('best_epoch', 24), ('best_eval_accuracy', 0.84), ('epoch', 27.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.44it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.32it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.40it/s][A12/07/2022 13:31:12 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 23%|██▎       | 700/3000 [06:16<18:13,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.40it/s][A
                                               [A{'eval_loss': 0.49389538168907166, 'eval_accuracy': 0.88, 'eval_runtime': 1.5377, 'eval_samples_per_second': 65.034, 'eval_steps_per_second': 8.454, 'epoch': 28.0}
12/07/2022 13:31:12 - INFO - training.trainer_base - ***** Epoch 27: Best results *****
12/07/2022 13:31:12 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:31:12 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:31:12 - INFO - training.trainer_base - epoch = 27.0
                                                   23%|██▎       | 700/3000 [06:16<18:13,  2.10it/s] 23%|██▎       | 701/3000 [06:17<36:02,  1.06it/s] 23%|██▎       | 702/3000 [06:17<30:42,  1.25it/s] 23%|██▎       | 703/3000 [06:18<26:58,  1.42it/s] 23%|██▎       | 704/3000 [06:18<24:19,  1.57it/s] 24%|██▎       | 705/3000 [06:19<22:27,  1.70it/s] 24%|██▎       | 706/3000 [06:19<21:09,  1.81it/s] 24%|██▎       | 707/3000 [06:20<20:16,  1.88it/s] 24%|██▎       | 708/3000 [06:20<19:39,  1.94it/s] 24%|██▎       | 709/3000 [06:21<19:13,  1.99it/s] 24%|██▎       | 710/3000 [06:21<18:52,  2.02it/s] 24%|██▎       | 711/3000 [06:22<18:39,  2.05it/s] 24%|██▎       | 712/3000 [06:22<18:29,  2.06it/s] 24%|██▍       | 713/3000 [06:22<18:24,  2.07it/s] 24%|██▍       | 714/3000 [06:23<18:19,  2.08it/s] 24%|██▍       | 715/3000 [06:23<18:13,  2.09it/s] 24%|██▍       | 716/3000 [06:24<18:09,  2.10it/s] 24%|██▍       | 717/3000 [06:24<18:08,  2.10it/s] 24%|██▍       | 718/3000 [06:25<18:07,  2.10it/s] 24%|██▍       | 719/3000 [06:25<18:08,  2.10it/s] 24%|██▍       | 720/3000 [06:26<18:04,  2.10it/s] 24%|██▍       | 721/3000 [06:26<18:03,  2.10it/s] 24%|██▍       | 722/3000 [06:27<18:02,  2.10it/s] 24%|██▍       | 723/3000 [06:27<18:03,  2.10it/s] 24%|██▍       | 724/3000 [06:28<18:05,  2.10it/s] 24%|██▍       | 725/3000 [06:28<18:04,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:31:24,644 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:31:24,646 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:31:24,646 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:31:24,646 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 28.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.45it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:31:26 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 24%|██▍       | 725/3000 [06:30<18:04,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.48352256417274475, 'eval_accuracy': 0.87, 'eval_runtime': 1.5281, 'eval_samples_per_second': 65.442, 'eval_steps_per_second': 8.507, 'epoch': 29.0}
12/07/2022 13:31:26 - INFO - training.trainer_base - ***** Epoch 28: Best results *****
12/07/2022 13:31:26 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:31:26 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:31:26 - INFO - training.trainer_base - epoch = 28.0
                                                   24%|██▍       | 725/3000 [06:30<18:04,  2.10it/s] 24%|██▍       | 726/3000 [06:30<35:28,  1.07it/s] 24%|██▍       | 727/3000 [06:31<30:11,  1.25it/s] 24%|██▍       | 728/3000 [06:31<26:32,  1.43it/s] 24%|██▍       | 729/3000 [06:32<23:58,  1.58it/s] 24%|██▍       | 730/3000 [06:32<22:13,  1.70it/s] 24%|██▍       | 731/3000 [06:33<20:57,  1.80it/s] 24%|██▍       | 732/3000 [06:33<20:03,  1.88it/s] 24%|██▍       | 733/3000 [06:34<19:24,  1.95it/s] 24%|██▍       | 734/3000 [06:34<18:56,  1.99it/s] 24%|██▍       | 735/3000 [06:34<18:37,  2.03it/s] 25%|██▍       | 736/3000 [06:35<18:27,  2.04it/s] 25%|██▍       | 737/3000 [06:35<18:16,  2.06it/s] 25%|██▍       | 738/3000 [06:36<18:07,  2.08it/s] 25%|██▍       | 739/3000 [06:36<18:02,  2.09it/s] 25%|██▍       | 740/3000 [06:37<17:59,  2.09it/s] 25%|██▍       | 741/3000 [06:37<17:57,  2.10it/s] 25%|██▍       | 742/3000 [06:38<17:59,  2.09it/s] 25%|██▍       | 743/3000 [06:38<17:57,  2.09it/s] 25%|██▍       | 744/3000 [06:39<17:54,  2.10it/s] 25%|██▍       | 745/3000 [06:39<17:53,  2.10it/s] 25%|██▍       | 746/3000 [06:40<17:53,  2.10it/s] 25%|██▍       | 747/3000 [06:40<17:55,  2.10it/s] 25%|██▍       | 748/3000 [06:41<17:53,  2.10it/s] 25%|██▍       | 749/3000 [06:41<17:49,  2.11it/s] 25%|██▌       | 750/3000 [06:42<17:48,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:31:38,064 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:31:38,065 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:31:38,065 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:31:38,065 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 29.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.38it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.36it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:31:39 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 25%|██▌       | 750/3000 [06:43<17:48,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.5066179037094116, 'eval_accuracy': 0.85, 'eval_runtime': 1.53, 'eval_samples_per_second': 65.361, 'eval_steps_per_second': 8.497, 'epoch': 30.0}
12/07/2022 13:31:39 - INFO - training.trainer_base - ***** Epoch 29: Best results *****
12/07/2022 13:31:39 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:31:39 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:31:39 - INFO - training.trainer_base - epoch = 29.0
                                                   25%|██▌       | 750/3000 [06:43<17:48,  2.11it/s] 25%|██▌       | 751/3000 [06:44<35:02,  1.07it/s] 25%|██▌       | 752/3000 [06:44<29:52,  1.25it/s] 25%|██▌       | 753/3000 [06:45<26:17,  1.42it/s] 25%|██▌       | 754/3000 [06:45<23:44,  1.58it/s] 25%|██▌       | 755/3000 [06:46<21:54,  1.71it/s] 25%|██▌       | 756/3000 [06:46<20:39,  1.81it/s] 25%|██▌       | 757/3000 [06:46<19:47,  1.89it/s] 25%|██▌       | 758/3000 [06:47<19:10,  1.95it/s] 25%|██▌       | 759/3000 [06:47<18:47,  1.99it/s] 25%|██▌       | 760/3000 [06:48<18:27,  2.02it/s] 25%|██▌       | 761/3000 [06:48<18:13,  2.05it/s] 25%|██▌       | 762/3000 [06:49<18:05,  2.06it/s] 25%|██▌       | 763/3000 [06:49<18:00,  2.07it/s] 25%|██▌       | 764/3000 [06:50<17:56,  2.08it/s] 26%|██▌       | 765/3000 [06:50<17:52,  2.08it/s] 26%|██▌       | 766/3000 [06:51<17:47,  2.09it/s] 26%|██▌       | 767/3000 [06:51<17:45,  2.10it/s] 26%|██▌       | 768/3000 [06:52<17:45,  2.09it/s] 26%|██▌       | 769/3000 [06:52<17:45,  2.09it/s] 26%|██▌       | 770/3000 [06:53<17:43,  2.10it/s] 26%|██▌       | 771/3000 [06:53<17:41,  2.10it/s] 26%|██▌       | 772/3000 [06:54<17:39,  2.10it/s] 26%|██▌       | 773/3000 [06:54<17:37,  2.11it/s] 26%|██▌       | 774/3000 [06:55<17:39,  2.10it/s] 26%|██▌       | 775/3000 [06:55<17:40,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:31:51,498 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:31:51,499 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:31:51,499 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:31:51,499 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 30.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.45it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.43it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.30it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:31:53 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 26%|██▌       | 775/3000 [06:57<17:40,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.5194131731987, 'eval_accuracy': 0.87, 'eval_runtime': 1.529, 'eval_samples_per_second': 65.403, 'eval_steps_per_second': 8.502, 'epoch': 31.0}
12/07/2022 13:31:53 - INFO - training.trainer_base - ***** Epoch 30: Best results *****
12/07/2022 13:31:53 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:31:53 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:31:53 - INFO - training.trainer_base - epoch = 30.0
                                                   26%|██▌       | 775/3000 [06:57<17:40,  2.10it/s] 26%|██▌       | 776/3000 [06:57<34:43,  1.07it/s] 26%|██▌       | 777/3000 [06:58<29:34,  1.25it/s] 26%|██▌       | 778/3000 [06:58<25:56,  1.43it/s] 26%|██▌       | 779/3000 [06:58<23:23,  1.58it/s] 26%|██▌       | 780/3000 [06:59<21:37,  1.71it/s] 26%|██▌       | 781/3000 [06:59<20:24,  1.81it/s] 26%|██▌       | 782/3000 [07:00<19:35,  1.89it/s] 26%|██▌       | 783/3000 [07:00<18:58,  1.95it/s] 26%|██▌       | 784/3000 [07:01<18:31,  1.99it/s] 26%|██▌       | 785/3000 [07:01<18:12,  2.03it/s] 26%|██▌       | 786/3000 [07:02<17:59,  2.05it/s] 26%|██▌       | 787/3000 [07:02<17:54,  2.06it/s] 26%|██▋       | 788/3000 [07:03<17:49,  2.07it/s] 26%|██▋       | 789/3000 [07:03<17:42,  2.08it/s] 26%|██▋       | 790/3000 [07:04<17:38,  2.09it/s] 26%|██▋       | 791/3000 [07:04<17:36,  2.09it/s] 26%|██▋       | 792/3000 [07:05<17:35,  2.09it/s] 26%|██▋       | 793/3000 [07:05<17:34,  2.09it/s] 26%|██▋       | 794/3000 [07:06<17:32,  2.10it/s] 26%|██▋       | 795/3000 [07:06<17:30,  2.10it/s] 27%|██▋       | 796/3000 [07:07<17:27,  2.10it/s] 27%|██▋       | 797/3000 [07:07<17:26,  2.10it/s] 27%|██▋       | 798/3000 [07:07<17:27,  2.10it/s] 27%|██▋       | 799/3000 [07:08<17:29,  2.10it/s] 27%|██▋       | 800/3000 [07:08<17:28,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:32:04,924 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:32:04,925 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:32:04,926 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:32:04,926 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 31.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.45it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:32:06 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 27%|██▋       | 800/3000 [07:10<17:28,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.5290361046791077, 'eval_accuracy': 0.87, 'eval_runtime': 1.5291, 'eval_samples_per_second': 65.396, 'eval_steps_per_second': 8.502, 'epoch': 32.0}
12/07/2022 13:32:06 - INFO - training.trainer_base - ***** Epoch 31: Best results *****
12/07/2022 13:32:06 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:32:06 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:32:06 - INFO - training.trainer_base - epoch = 31.0
                                                   27%|██▋       | 800/3000 [07:10<17:28,  2.10it/s] 27%|██▋       | 801/3000 [07:10<34:19,  1.07it/s] 27%|██▋       | 802/3000 [07:11<29:13,  1.25it/s] 27%|██▋       | 803/3000 [07:11<25:39,  1.43it/s] 27%|██▋       | 804/3000 [07:12<23:11,  1.58it/s] 27%|██▋       | 805/3000 [07:12<21:30,  1.70it/s] 27%|██▋       | 806/3000 [07:13<20:15,  1.80it/s] 27%|██▋       | 807/3000 [07:13<19:21,  1.89it/s] 27%|██▋       | 808/3000 [07:14<18:46,  1.95it/s] 27%|██▋       | 809/3000 [07:14<18:20,  1.99it/s] 27%|██▋       | 810/3000 [07:15<18:03,  2.02it/s] 27%|██▋       | 811/3000 [07:15<17:52,  2.04it/s] 27%|██▋       | 812/3000 [07:16<17:41,  2.06it/s] 27%|██▋       | 813/3000 [07:16<17:35,  2.07it/s] 27%|██▋       | 814/3000 [07:17<17:32,  2.08it/s] 27%|██▋       | 815/3000 [07:17<17:28,  2.08it/s] 27%|██▋       | 816/3000 [07:18<17:27,  2.09it/s] 27%|██▋       | 817/3000 [07:18<17:25,  2.09it/s] 27%|██▋       | 818/3000 [07:19<17:21,  2.09it/s] 27%|██▋       | 819/3000 [07:19<17:19,  2.10it/s] 27%|██▋       | 820/3000 [07:20<17:18,  2.10it/s] 27%|██▋       | 821/3000 [07:20<17:18,  2.10it/s] 27%|██▋       | 822/3000 [07:20<17:16,  2.10it/s] 27%|██▋       | 823/3000 [07:21<17:12,  2.11it/s] 27%|██▋       | 824/3000 [07:21<17:13,  2.11it/s] 28%|██▊       | 825/3000 [07:22<17:15,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:32:18,360 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:32:18,361 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:32:18,361 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:32:18,361 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 32.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.43it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:32:19 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 28%|██▊       | 825/3000 [07:23<17:15,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.575102686882019, 'eval_accuracy': 0.86, 'eval_runtime': 1.5317, 'eval_samples_per_second': 65.289, 'eval_steps_per_second': 8.488, 'epoch': 33.0}
12/07/2022 13:32:19 - INFO - training.trainer_base - ***** Epoch 32: Best results *****
12/07/2022 13:32:19 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:32:19 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:32:19 - INFO - training.trainer_base - epoch = 32.0
                                                   28%|██▊       | 825/3000 [07:23<17:15,  2.10it/s] 28%|██▊       | 826/3000 [07:24<34:06,  1.06it/s] 28%|██▊       | 827/3000 [07:24<29:04,  1.25it/s] 28%|██▊       | 828/3000 [07:25<25:29,  1.42it/s] 28%|██▊       | 829/3000 [07:25<23:01,  1.57it/s] 28%|██▊       | 830/3000 [07:26<21:17,  1.70it/s] 28%|██▊       | 831/3000 [07:26<20:05,  1.80it/s] 28%|██▊       | 832/3000 [07:27<19:10,  1.88it/s] 28%|██▊       | 833/3000 [07:27<18:34,  1.95it/s] 28%|██▊       | 834/3000 [07:28<18:10,  1.99it/s] 28%|██▊       | 835/3000 [07:28<17:54,  2.01it/s] 28%|██▊       | 836/3000 [07:29<17:41,  2.04it/s] 28%|██▊       | 837/3000 [07:29<17:28,  2.06it/s] 28%|██▊       | 838/3000 [07:30<17:21,  2.08it/s] 28%|██▊       | 839/3000 [07:30<17:19,  2.08it/s] 28%|██▊       | 840/3000 [07:31<17:14,  2.09it/s] 28%|██▊       | 841/3000 [07:31<17:14,  2.09it/s] 28%|██▊       | 842/3000 [07:32<17:09,  2.10it/s] 28%|██▊       | 843/3000 [07:32<17:06,  2.10it/s] 28%|██▊       | 844/3000 [07:32<17:06,  2.10it/s] 28%|██▊       | 845/3000 [07:33<17:06,  2.10it/s] 28%|██▊       | 846/3000 [07:33<17:06,  2.10it/s] 28%|██▊       | 847/3000 [07:34<17:05,  2.10it/s] 28%|██▊       | 848/3000 [07:34<17:04,  2.10it/s] 28%|██▊       | 849/3000 [07:35<17:02,  2.10it/s] 28%|██▊       | 850/3000 [07:35<17:02,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:32:31,814 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:32:31,815 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:32:31,815 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:32:31,815 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 33.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.48it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.31it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.24it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:32:33 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 28%|██▊       | 850/3000 [07:37<17:02,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.5415397882461548, 'eval_accuracy': 0.86, 'eval_runtime': 1.5364, 'eval_samples_per_second': 65.088, 'eval_steps_per_second': 8.461, 'epoch': 34.0}
12/07/2022 13:32:33 - INFO - training.trainer_base - ***** Epoch 33: Best results *****
12/07/2022 13:32:33 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:32:33 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:32:33 - INFO - training.trainer_base - epoch = 33.0
                                                   28%|██▊       | 850/3000 [07:37<17:02,  2.10it/s] 28%|██▊       | 851/3000 [07:37<33:42,  1.06it/s] 28%|██▊       | 852/3000 [07:38<28:44,  1.25it/s] 28%|██▊       | 853/3000 [07:38<25:15,  1.42it/s] 28%|██▊       | 854/3000 [07:39<22:45,  1.57it/s] 28%|██▊       | 855/3000 [07:39<20:59,  1.70it/s] 29%|██▊       | 856/3000 [07:40<19:46,  1.81it/s] 29%|██▊       | 857/3000 [07:40<18:56,  1.89it/s] 29%|██▊       | 858/3000 [07:41<18:24,  1.94it/s] 29%|██▊       | 859/3000 [07:41<17:58,  1.98it/s] 29%|██▊       | 860/3000 [07:42<17:37,  2.02it/s] 29%|██▊       | 861/3000 [07:42<17:23,  2.05it/s] 29%|██▊       | 862/3000 [07:43<17:16,  2.06it/s] 29%|██▉       | 863/3000 [07:43<17:11,  2.07it/s] 29%|██▉       | 864/3000 [07:44<17:09,  2.08it/s] 29%|██▉       | 865/3000 [07:44<17:05,  2.08it/s] 29%|██▉       | 866/3000 [07:45<17:01,  2.09it/s] 29%|██▉       | 867/3000 [07:45<16:57,  2.10it/s] 29%|██▉       | 868/3000 [07:45<16:54,  2.10it/s] 29%|██▉       | 869/3000 [07:46<16:56,  2.10it/s] 29%|██▉       | 870/3000 [07:46<16:55,  2.10it/s] 29%|██▉       | 871/3000 [07:47<16:54,  2.10it/s] 29%|██▉       | 872/3000 [07:47<16:52,  2.10it/s] 29%|██▉       | 873/3000 [07:48<16:51,  2.10it/s] 29%|██▉       | 874/3000 [07:48<16:52,  2.10it/s] 29%|██▉       | 875/3000 [07:49<16:52,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:32:45,268 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:32:45,270 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:32:45,270 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:32:45,270 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 34.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.44it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.30it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:32:46 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 29%|██▉       | 875/3000 [07:50<16:52,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.5947104096412659, 'eval_accuracy': 0.85, 'eval_runtime': 1.5294, 'eval_samples_per_second': 65.384, 'eval_steps_per_second': 8.5, 'epoch': 35.0}
12/07/2022 13:32:46 - INFO - training.trainer_base - ***** Epoch 34: Best results *****
12/07/2022 13:32:46 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:32:46 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:32:46 - INFO - training.trainer_base - epoch = 34.0
                                                   29%|██▉       | 875/3000 [07:50<16:52,  2.10it/s] 29%|██▉       | 876/3000 [07:51<33:09,  1.07it/s] 29%|██▉       | 877/3000 [07:51<28:13,  1.25it/s] 29%|██▉       | 878/3000 [07:52<24:46,  1.43it/s] 29%|██▉       | 879/3000 [07:52<22:22,  1.58it/s] 29%|██▉       | 880/3000 [07:53<20:41,  1.71it/s] 29%|██▉       | 881/3000 [07:53<19:33,  1.81it/s] 29%|██▉       | 882/3000 [07:54<18:44,  1.88it/s] 29%|██▉       | 883/3000 [07:54<18:09,  1.94it/s] 29%|██▉       | 884/3000 [07:55<17:42,  1.99it/s] 30%|██▉       | 885/3000 [07:55<17:24,  2.02it/s] 30%|██▉       | 886/3000 [07:56<17:11,  2.05it/s] 30%|██▉       | 887/3000 [07:56<17:03,  2.07it/s] 30%|██▉       | 888/3000 [07:57<16:56,  2.08it/s] 30%|██▉       | 889/3000 [07:57<16:50,  2.09it/s] 30%|██▉       | 890/3000 [07:57<16:47,  2.10it/s] 30%|██▉       | 891/3000 [07:58<16:45,  2.10it/s] 30%|██▉       | 892/3000 [07:58<16:43,  2.10it/s] 30%|██▉       | 893/3000 [07:59<16:40,  2.10it/s] 30%|██▉       | 894/3000 [07:59<16:37,  2.11it/s] 30%|██▉       | 895/3000 [08:00<16:37,  2.11it/s] 30%|██▉       | 896/3000 [08:00<16:37,  2.11it/s] 30%|██▉       | 897/3000 [08:01<16:38,  2.11it/s] 30%|██▉       | 898/3000 [08:01<16:36,  2.11it/s] 30%|██▉       | 899/3000 [08:02<16:34,  2.11it/s] 30%|███       | 900/3000 [08:02<16:35,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:32:58,668 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:32:58,669 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:32:58,669 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:32:58,669 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 35.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.43it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.31it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:33:00 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 30%|███       | 900/3000 [08:04<16:35,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.5796974301338196, 'eval_accuracy': 0.87, 'eval_runtime': 1.5304, 'eval_samples_per_second': 65.342, 'eval_steps_per_second': 8.494, 'epoch': 36.0}
12/07/2022 13:33:00 - INFO - training.trainer_base - ***** Epoch 35: Best results *****
12/07/2022 13:33:00 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:33:00 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:33:00 - INFO - training.trainer_base - epoch = 35.0
                                                   30%|███       | 900/3000 [08:04<16:35,  2.11it/s] 30%|███       | 901/3000 [08:04<32:40,  1.07it/s] 30%|███       | 902/3000 [08:05<27:51,  1.26it/s] 30%|███       | 903/3000 [08:05<24:30,  1.43it/s] 30%|███       | 904/3000 [08:06<22:07,  1.58it/s] 30%|███       | 905/3000 [08:06<20:24,  1.71it/s] 30%|███       | 906/3000 [08:07<19:14,  1.81it/s] 30%|███       | 907/3000 [08:07<18:25,  1.89it/s] 30%|███       | 908/3000 [08:08<17:52,  1.95it/s] 30%|███       | 909/3000 [08:08<17:32,  1.99it/s] 30%|███       | 910/3000 [08:08<17:12,  2.02it/s] 30%|███       | 911/3000 [08:09<16:57,  2.05it/s] 30%|███       | 912/3000 [08:09<16:50,  2.07it/s] 30%|███       | 913/3000 [08:10<16:45,  2.08it/s] 30%|███       | 914/3000 [08:10<16:42,  2.08it/s] 30%|███       | 915/3000 [08:11<16:38,  2.09it/s] 31%|███       | 916/3000 [08:11<16:34,  2.10it/s] 31%|███       | 917/3000 [08:12<16:31,  2.10it/s] 31%|███       | 918/3000 [08:12<16:30,  2.10it/s] 31%|███       | 919/3000 [08:13<16:31,  2.10it/s] 31%|███       | 920/3000 [08:13<16:30,  2.10it/s] 31%|███       | 921/3000 [08:14<16:28,  2.10it/s] 31%|███       | 922/3000 [08:14<16:27,  2.10it/s] 31%|███       | 923/3000 [08:15<16:27,  2.10it/s] 31%|███       | 924/3000 [08:15<16:29,  2.10it/s] 31%|███       | 925/3000 [08:16<16:29,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:33:12,087 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:33:12,088 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:33:12,088 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:33:12,088 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 36.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.62it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.39it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.86it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:33:13 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 31%|███       | 925/3000 [08:17<16:29,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6677192449569702, 'eval_accuracy': 0.85, 'eval_runtime': 1.5274, 'eval_samples_per_second': 65.471, 'eval_steps_per_second': 8.511, 'epoch': 37.0}
12/07/2022 13:33:13 - INFO - training.trainer_base - ***** Epoch 36: Best results *****
12/07/2022 13:33:13 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:33:13 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:33:13 - INFO - training.trainer_base - epoch = 36.0
                                                   31%|███       | 925/3000 [08:17<16:29,  2.10it/s] 31%|███       | 926/3000 [08:18<32:21,  1.07it/s] 31%|███       | 927/3000 [08:18<27:32,  1.25it/s] 31%|███       | 928/3000 [08:19<24:10,  1.43it/s] 31%|███       | 929/3000 [08:19<21:51,  1.58it/s] 31%|███       | 930/3000 [08:20<20:12,  1.71it/s] 31%|███       | 931/3000 [08:20<19:02,  1.81it/s] 31%|███       | 932/3000 [08:20<18:12,  1.89it/s] 31%|███       | 933/3000 [08:21<17:39,  1.95it/s] 31%|███       | 934/3000 [08:21<17:16,  1.99it/s] 31%|███       | 935/3000 [08:22<17:01,  2.02it/s] 31%|███       | 936/3000 [08:22<16:49,  2.04it/s] 31%|███       | 937/3000 [08:23<16:40,  2.06it/s] 31%|███▏      | 938/3000 [08:23<16:33,  2.08it/s] 31%|███▏      | 939/3000 [08:24<16:29,  2.08it/s] 31%|███▏      | 940/3000 [08:24<16:27,  2.09it/s] 31%|███▏      | 941/3000 [08:25<16:23,  2.09it/s] 31%|███▏      | 942/3000 [08:25<16:19,  2.10it/s] 31%|███▏      | 943/3000 [08:26<16:17,  2.10it/s] 31%|███▏      | 944/3000 [08:26<16:18,  2.10it/s] 32%|███▏      | 945/3000 [08:27<16:19,  2.10it/s] 32%|███▏      | 946/3000 [08:27<16:20,  2.10it/s] 32%|███▏      | 947/3000 [08:28<16:16,  2.10it/s] 32%|███▏      | 948/3000 [08:28<16:14,  2.11it/s] 32%|███▏      | 949/3000 [08:29<16:13,  2.11it/s] 32%|███▏      | 950/3000 [08:29<16:14,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:33:25,500 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:33:25,501 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:33:25,501 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:33:25,501 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 37.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.44it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:33:27 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 32%|███▏      | 950/3000 [08:31<16:14,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.6347066164016724, 'eval_accuracy': 0.83, 'eval_runtime': 1.5306, 'eval_samples_per_second': 65.334, 'eval_steps_per_second': 8.493, 'epoch': 38.0}
12/07/2022 13:33:27 - INFO - training.trainer_base - ***** Epoch 37: Best results *****
12/07/2022 13:33:27 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:33:27 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:33:27 - INFO - training.trainer_base - epoch = 37.0
                                                   32%|███▏      | 950/3000 [08:31<16:14,  2.10it/s] 32%|███▏      | 951/3000 [08:31<31:58,  1.07it/s] 32%|███▏      | 952/3000 [08:32<27:13,  1.25it/s] 32%|███▏      | 953/3000 [08:32<23:56,  1.43it/s] 32%|███▏      | 954/3000 [08:32<21:38,  1.58it/s] 32%|███▏      | 955/3000 [08:33<20:02,  1.70it/s] 32%|███▏      | 956/3000 [08:33<18:52,  1.80it/s] 32%|███▏      | 957/3000 [08:34<18:02,  1.89it/s] 32%|███▏      | 958/3000 [08:34<17:29,  1.95it/s] 32%|███▏      | 959/3000 [08:35<17:06,  1.99it/s] 32%|███▏      | 960/3000 [08:35<16:50,  2.02it/s] 32%|███▏      | 961/3000 [08:36<16:37,  2.04it/s] 32%|███▏      | 962/3000 [08:36<16:29,  2.06it/s] 32%|███▏      | 963/3000 [08:37<16:22,  2.07it/s] 32%|███▏      | 964/3000 [08:37<16:18,  2.08it/s] 32%|███▏      | 965/3000 [08:38<16:15,  2.09it/s] 32%|███▏      | 966/3000 [08:38<16:12,  2.09it/s] 32%|███▏      | 967/3000 [08:39<16:09,  2.10it/s] 32%|███▏      | 968/3000 [08:39<16:07,  2.10it/s] 32%|███▏      | 969/3000 [08:40<16:05,  2.10it/s] 32%|███▏      | 970/3000 [08:40<16:06,  2.10it/s] 32%|███▏      | 971/3000 [08:41<16:04,  2.10it/s] 32%|███▏      | 972/3000 [08:41<16:00,  2.11it/s] 32%|███▏      | 973/3000 [08:42<16:00,  2.11it/s] 32%|███▏      | 974/3000 [08:42<16:01,  2.11it/s] 32%|███▎      | 975/3000 [08:42<16:02,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:33:38,928 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:33:38,929 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:33:38,929 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:33:38,929 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 38.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.50it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.24it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.80it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:33:40 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                  
                                               [A 32%|███▎      | 975/3000 [08:44<16:02,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.6854398250579834, 'eval_accuracy': 0.86, 'eval_runtime': 1.5316, 'eval_samples_per_second': 65.292, 'eval_steps_per_second': 8.488, 'epoch': 39.0}
12/07/2022 13:33:40 - INFO - training.trainer_base - ***** Epoch 38: Best results *****
12/07/2022 13:33:40 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:33:40 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:33:40 - INFO - training.trainer_base - epoch = 38.0
                                                   32%|███▎      | 975/3000 [08:44<16:02,  2.10it/s] 33%|███▎      | 976/3000 [08:44<31:35,  1.07it/s] 33%|███▎      | 977/3000 [08:45<26:55,  1.25it/s] 33%|███▎      | 978/3000 [08:45<23:36,  1.43it/s] 33%|███▎      | 979/3000 [08:46<21:18,  1.58it/s] 33%|███▎      | 980/3000 [08:46<19:43,  1.71it/s] 33%|███▎      | 981/3000 [08:47<18:35,  1.81it/s] 33%|███▎      | 982/3000 [08:47<17:49,  1.89it/s] 33%|███▎      | 983/3000 [08:48<17:15,  1.95it/s] 33%|███▎      | 984/3000 [08:48<16:50,  2.00it/s] 33%|███▎      | 985/3000 [08:49<16:34,  2.03it/s] 33%|███▎      | 986/3000 [08:49<16:22,  2.05it/s] 33%|███▎      | 987/3000 [08:50<16:16,  2.06it/s] 33%|███▎      | 988/3000 [08:50<16:09,  2.08it/s] 33%|███▎      | 989/3000 [08:51<16:02,  2.09it/s] 33%|███▎      | 990/3000 [08:51<16:00,  2.09it/s] 33%|███▎      | 991/3000 [08:52<15:58,  2.10it/s] 33%|███▎      | 992/3000 [08:52<15:57,  2.10it/s] 33%|███▎      | 993/3000 [08:53<15:56,  2.10it/s] 33%|███▎      | 994/3000 [08:53<15:55,  2.10it/s] 33%|███▎      | 995/3000 [08:53<15:52,  2.10it/s] 33%|███▎      | 996/3000 [08:54<15:52,  2.10it/s] 33%|███▎      | 997/3000 [08:54<15:51,  2.10it/s] 33%|███▎      | 998/3000 [08:55<15:53,  2.10it/s] 33%|███▎      | 999/3000 [08:55<15:53,  2.10it/s] 33%|███▎      | 1000/3000 [08:56<15:52,  2.10it/s]                                                    33%|███▎      | 1000/3000 [08:56<15:52,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:33:52,349 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:33:52,351 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:33:52,351 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:33:52,351 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 39.0)])
{'loss': 0.1892, 'learning_rate': 0.005999999999999999, 'epoch': 40.0}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.53it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:33:53 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 33%|███▎      | 1000/3000 [08:57<15:52,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.5840908288955688, 'eval_accuracy': 0.86, 'eval_runtime': 1.531, 'eval_samples_per_second': 65.315, 'eval_steps_per_second': 8.491, 'epoch': 40.0}
12/07/2022 13:33:53 - INFO - training.trainer_base - ***** Epoch 39: Best results *****
12/07/2022 13:33:53 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:33:53 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:33:53 - INFO - training.trainer_base - epoch = 39.0
                                                    33%|███▎      | 1000/3000 [08:57<15:52,  2.10it/s] 33%|███▎      | 1001/3000 [08:58<31:11,  1.07it/s] 33%|███▎      | 1002/3000 [08:58<26:33,  1.25it/s] 33%|███▎      | 1003/3000 [08:59<23:19,  1.43it/s] 33%|███▎      | 1004/3000 [08:59<21:03,  1.58it/s] 34%|███▎      | 1005/3000 [09:00<19:29,  1.71it/s] 34%|███▎      | 1006/3000 [09:00<18:21,  1.81it/s] 34%|███▎      | 1007/3000 [09:01<17:34,  1.89it/s] 34%|███▎      | 1008/3000 [09:01<17:00,  1.95it/s] 34%|███▎      | 1009/3000 [09:02<16:38,  1.99it/s] 34%|███▎      | 1010/3000 [09:02<16:24,  2.02it/s] 34%|███▎      | 1011/3000 [09:03<16:10,  2.05it/s] 34%|███▎      | 1012/3000 [09:03<16:02,  2.07it/s] 34%|███▍      | 1013/3000 [09:04<15:57,  2.08it/s] 34%|███▍      | 1014/3000 [09:04<15:54,  2.08it/s] 34%|███▍      | 1015/3000 [09:05<15:51,  2.09it/s] 34%|███▍      | 1016/3000 [09:05<15:46,  2.10it/s] 34%|███▍      | 1017/3000 [09:05<15:43,  2.10it/s] 34%|███▍      | 1018/3000 [09:06<15:42,  2.10it/s] 34%|███▍      | 1019/3000 [09:06<15:42,  2.10it/s] 34%|███▍      | 1020/3000 [09:07<15:43,  2.10it/s] 34%|███▍      | 1021/3000 [09:07<15:44,  2.09it/s] 34%|███▍      | 1022/3000 [09:08<15:42,  2.10it/s] 34%|███▍      | 1023/3000 [09:08<15:40,  2.10it/s] 34%|███▍      | 1024/3000 [09:09<15:38,  2.10it/s] 34%|███▍      | 1025/3000 [09:09<15:37,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:34:05,762 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:34:05,764 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:34:05,764 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:34:05,764 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 40.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.32it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.32it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:34:07 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 34%|███▍      | 1025/3000 [09:11<15:37,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.588889479637146, 'eval_accuracy': 0.87, 'eval_runtime': 1.5315, 'eval_samples_per_second': 65.294, 'eval_steps_per_second': 8.488, 'epoch': 41.0}
12/07/2022 13:34:07 - INFO - training.trainer_base - ***** Epoch 40: Best results *****
12/07/2022 13:34:07 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:34:07 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:34:07 - INFO - training.trainer_base - epoch = 40.0
                                                    34%|███▍      | 1025/3000 [09:11<15:37,  2.11it/s] 34%|███▍      | 1026/3000 [09:11<30:48,  1.07it/s] 34%|███▍      | 1027/3000 [09:12<26:14,  1.25it/s] 34%|███▍      | 1028/3000 [09:12<23:02,  1.43it/s] 34%|███▍      | 1029/3000 [09:13<20:47,  1.58it/s] 34%|███▍      | 1030/3000 [09:13<19:14,  1.71it/s] 34%|███▍      | 1031/3000 [09:14<18:11,  1.80it/s] 34%|███▍      | 1032/3000 [09:14<17:25,  1.88it/s] 34%|███▍      | 1033/3000 [09:15<16:53,  1.94it/s] 34%|███▍      | 1034/3000 [09:15<16:28,  1.99it/s] 34%|███▍      | 1035/3000 [09:16<16:09,  2.03it/s] 35%|███▍      | 1036/3000 [09:16<15:58,  2.05it/s] 35%|███▍      | 1037/3000 [09:17<15:50,  2.06it/s] 35%|███▍      | 1038/3000 [09:17<15:46,  2.07it/s] 35%|███▍      | 1039/3000 [09:17<15:40,  2.09it/s] 35%|███▍      | 1040/3000 [09:18<15:36,  2.09it/s] 35%|███▍      | 1041/3000 [09:18<15:32,  2.10it/s] 35%|███▍      | 1042/3000 [09:19<15:31,  2.10it/s] 35%|███▍      | 1043/3000 [09:19<15:33,  2.10it/s] 35%|███▍      | 1044/3000 [09:20<15:32,  2.10it/s] 35%|███▍      | 1045/3000 [09:20<15:30,  2.10it/s] 35%|███▍      | 1046/3000 [09:21<15:28,  2.10it/s] 35%|███▍      | 1047/3000 [09:21<15:28,  2.10it/s] 35%|███▍      | 1048/3000 [09:22<15:29,  2.10it/s] 35%|███▍      | 1049/3000 [09:22<15:29,  2.10it/s] 35%|███▌      | 1050/3000 [09:23<15:28,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:34:19,192 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:34:19,194 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:34:19,194 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:34:19,194 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 41.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.57it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:34:20 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 35%|███▌      | 1050/3000 [09:24<15:28,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6107398867607117, 'eval_accuracy': 0.85, 'eval_runtime': 1.5285, 'eval_samples_per_second': 65.423, 'eval_steps_per_second': 8.505, 'epoch': 42.0}
12/07/2022 13:34:20 - INFO - training.trainer_base - ***** Epoch 41: Best results *****
12/07/2022 13:34:20 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:34:20 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:34:20 - INFO - training.trainer_base - epoch = 41.0
                                                    35%|███▌      | 1050/3000 [09:24<15:28,  2.10it/s] 35%|███▌      | 1051/3000 [09:25<30:23,  1.07it/s] 35%|███▌      | 1052/3000 [09:25<25:53,  1.25it/s] 35%|███▌      | 1053/3000 [09:26<22:44,  1.43it/s] 35%|███▌      | 1054/3000 [09:26<20:35,  1.58it/s] 35%|███▌      | 1055/3000 [09:27<19:04,  1.70it/s] 35%|███▌      | 1056/3000 [09:27<17:56,  1.81it/s] 35%|███▌      | 1057/3000 [09:28<17:08,  1.89it/s] 35%|███▌      | 1058/3000 [09:28<16:35,  1.95it/s] 35%|███▌      | 1059/3000 [09:29<16:15,  1.99it/s] 35%|███▌      | 1060/3000 [09:29<16:01,  2.02it/s] 35%|███▌      | 1061/3000 [09:29<15:48,  2.04it/s] 35%|███▌      | 1062/3000 [09:30<15:37,  2.07it/s] 35%|███▌      | 1063/3000 [09:30<15:31,  2.08it/s] 35%|███▌      | 1064/3000 [09:31<15:37,  2.06it/s] 36%|███▌      | 1065/3000 [09:31<15:33,  2.07it/s] 36%|███▌      | 1066/3000 [09:32<15:28,  2.08it/s] 36%|███▌      | 1067/3000 [09:32<15:25,  2.09it/s] 36%|███▌      | 1068/3000 [09:33<15:25,  2.09it/s] 36%|███▌      | 1069/3000 [09:33<15:24,  2.09it/s] 36%|███▌      | 1070/3000 [09:34<15:23,  2.09it/s] 36%|███▌      | 1071/3000 [09:34<15:20,  2.10it/s] 36%|███▌      | 1072/3000 [09:35<15:16,  2.10it/s] 36%|███▌      | 1073/3000 [09:35<15:14,  2.11it/s] 36%|███▌      | 1074/3000 [09:36<15:15,  2.10it/s] 36%|███▌      | 1075/3000 [09:36<15:16,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:34:32,638 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:34:32,639 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:34:32,639 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:34:32,639 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 42.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.28it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.32it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.79it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.66it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:34:34 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 36%|███▌      | 1075/3000 [09:38<15:16,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.5709826350212097, 'eval_accuracy': 0.88, 'eval_runtime': 1.5319, 'eval_samples_per_second': 65.278, 'eval_steps_per_second': 8.486, 'epoch': 43.0}
12/07/2022 13:34:34 - INFO - training.trainer_base - ***** Epoch 42: Best results *****
12/07/2022 13:34:34 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:34:34 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:34:34 - INFO - training.trainer_base - epoch = 42.0
                                                    36%|███▌      | 1075/3000 [09:38<15:16,  2.10it/s] 36%|███▌      | 1076/3000 [09:38<30:04,  1.07it/s] 36%|███▌      | 1077/3000 [09:39<25:35,  1.25it/s] 36%|███▌      | 1078/3000 [09:39<22:27,  1.43it/s] 36%|███▌      | 1079/3000 [09:40<20:16,  1.58it/s] 36%|███▌      | 1080/3000 [09:40<18:45,  1.71it/s] 36%|███▌      | 1081/3000 [09:41<17:39,  1.81it/s] 36%|███▌      | 1082/3000 [09:41<16:53,  1.89it/s] 36%|███▌      | 1083/3000 [09:42<16:23,  1.95it/s] 36%|███▌      | 1084/3000 [09:42<16:01,  1.99it/s] 36%|███▌      | 1085/3000 [09:42<15:44,  2.03it/s] 36%|███▌      | 1086/3000 [09:43<15:33,  2.05it/s] 36%|███▌      | 1087/3000 [09:43<15:24,  2.07it/s] 36%|███▋      | 1088/3000 [09:44<15:20,  2.08it/s] 36%|███▋      | 1089/3000 [09:44<15:19,  2.08it/s] 36%|███▋      | 1090/3000 [09:45<15:16,  2.08it/s] 36%|███▋      | 1091/3000 [09:45<15:11,  2.09it/s] 36%|███▋      | 1092/3000 [09:46<15:09,  2.10it/s] 36%|███▋      | 1093/3000 [09:46<15:08,  2.10it/s] 36%|███▋      | 1094/3000 [09:47<15:09,  2.09it/s] 36%|███▋      | 1095/3000 [09:47<15:07,  2.10it/s] 37%|███▋      | 1096/3000 [09:48<15:04,  2.10it/s] 37%|███▋      | 1097/3000 [09:48<15:05,  2.10it/s] 37%|███▋      | 1098/3000 [09:49<15:04,  2.10it/s] 37%|███▋      | 1099/3000 [09:49<15:03,  2.10it/s] 37%|███▋      | 1100/3000 [09:50<15:03,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:34:46,057 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:34:46,058 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:34:46,058 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:34:46,058 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 43.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.66it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.42it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:34:47 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 37%|███▋      | 1100/3000 [09:51<15:03,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.5632787942886353, 'eval_accuracy': 0.86, 'eval_runtime': 1.5265, 'eval_samples_per_second': 65.509, 'eval_steps_per_second': 8.516, 'epoch': 44.0}
12/07/2022 13:34:47 - INFO - training.trainer_base - ***** Epoch 43: Best results *****
12/07/2022 13:34:47 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:34:47 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:34:47 - INFO - training.trainer_base - epoch = 43.0
                                                    37%|███▋      | 1100/3000 [09:51<15:03,  2.10it/s] 37%|███▋      | 1101/3000 [09:52<29:36,  1.07it/s] 37%|███▋      | 1102/3000 [09:52<25:12,  1.25it/s] 37%|███▋      | 1103/3000 [09:53<22:08,  1.43it/s] 37%|███▋      | 1104/3000 [09:53<19:59,  1.58it/s] 37%|███▋      | 1105/3000 [09:53<18:31,  1.71it/s] 37%|███▋      | 1106/3000 [09:54<17:28,  1.81it/s] 37%|███▋      | 1107/3000 [09:54<16:43,  1.89it/s] 37%|███▋      | 1108/3000 [09:55<16:12,  1.94it/s] 37%|███▋      | 1109/3000 [09:55<15:50,  1.99it/s] 37%|███▋      | 1110/3000 [09:56<15:34,  2.02it/s] 37%|███▋      | 1111/3000 [09:56<15:24,  2.04it/s] 37%|███▋      | 1112/3000 [09:57<15:16,  2.06it/s] 37%|███▋      | 1113/3000 [09:57<15:09,  2.08it/s] 37%|███▋      | 1114/3000 [09:58<15:05,  2.08it/s] 37%|███▋      | 1115/3000 [09:58<15:03,  2.09it/s] 37%|███▋      | 1116/3000 [09:59<15:02,  2.09it/s] 37%|███▋      | 1117/3000 [09:59<14:59,  2.09it/s] 37%|███▋      | 1118/3000 [10:00<14:55,  2.10it/s] 37%|███▋      | 1119/3000 [10:00<14:53,  2.10it/s] 37%|███▋      | 1120/3000 [10:01<14:54,  2.10it/s] 37%|███▋      | 1121/3000 [10:01<14:58,  2.09it/s] 37%|███▋      | 1122/3000 [10:02<14:59,  2.09it/s] 37%|███▋      | 1123/3000 [10:02<14:56,  2.09it/s] 37%|███▋      | 1124/3000 [10:03<14:54,  2.10it/s] 38%|███▊      | 1125/3000 [10:03<14:51,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:34:59,489 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:34:59,490 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:34:59,490 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:34:59,491 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 44.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.56it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.42it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.46it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:35:01 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 38%|███▊      | 1125/3000 [10:05<14:51,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.6315944790840149, 'eval_accuracy': 0.88, 'eval_runtime': 1.5304, 'eval_samples_per_second': 65.342, 'eval_steps_per_second': 8.494, 'epoch': 45.0}
12/07/2022 13:35:01 - INFO - training.trainer_base - ***** Epoch 44: Best results *****
12/07/2022 13:35:01 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:35:01 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:35:01 - INFO - training.trainer_base - epoch = 44.0
                                                    38%|███▊      | 1125/3000 [10:05<14:51,  2.10it/s] 38%|███▊      | 1126/3000 [10:05<29:12,  1.07it/s] 38%|███▊      | 1127/3000 [10:05<24:52,  1.26it/s] 38%|███▊      | 1128/3000 [10:06<21:51,  1.43it/s] 38%|███▊      | 1129/3000 [10:06<19:44,  1.58it/s] 38%|███▊      | 1130/3000 [10:07<18:15,  1.71it/s] 38%|███▊      | 1131/3000 [10:07<17:12,  1.81it/s] 38%|███▊      | 1132/3000 [10:08<16:30,  1.89it/s] 38%|███▊      | 1133/3000 [10:08<15:59,  1.95it/s] 38%|███▊      | 1134/3000 [10:09<15:38,  1.99it/s] 38%|███▊      | 1135/3000 [10:09<15:21,  2.02it/s] 38%|███▊      | 1136/3000 [10:10<15:09,  2.05it/s] 38%|███▊      | 1137/3000 [10:10<15:01,  2.07it/s] 38%|███▊      | 1138/3000 [10:11<14:56,  2.08it/s] 38%|███▊      | 1139/3000 [10:11<14:54,  2.08it/s] 38%|███▊      | 1140/3000 [10:12<14:49,  2.09it/s] 38%|███▊      | 1141/3000 [10:12<14:45,  2.10it/s] 38%|███▊      | 1142/3000 [10:13<14:45,  2.10it/s] 38%|███▊      | 1143/3000 [10:13<14:45,  2.10it/s] 38%|███▊      | 1144/3000 [10:14<14:44,  2.10it/s] 38%|███▊      | 1145/3000 [10:14<14:44,  2.10it/s] 38%|███▊      | 1146/3000 [10:15<14:41,  2.10it/s] 38%|███▊      | 1147/3000 [10:15<14:38,  2.11it/s] 38%|███▊      | 1148/3000 [10:15<14:38,  2.11it/s] 38%|███▊      | 1149/3000 [10:16<14:41,  2.10it/s] 38%|███▊      | 1150/3000 [10:16<14:41,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:35:12,908 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:35:12,909 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:35:12,909 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:35:12,909 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 45.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.48it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.31it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.61it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.45it/s][A12/07/2022 13:35:14 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 38%|███▊      | 1150/3000 [10:18<14:41,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.45it/s][A
                                               [A{'eval_loss': 0.6580053567886353, 'eval_accuracy': 0.88, 'eval_runtime': 1.5391, 'eval_samples_per_second': 64.973, 'eval_steps_per_second': 8.446, 'epoch': 46.0}
12/07/2022 13:35:14 - INFO - training.trainer_base - ***** Epoch 45: Best results *****
12/07/2022 13:35:14 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:35:14 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:35:14 - INFO - training.trainer_base - epoch = 45.0
                                                    38%|███▊      | 1150/3000 [10:18<14:41,  2.10it/s] 38%|███▊      | 1151/3000 [10:18<28:57,  1.06it/s] 38%|███▊      | 1152/3000 [10:19<24:39,  1.25it/s] 38%|███▊      | 1153/3000 [10:19<21:39,  1.42it/s] 38%|███▊      | 1154/3000 [10:20<19:31,  1.58it/s] 38%|███▊      | 1155/3000 [10:20<18:03,  1.70it/s] 39%|███▊      | 1156/3000 [10:21<17:03,  1.80it/s] 39%|███▊      | 1157/3000 [10:21<16:20,  1.88it/s] 39%|███▊      | 1158/3000 [10:22<15:46,  1.95it/s] 39%|███▊      | 1159/3000 [10:22<15:23,  1.99it/s] 39%|███▊      | 1160/3000 [10:23<15:07,  2.03it/s] 39%|███▊      | 1161/3000 [10:23<14:57,  2.05it/s] 39%|███▊      | 1162/3000 [10:24<14:51,  2.06it/s] 39%|███▉      | 1163/3000 [10:24<14:44,  2.08it/s] 39%|███▉      | 1164/3000 [10:25<14:37,  2.09it/s] 39%|███▉      | 1165/3000 [10:25<14:34,  2.10it/s] 39%|███▉      | 1166/3000 [10:26<14:34,  2.10it/s] 39%|███▉      | 1167/3000 [10:26<14:34,  2.10it/s] 39%|███▉      | 1168/3000 [10:27<14:31,  2.10it/s] 39%|███▉      | 1169/3000 [10:27<14:29,  2.11it/s] 39%|███▉      | 1170/3000 [10:27<14:28,  2.11it/s] 39%|███▉      | 1171/3000 [10:28<14:28,  2.11it/s] 39%|███▉      | 1172/3000 [10:28<14:30,  2.10it/s] 39%|███▉      | 1173/3000 [10:29<14:27,  2.11it/s] 39%|███▉      | 1174/3000 [10:29<14:25,  2.11it/s] 39%|███▉      | 1175/3000 [10:30<14:26,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:35:26,327 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:35:26,328 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:35:26,328 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:35:26,328 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 46.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.47it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.32it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.80it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.67it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:35:27 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 39%|███▉      | 1175/3000 [10:31<14:26,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.6270668506622314, 'eval_accuracy': 0.87, 'eval_runtime': 1.5318, 'eval_samples_per_second': 65.284, 'eval_steps_per_second': 8.487, 'epoch': 47.0}
12/07/2022 13:35:27 - INFO - training.trainer_base - ***** Epoch 46: Best results *****
12/07/2022 13:35:27 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:35:27 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:35:27 - INFO - training.trainer_base - epoch = 46.0
                                                    39%|███▉      | 1175/3000 [10:31<14:26,  2.11it/s] 39%|███▉      | 1176/3000 [10:32<28:26,  1.07it/s] 39%|███▉      | 1177/3000 [10:32<24:15,  1.25it/s] 39%|███▉      | 1178/3000 [10:33<21:19,  1.42it/s] 39%|███▉      | 1179/3000 [10:33<19:14,  1.58it/s] 39%|███▉      | 1180/3000 [10:34<17:46,  1.71it/s] 39%|███▉      | 1181/3000 [10:34<16:44,  1.81it/s] 39%|███▉      | 1182/3000 [10:35<16:02,  1.89it/s] 39%|███▉      | 1183/3000 [10:35<15:33,  1.95it/s] 39%|███▉      | 1184/3000 [10:36<15:10,  1.99it/s] 40%|███▉      | 1185/3000 [10:36<14:54,  2.03it/s] 40%|███▉      | 1186/3000 [10:37<14:44,  2.05it/s] 40%|███▉      | 1187/3000 [10:37<14:38,  2.06it/s] 40%|███▉      | 1188/3000 [10:38<14:34,  2.07it/s] 40%|███▉      | 1189/3000 [10:38<14:30,  2.08it/s] 40%|███▉      | 1190/3000 [10:39<14:26,  2.09it/s] 40%|███▉      | 1191/3000 [10:39<14:22,  2.10it/s] 40%|███▉      | 1192/3000 [10:39<14:21,  2.10it/s] 40%|███▉      | 1193/3000 [10:40<14:22,  2.10it/s] 40%|███▉      | 1194/3000 [10:40<14:21,  2.10it/s] 40%|███▉      | 1195/3000 [10:41<14:19,  2.10it/s] 40%|███▉      | 1196/3000 [10:41<14:17,  2.10it/s] 40%|███▉      | 1197/3000 [10:42<14:17,  2.10it/s] 40%|███▉      | 1198/3000 [10:42<14:18,  2.10it/s] 40%|███▉      | 1199/3000 [10:43<14:19,  2.10it/s] 40%|████      | 1200/3000 [10:43<14:18,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:35:39,757 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:35:39,759 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:35:39,759 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:35:39,759 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 47.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.52it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:35:41 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 40%|████      | 1200/3000 [10:45<14:18,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6001057624816895, 'eval_accuracy': 0.87, 'eval_runtime': 1.5294, 'eval_samples_per_second': 65.385, 'eval_steps_per_second': 8.5, 'epoch': 48.0}
12/07/2022 13:35:41 - INFO - training.trainer_base - ***** Epoch 47: Best results *****
12/07/2022 13:35:41 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:35:41 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:35:41 - INFO - training.trainer_base - epoch = 47.0
                                                    40%|████      | 1200/3000 [10:45<14:18,  2.10it/s] 40%|████      | 1201/3000 [10:45<28:04,  1.07it/s] 40%|████      | 1202/3000 [10:46<23:54,  1.25it/s] 40%|████      | 1203/3000 [10:46<21:00,  1.43it/s] 40%|████      | 1204/3000 [10:47<18:58,  1.58it/s] 40%|████      | 1205/3000 [10:47<17:32,  1.71it/s] 40%|████      | 1206/3000 [10:48<16:30,  1.81it/s] 40%|████      | 1207/3000 [10:48<15:49,  1.89it/s] 40%|████      | 1208/3000 [10:49<15:20,  1.95it/s] 40%|████      | 1209/3000 [10:49<14:58,  1.99it/s] 40%|████      | 1210/3000 [10:50<14:41,  2.03it/s] 40%|████      | 1211/3000 [10:50<14:29,  2.06it/s] 40%|████      | 1212/3000 [10:51<14:24,  2.07it/s] 40%|████      | 1213/3000 [10:51<14:20,  2.08it/s] 40%|████      | 1214/3000 [10:51<14:15,  2.09it/s] 40%|████      | 1215/3000 [10:52<14:11,  2.10it/s] 41%|████      | 1216/3000 [10:52<14:09,  2.10it/s] 41%|████      | 1217/3000 [10:53<14:08,  2.10it/s] 41%|████      | 1218/3000 [10:53<14:08,  2.10it/s] 41%|████      | 1219/3000 [10:54<14:06,  2.10it/s] 41%|████      | 1220/3000 [10:54<14:05,  2.11it/s] 41%|████      | 1221/3000 [10:55<14:02,  2.11it/s] 41%|████      | 1222/3000 [10:55<14:02,  2.11it/s] 41%|████      | 1223/3000 [10:56<14:03,  2.11it/s] 41%|████      | 1224/3000 [10:56<14:02,  2.11it/s] 41%|████      | 1225/3000 [10:57<13:59,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:35:53,147 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:35:53,149 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:35:53,149 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:35:53,149 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 48.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.46it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.41it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.46it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.39it/s][A12/07/2022 13:35:54 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 41%|████      | 1225/3000 [10:58<13:59,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.39it/s][A
                                               [A{'eval_loss': 0.5848602056503296, 'eval_accuracy': 0.86, 'eval_runtime': 1.532, 'eval_samples_per_second': 65.275, 'eval_steps_per_second': 8.486, 'epoch': 49.0}
12/07/2022 13:35:54 - INFO - training.trainer_base - ***** Epoch 48: Best results *****
12/07/2022 13:35:54 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:35:54 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:35:54 - INFO - training.trainer_base - epoch = 48.0
                                                    41%|████      | 1225/3000 [10:58<13:59,  2.11it/s] 41%|████      | 1226/3000 [10:59<27:36,  1.07it/s] 41%|████      | 1227/3000 [10:59<23:30,  1.26it/s] 41%|████      | 1228/3000 [11:00<20:39,  1.43it/s] 41%|████      | 1229/3000 [11:00<18:40,  1.58it/s] 41%|████      | 1230/3000 [11:01<17:16,  1.71it/s] 41%|████      | 1231/3000 [11:01<16:17,  1.81it/s] 41%|████      | 1232/3000 [11:02<15:34,  1.89it/s] 41%|████      | 1233/3000 [11:02<15:05,  1.95it/s] 41%|████      | 1234/3000 [11:02<14:45,  1.99it/s] 41%|████      | 1235/3000 [11:03<14:33,  2.02it/s] 41%|████      | 1236/3000 [11:03<14:21,  2.05it/s] 41%|████      | 1237/3000 [11:04<14:13,  2.07it/s] 41%|████▏     | 1238/3000 [11:04<14:09,  2.08it/s] 41%|████▏     | 1239/3000 [11:05<14:06,  2.08it/s] 41%|████▏     | 1240/3000 [11:05<14:02,  2.09it/s] 41%|████▏     | 1241/3000 [11:06<14:02,  2.09it/s] 41%|████▏     | 1242/3000 [11:06<14:00,  2.09it/s] 41%|████▏     | 1243/3000 [11:07<13:57,  2.10it/s] 41%|████▏     | 1244/3000 [11:07<13:55,  2.10it/s] 42%|████▏     | 1245/3000 [11:08<13:54,  2.10it/s] 42%|████▏     | 1246/3000 [11:08<13:56,  2.10it/s] 42%|████▏     | 1247/3000 [11:09<13:56,  2.10it/s] 42%|████▏     | 1248/3000 [11:09<13:53,  2.10it/s] 42%|████▏     | 1249/3000 [11:10<13:53,  2.10it/s] 42%|████▏     | 1250/3000 [11:10<13:52,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:36:06,571 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:36:06,573 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:36:06,573 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:36:06,573 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 49.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.47it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.60it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.52it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.45it/s][A12/07/2022 13:36:08 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 42%|████▏     | 1250/3000 [11:12<13:52,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.45it/s][A
                                               [A{'eval_loss': 0.5537855625152588, 'eval_accuracy': 0.87, 'eval_runtime': 1.531, 'eval_samples_per_second': 65.319, 'eval_steps_per_second': 8.491, 'epoch': 50.0}
12/07/2022 13:36:08 - INFO - training.trainer_base - ***** Epoch 49: Best results *****
12/07/2022 13:36:08 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:36:08 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:36:08 - INFO - training.trainer_base - epoch = 49.0
                                                    42%|████▏     | 1250/3000 [11:12<13:52,  2.10it/s] 42%|████▏     | 1251/3000 [11:12<27:23,  1.06it/s] 42%|████▏     | 1252/3000 [11:13<23:21,  1.25it/s] 42%|████▏     | 1253/3000 [11:13<20:30,  1.42it/s] 42%|████▏     | 1254/3000 [11:14<18:30,  1.57it/s] 42%|████▏     | 1255/3000 [11:14<17:04,  1.70it/s] 42%|████▏     | 1256/3000 [11:14<16:03,  1.81it/s] 42%|████▏     | 1257/3000 [11:15<15:22,  1.89it/s] 42%|████▏     | 1258/3000 [11:15<14:54,  1.95it/s] 42%|████▏     | 1259/3000 [11:16<14:34,  1.99it/s] 42%|████▏     | 1260/3000 [11:16<14:19,  2.02it/s] 42%|████▏     | 1261/3000 [11:17<14:09,  2.05it/s] 42%|████▏     | 1262/3000 [11:17<14:01,  2.06it/s] 42%|████▏     | 1263/3000 [11:18<13:57,  2.08it/s] 42%|████▏     | 1264/3000 [11:18<13:53,  2.08it/s] 42%|████▏     | 1265/3000 [11:19<13:48,  2.09it/s] 42%|████▏     | 1266/3000 [11:19<13:47,  2.10it/s] 42%|████▏     | 1267/3000 [11:20<13:45,  2.10it/s] 42%|████▏     | 1268/3000 [11:20<13:45,  2.10it/s] 42%|████▏     | 1269/3000 [11:21<13:46,  2.10it/s] 42%|████▏     | 1270/3000 [11:21<13:46,  2.09it/s] 42%|████▏     | 1271/3000 [11:22<13:43,  2.10it/s] 42%|████▏     | 1272/3000 [11:22<13:42,  2.10it/s] 42%|████▏     | 1273/3000 [11:23<13:41,  2.10it/s] 42%|████▏     | 1274/3000 [11:23<13:41,  2.10it/s] 42%|████▎     | 1275/3000 [11:24<13:40,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:36:20,008 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:36:20,010 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:36:20,010 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:36:20,010 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 50.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:36:21 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 42%|████▎     | 1275/3000 [11:25<13:40,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.5761474370956421, 'eval_accuracy': 0.87, 'eval_runtime': 1.5325, 'eval_samples_per_second': 65.252, 'eval_steps_per_second': 8.483, 'epoch': 51.0}
12/07/2022 13:36:21 - INFO - training.trainer_base - ***** Epoch 50: Best results *****
12/07/2022 13:36:21 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:36:21 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:36:21 - INFO - training.trainer_base - epoch = 50.0
                                                    42%|████▎     | 1275/3000 [11:25<13:40,  2.10it/s] 43%|████▎     | 1276/3000 [11:26<26:56,  1.07it/s] 43%|████▎     | 1277/3000 [11:26<22:56,  1.25it/s] 43%|████▎     | 1278/3000 [11:26<20:07,  1.43it/s] 43%|████▎     | 1279/3000 [11:27<18:11,  1.58it/s] 43%|████▎     | 1280/3000 [11:27<16:47,  1.71it/s] 43%|████▎     | 1281/3000 [11:28<15:50,  1.81it/s] 43%|████▎     | 1282/3000 [11:28<15:08,  1.89it/s] 43%|████▎     | 1283/3000 [11:29<14:37,  1.96it/s] 43%|████▎     | 1284/3000 [11:29<14:18,  2.00it/s] 43%|████▎     | 1285/3000 [11:30<14:06,  2.03it/s] 43%|████▎     | 1286/3000 [11:30<13:59,  2.04it/s] 43%|████▎     | 1287/3000 [11:31<13:53,  2.06it/s] 43%|████▎     | 1288/3000 [11:31<13:45,  2.07it/s] 43%|████▎     | 1289/3000 [11:32<13:39,  2.09it/s] 43%|████▎     | 1290/3000 [11:32<13:36,  2.09it/s] 43%|████▎     | 1291/3000 [11:33<13:36,  2.09it/s] 43%|████▎     | 1292/3000 [11:33<13:36,  2.09it/s] 43%|████▎     | 1293/3000 [11:34<13:35,  2.09it/s] 43%|████▎     | 1294/3000 [11:34<13:31,  2.10it/s] 43%|████▎     | 1295/3000 [11:35<13:30,  2.10it/s] 43%|████▎     | 1296/3000 [11:35<13:30,  2.10it/s] 43%|████▎     | 1297/3000 [11:36<13:30,  2.10it/s] 43%|████▎     | 1298/3000 [11:36<13:29,  2.10it/s] 43%|████▎     | 1299/3000 [11:36<13:27,  2.11it/s] 43%|████▎     | 1300/3000 [11:37<13:26,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:36:33,423 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:36:33,424 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:36:33,424 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:36:33,424 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 51.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.47it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:36:34 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 43%|████▎     | 1300/3000 [11:38<13:26,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.6162433624267578, 'eval_accuracy': 0.87, 'eval_runtime': 1.5301, 'eval_samples_per_second': 65.353, 'eval_steps_per_second': 8.496, 'epoch': 52.0}
12/07/2022 13:36:34 - INFO - training.trainer_base - ***** Epoch 51: Best results *****
12/07/2022 13:36:34 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:36:34 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:36:34 - INFO - training.trainer_base - epoch = 51.0
                                                    43%|████▎     | 1300/3000 [11:38<13:26,  2.11it/s] 43%|████▎     | 1301/3000 [11:39<26:27,  1.07it/s] 43%|████▎     | 1302/3000 [11:39<22:33,  1.25it/s] 43%|████▎     | 1303/3000 [11:40<19:50,  1.43it/s] 43%|████▎     | 1304/3000 [11:40<17:54,  1.58it/s] 44%|████▎     | 1305/3000 [11:41<16:32,  1.71it/s] 44%|████▎     | 1306/3000 [11:41<15:35,  1.81it/s] 44%|████▎     | 1307/3000 [11:42<14:56,  1.89it/s] 44%|████▎     | 1308/3000 [11:42<14:28,  1.95it/s] 44%|████▎     | 1309/3000 [11:43<14:09,  1.99it/s] 44%|████▎     | 1310/3000 [11:43<13:54,  2.03it/s] 44%|████▎     | 1311/3000 [11:44<13:43,  2.05it/s] 44%|████▎     | 1312/3000 [11:44<13:37,  2.06it/s] 44%|████▍     | 1313/3000 [11:45<13:34,  2.07it/s] 44%|████▍     | 1314/3000 [11:45<13:30,  2.08it/s] 44%|████▍     | 1315/3000 [11:46<13:27,  2.09it/s] 44%|████▍     | 1316/3000 [11:46<13:24,  2.09it/s] 44%|████▍     | 1317/3000 [11:47<13:23,  2.09it/s] 44%|████▍     | 1318/3000 [11:47<13:23,  2.09it/s] 44%|████▍     | 1319/3000 [11:48<13:22,  2.09it/s] 44%|████▍     | 1320/3000 [11:48<13:18,  2.10it/s] 44%|████▍     | 1321/3000 [11:48<13:17,  2.10it/s] 44%|████▍     | 1322/3000 [11:49<13:17,  2.10it/s] 44%|████▍     | 1323/3000 [11:49<13:17,  2.10it/s] 44%|████▍     | 1324/3000 [11:50<13:16,  2.10it/s] 44%|████▍     | 1325/3000 [11:50<13:14,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:36:46,843 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:36:46,845 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:36:46,845 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:36:46,845 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 52.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.49it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.32it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.40it/s][A12/07/2022 13:36:48 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 44%|████▍     | 1325/3000 [11:52<13:14,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.40it/s][A
                                               [A{'eval_loss': 0.6583350896835327, 'eval_accuracy': 0.86, 'eval_runtime': 1.5314, 'eval_samples_per_second': 65.298, 'eval_steps_per_second': 8.489, 'epoch': 53.0}
12/07/2022 13:36:48 - INFO - training.trainer_base - ***** Epoch 52: Best results *****
12/07/2022 13:36:48 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:36:48 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:36:48 - INFO - training.trainer_base - epoch = 52.0
                                                    44%|████▍     | 1325/3000 [11:52<13:14,  2.11it/s] 44%|████▍     | 1326/3000 [11:52<26:04,  1.07it/s] 44%|████▍     | 1327/3000 [11:53<22:11,  1.26it/s] 44%|████▍     | 1328/3000 [11:53<19:30,  1.43it/s] 44%|████▍     | 1329/3000 [11:54<17:37,  1.58it/s] 44%|████▍     | 1330/3000 [11:54<16:17,  1.71it/s] 44%|████▍     | 1331/3000 [11:55<15:20,  1.81it/s] 44%|████▍     | 1332/3000 [11:55<14:42,  1.89it/s] 44%|████▍     | 1333/3000 [11:56<14:16,  1.95it/s] 44%|████▍     | 1334/3000 [11:56<13:56,  1.99it/s] 44%|████▍     | 1335/3000 [11:57<13:42,  2.03it/s] 45%|████▍     | 1336/3000 [11:57<13:32,  2.05it/s] 45%|████▍     | 1337/3000 [11:58<13:25,  2.06it/s] 45%|████▍     | 1338/3000 [11:58<13:22,  2.07it/s] 45%|████▍     | 1339/3000 [11:59<13:18,  2.08it/s] 45%|████▍     | 1340/3000 [11:59<13:14,  2.09it/s] 45%|████▍     | 1341/3000 [12:00<13:11,  2.10it/s] 45%|████▍     | 1342/3000 [12:00<13:09,  2.10it/s] 45%|████▍     | 1343/3000 [12:00<13:09,  2.10it/s] 45%|████▍     | 1344/3000 [12:01<13:08,  2.10it/s] 45%|████▍     | 1345/3000 [12:01<13:06,  2.10it/s] 45%|████▍     | 1346/3000 [12:02<13:06,  2.10it/s] 45%|████▍     | 1347/3000 [12:02<13:07,  2.10it/s] 45%|████▍     | 1348/3000 [12:03<13:06,  2.10it/s] 45%|████▍     | 1349/3000 [12:03<13:07,  2.10it/s] 45%|████▌     | 1350/3000 [12:04<13:06,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:37:00,265 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:37:00,266 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:37:00,266 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:37:00,266 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 53.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.58it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.39it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.81it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.67it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:37:01 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 45%|████▌     | 1350/3000 [12:05<13:06,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.6510089039802551, 'eval_accuracy': 0.87, 'eval_runtime': 1.5287, 'eval_samples_per_second': 65.414, 'eval_steps_per_second': 8.504, 'epoch': 54.0}
12/07/2022 13:37:01 - INFO - training.trainer_base - ***** Epoch 53: Best results *****
12/07/2022 13:37:01 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:37:01 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:37:01 - INFO - training.trainer_base - epoch = 53.0
                                                    45%|████▌     | 1350/3000 [12:05<13:06,  2.10it/s] 45%|████▌     | 1351/3000 [12:06<25:43,  1.07it/s] 45%|████▌     | 1352/3000 [12:06<21:54,  1.25it/s] 45%|████▌     | 1353/3000 [12:07<19:14,  1.43it/s] 45%|████▌     | 1354/3000 [12:07<17:23,  1.58it/s] 45%|████▌     | 1355/3000 [12:08<16:06,  1.70it/s] 45%|████▌     | 1356/3000 [12:08<15:10,  1.80it/s] 45%|████▌     | 1357/3000 [12:09<14:29,  1.89it/s] 45%|████▌     | 1358/3000 [12:09<14:02,  1.95it/s] 45%|████▌     | 1359/3000 [12:10<13:43,  1.99it/s] 45%|████▌     | 1360/3000 [12:10<13:31,  2.02it/s] 45%|████▌     | 1361/3000 [12:11<13:21,  2.04it/s] 45%|████▌     | 1362/3000 [12:11<13:13,  2.06it/s] 45%|████▌     | 1363/3000 [12:12<13:07,  2.08it/s] 45%|████▌     | 1364/3000 [12:12<13:04,  2.09it/s] 46%|████▌     | 1365/3000 [12:12<13:03,  2.09it/s] 46%|████▌     | 1366/3000 [12:13<13:02,  2.09it/s] 46%|████▌     | 1367/3000 [12:13<12:59,  2.10it/s] 46%|████▌     | 1368/3000 [12:14<12:58,  2.10it/s] 46%|████▌     | 1369/3000 [12:14<12:56,  2.10it/s] 46%|████▌     | 1370/3000 [12:15<12:55,  2.10it/s] 46%|████▌     | 1371/3000 [12:15<12:54,  2.10it/s] 46%|████▌     | 1372/3000 [12:16<12:55,  2.10it/s] 46%|████▌     | 1373/3000 [12:16<12:51,  2.11it/s] 46%|████▌     | 1374/3000 [12:17<12:52,  2.11it/s] 46%|████▌     | 1375/3000 [12:17<12:52,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:37:13,685 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:37:13,687 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:37:13,687 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:37:13,687 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 54.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.43it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.41it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.31it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:37:15 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 46%|████▌     | 1375/3000 [12:19<12:52,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.6968551874160767, 'eval_accuracy': 0.86, 'eval_runtime': 1.5273, 'eval_samples_per_second': 65.475, 'eval_steps_per_second': 8.512, 'epoch': 55.0}
12/07/2022 13:37:15 - INFO - training.trainer_base - ***** Epoch 54: Best results *****
12/07/2022 13:37:15 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:37:15 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:37:15 - INFO - training.trainer_base - epoch = 54.0
                                                    46%|████▌     | 1375/3000 [12:19<12:52,  2.10it/s] 46%|████▌     | 1376/3000 [12:19<25:19,  1.07it/s] 46%|████▌     | 1377/3000 [12:20<21:34,  1.25it/s] 46%|████▌     | 1378/3000 [12:20<18:58,  1.42it/s] 46%|████▌     | 1379/3000 [12:21<17:07,  1.58it/s] 46%|████▌     | 1380/3000 [12:21<15:48,  1.71it/s] 46%|████▌     | 1381/3000 [12:22<14:54,  1.81it/s] 46%|████▌     | 1382/3000 [12:22<14:16,  1.89it/s] 46%|████▌     | 1383/3000 [12:23<13:49,  1.95it/s] 46%|████▌     | 1384/3000 [12:23<13:29,  2.00it/s] 46%|████▌     | 1385/3000 [12:23<13:15,  2.03it/s] 46%|████▌     | 1386/3000 [12:24<13:06,  2.05it/s] 46%|████▌     | 1387/3000 [12:24<13:01,  2.06it/s] 46%|████▋     | 1388/3000 [12:25<12:57,  2.07it/s] 46%|████▋     | 1389/3000 [12:25<12:54,  2.08it/s] 46%|████▋     | 1390/3000 [12:26<12:49,  2.09it/s] 46%|████▋     | 1391/3000 [12:26<12:46,  2.10it/s] 46%|████▋     | 1392/3000 [12:27<12:45,  2.10it/s] 46%|████▋     | 1393/3000 [12:27<12:46,  2.10it/s] 46%|████▋     | 1394/3000 [12:28<12:46,  2.09it/s] 46%|████▋     | 1395/3000 [12:28<12:46,  2.09it/s] 47%|████▋     | 1396/3000 [12:29<12:45,  2.10it/s] 47%|████▋     | 1397/3000 [12:29<12:44,  2.10it/s] 47%|████▋     | 1398/3000 [12:30<12:43,  2.10it/s] 47%|████▋     | 1399/3000 [12:30<12:43,  2.10it/s] 47%|████▋     | 1400/3000 [12:31<12:44,  2.09it/s][INFO|trainer.py:540] 2022-12-07 13:37:27,115 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:37:27,117 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:37:27,117 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:37:27,117 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 55.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.57it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.42it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.30it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.86it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.73it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.60it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:37:28 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 47%|████▋     | 1400/3000 [12:32<12:44,  2.09it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.6621415019035339, 'eval_accuracy': 0.86, 'eval_runtime': 1.5271, 'eval_samples_per_second': 65.484, 'eval_steps_per_second': 8.513, 'epoch': 56.0}
12/07/2022 13:37:28 - INFO - training.trainer_base - ***** Epoch 55: Best results *****
12/07/2022 13:37:28 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:37:28 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:37:28 - INFO - training.trainer_base - epoch = 55.0
                                                    47%|████▋     | 1400/3000 [12:32<12:44,  2.09it/s] 47%|████▋     | 1401/3000 [12:33<24:59,  1.07it/s] 47%|████▋     | 1402/3000 [12:33<21:16,  1.25it/s] 47%|████▋     | 1403/3000 [12:34<18:39,  1.43it/s] 47%|████▋     | 1404/3000 [12:34<16:49,  1.58it/s] 47%|████▋     | 1405/3000 [12:35<15:34,  1.71it/s] 47%|████▋     | 1406/3000 [12:35<14:42,  1.81it/s] 47%|████▋     | 1407/3000 [12:36<14:04,  1.89it/s] 47%|████▋     | 1408/3000 [12:36<13:34,  1.95it/s] 47%|████▋     | 1409/3000 [12:36<13:17,  2.00it/s] 47%|████▋     | 1410/3000 [12:37<13:05,  2.02it/s] 47%|████▋     | 1411/3000 [12:37<12:57,  2.04it/s] 47%|████▋     | 1412/3000 [12:38<12:50,  2.06it/s] 47%|████▋     | 1413/3000 [12:38<12:44,  2.08it/s] 47%|████▋     | 1414/3000 [12:39<12:40,  2.09it/s] 47%|████▋     | 1415/3000 [12:39<12:38,  2.09it/s] 47%|████▋     | 1416/3000 [12:40<12:36,  2.09it/s] 47%|████▋     | 1417/3000 [12:40<12:36,  2.09it/s] 47%|████▋     | 1418/3000 [12:41<12:35,  2.09it/s] 47%|████▋     | 1419/3000 [12:41<12:32,  2.10it/s] 47%|████▋     | 1420/3000 [12:42<12:30,  2.11it/s] 47%|████▋     | 1421/3000 [12:42<12:29,  2.11it/s] 47%|████▋     | 1422/3000 [12:43<12:30,  2.10it/s] 47%|████▋     | 1423/3000 [12:43<12:29,  2.10it/s] 47%|████▋     | 1424/3000 [12:44<12:29,  2.10it/s] 48%|████▊     | 1425/3000 [12:44<12:28,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:37:40,530 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:37:40,532 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:37:40,532 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:37:40,532 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 56.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.51it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.41it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:37:42 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 48%|████▊     | 1425/3000 [12:46<12:28,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.6782240867614746, 'eval_accuracy': 0.84, 'eval_runtime': 1.5306, 'eval_samples_per_second': 65.335, 'eval_steps_per_second': 8.494, 'epoch': 57.0}
12/07/2022 13:37:42 - INFO - training.trainer_base - ***** Epoch 56: Best results *****
12/07/2022 13:37:42 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:37:42 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:37:42 - INFO - training.trainer_base - epoch = 56.0
                                                    48%|████▊     | 1425/3000 [12:46<12:28,  2.10it/s] 48%|████▊     | 1426/3000 [12:46<24:32,  1.07it/s] 48%|████▊     | 1427/3000 [12:47<20:55,  1.25it/s] 48%|████▊     | 1428/3000 [12:47<18:23,  1.42it/s] 48%|████▊     | 1429/3000 [12:48<16:37,  1.58it/s] 48%|████▊     | 1430/3000 [12:48<15:19,  1.71it/s] 48%|████▊     | 1431/3000 [12:48<14:26,  1.81it/s] 48%|████▊     | 1432/3000 [12:49<13:50,  1.89it/s] 48%|████▊     | 1433/3000 [12:49<13:24,  1.95it/s] 48%|████▊     | 1434/3000 [12:50<13:05,  1.99it/s] 48%|████▊     | 1435/3000 [12:50<12:52,  2.03it/s] 48%|████▊     | 1436/3000 [12:51<12:42,  2.05it/s] 48%|████▊     | 1437/3000 [12:51<12:37,  2.06it/s] 48%|████▊     | 1438/3000 [12:52<12:34,  2.07it/s] 48%|████▊     | 1439/3000 [12:52<12:32,  2.07it/s] 48%|████▊     | 1440/3000 [12:53<12:27,  2.09it/s] 48%|████▊     | 1441/3000 [12:53<12:24,  2.09it/s] 48%|████▊     | 1442/3000 [12:54<12:23,  2.10it/s] 48%|████▊     | 1443/3000 [12:54<12:22,  2.10it/s] 48%|████▊     | 1444/3000 [12:55<12:22,  2.10it/s] 48%|████▊     | 1445/3000 [12:55<12:20,  2.10it/s] 48%|████▊     | 1446/3000 [12:56<12:18,  2.10it/s] 48%|████▊     | 1447/3000 [12:56<12:17,  2.10it/s] 48%|████▊     | 1448/3000 [12:57<12:17,  2.10it/s] 48%|████▊     | 1449/3000 [12:57<12:18,  2.10it/s] 48%|████▊     | 1450/3000 [12:57<12:18,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:37:53,960 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:37:53,961 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:37:53,961 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:37:53,961 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 57.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.62it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.41it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.31it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.86it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.73it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.62it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.52it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:37:55 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 48%|████▊     | 1450/3000 [12:59<12:18,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.6824653148651123, 'eval_accuracy': 0.83, 'eval_runtime': 1.5271, 'eval_samples_per_second': 65.482, 'eval_steps_per_second': 8.513, 'epoch': 58.0}
12/07/2022 13:37:55 - INFO - training.trainer_base - ***** Epoch 57: Best results *****
12/07/2022 13:37:55 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:37:55 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:37:55 - INFO - training.trainer_base - epoch = 57.0
                                                    48%|████▊     | 1450/3000 [12:59<12:18,  2.10it/s] 48%|████▊     | 1451/3000 [12:59<24:07,  1.07it/s] 48%|████▊     | 1452/3000 [13:00<20:32,  1.26it/s] 48%|████▊     | 1453/3000 [13:00<18:02,  1.43it/s] 48%|████▊     | 1454/3000 [13:01<16:18,  1.58it/s] 48%|████▊     | 1455/3000 [13:01<15:05,  1.71it/s] 49%|████▊     | 1456/3000 [13:02<14:12,  1.81it/s] 49%|████▊     | 1457/3000 [13:02<13:36,  1.89it/s] 49%|████▊     | 1458/3000 [13:03<13:12,  1.95it/s] 49%|████▊     | 1459/3000 [13:03<12:53,  1.99it/s] 49%|████▊     | 1460/3000 [13:04<12:39,  2.03it/s] 49%|████▊     | 1461/3000 [13:04<12:28,  2.05it/s] 49%|████▊     | 1462/3000 [13:05<12:23,  2.07it/s] 49%|████▉     | 1463/3000 [13:05<12:21,  2.07it/s] 49%|████▉     | 1464/3000 [13:06<12:16,  2.09it/s] 49%|████▉     | 1465/3000 [13:06<12:12,  2.10it/s] 49%|████▉     | 1466/3000 [13:07<12:10,  2.10it/s] 49%|████▉     | 1467/3000 [13:07<12:09,  2.10it/s] 49%|████▉     | 1468/3000 [13:08<12:06,  2.11it/s] 49%|████▉     | 1469/3000 [13:08<12:05,  2.11it/s] 49%|████▉     | 1470/3000 [13:09<12:04,  2.11it/s] 49%|████▉     | 1471/3000 [13:09<12:05,  2.11it/s] 49%|████▉     | 1472/3000 [13:09<12:06,  2.10it/s] 49%|████▉     | 1473/3000 [13:10<12:05,  2.10it/s] 49%|████▉     | 1474/3000 [13:10<12:05,  2.10it/s] 49%|████▉     | 1475/3000 [13:11<12:05,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:38:07,356 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:38:07,357 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:38:07,357 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:38:07,357 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 58.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:38:08 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 49%|████▉     | 1475/3000 [13:12<12:05,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.6408963203430176, 'eval_accuracy': 0.83, 'eval_runtime': 1.5298, 'eval_samples_per_second': 65.37, 'eval_steps_per_second': 8.498, 'epoch': 59.0}
12/07/2022 13:38:08 - INFO - training.trainer_base - ***** Epoch 58: Best results *****
12/07/2022 13:38:08 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:38:08 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:38:08 - INFO - training.trainer_base - epoch = 58.0
                                                    49%|████▉     | 1475/3000 [13:12<12:05,  2.10it/s] 49%|████▉     | 1476/3000 [13:13<23:45,  1.07it/s] 49%|████▉     | 1477/3000 [13:13<20:14,  1.25it/s] 49%|████▉     | 1478/3000 [13:14<17:48,  1.42it/s] 49%|████▉     | 1479/3000 [13:14<16:05,  1.57it/s] 49%|████▉     | 1480/3000 [13:15<14:50,  1.71it/s] 49%|████▉     | 1481/3000 [13:15<13:59,  1.81it/s] 49%|████▉     | 1482/3000 [13:16<13:23,  1.89it/s] 49%|████▉     | 1483/3000 [13:16<12:57,  1.95it/s] 49%|████▉     | 1484/3000 [13:17<12:40,  1.99it/s] 50%|████▉     | 1485/3000 [13:17<12:30,  2.02it/s] 50%|████▉     | 1486/3000 [13:18<12:19,  2.05it/s] 50%|████▉     | 1487/3000 [13:18<12:12,  2.07it/s] 50%|████▉     | 1488/3000 [13:19<12:07,  2.08it/s] 50%|████▉     | 1489/3000 [13:19<12:03,  2.09it/s] 50%|████▉     | 1490/3000 [13:20<12:01,  2.09it/s] 50%|████▉     | 1491/3000 [13:20<11:59,  2.10it/s] 50%|████▉     | 1492/3000 [13:20<11:56,  2.10it/s] 50%|████▉     | 1493/3000 [13:21<11:55,  2.11it/s] 50%|████▉     | 1494/3000 [13:21<11:55,  2.10it/s] 50%|████▉     | 1495/3000 [13:22<11:55,  2.10it/s] 50%|████▉     | 1496/3000 [13:22<11:53,  2.11it/s] 50%|████▉     | 1497/3000 [13:23<11:52,  2.11it/s] 50%|████▉     | 1498/3000 [13:23<11:52,  2.11it/s] 50%|████▉     | 1499/3000 [13:24<11:53,  2.10it/s] 50%|█████     | 1500/3000 [13:24<11:54,  2.10it/s]                                                    50%|█████     | 1500/3000 [13:24<11:54,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:38:20,768 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:38:20,769 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:38:20,769 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:38:20,769 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 59.0)])
{'loss': 0.055, 'learning_rate': 0.0045, 'epoch': 60.0}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.44it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.29it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:38:22 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 50%|█████     | 1500/3000 [13:26<11:54,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.6597821116447449, 'eval_accuracy': 0.83, 'eval_runtime': 1.5317, 'eval_samples_per_second': 65.289, 'eval_steps_per_second': 8.488, 'epoch': 60.0}
12/07/2022 13:38:22 - INFO - training.trainer_base - ***** Epoch 59: Best results *****
12/07/2022 13:38:22 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:38:22 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:38:22 - INFO - training.trainer_base - epoch = 59.0
                                                    50%|█████     | 1500/3000 [13:26<11:54,  2.10it/s] 50%|█████     | 1501/3000 [13:26<23:25,  1.07it/s] 50%|█████     | 1502/3000 [13:27<19:59,  1.25it/s] 50%|█████     | 1503/3000 [13:27<17:31,  1.42it/s] 50%|█████     | 1504/3000 [13:28<15:47,  1.58it/s] 50%|█████     | 1505/3000 [13:28<14:35,  1.71it/s] 50%|█████     | 1506/3000 [13:29<13:45,  1.81it/s] 50%|█████     | 1507/3000 [13:29<13:10,  1.89it/s] 50%|█████     | 1508/3000 [13:30<12:45,  1.95it/s] 50%|█████     | 1509/3000 [13:30<12:26,  2.00it/s] 50%|█████     | 1510/3000 [13:31<12:13,  2.03it/s] 50%|█████     | 1511/3000 [13:31<12:05,  2.05it/s] 50%|█████     | 1512/3000 [13:32<12:00,  2.06it/s] 50%|█████     | 1513/3000 [13:32<11:57,  2.07it/s] 50%|█████     | 1514/3000 [13:32<11:53,  2.08it/s] 50%|█████     | 1515/3000 [13:33<11:49,  2.09it/s] 51%|█████     | 1516/3000 [13:33<11:48,  2.10it/s] 51%|█████     | 1517/3000 [13:34<11:47,  2.10it/s] 51%|█████     | 1518/3000 [13:34<11:48,  2.09it/s] 51%|█████     | 1519/3000 [13:35<11:45,  2.10it/s] 51%|█████     | 1520/3000 [13:35<11:43,  2.10it/s] 51%|█████     | 1521/3000 [13:36<11:43,  2.10it/s] 51%|█████     | 1522/3000 [13:36<11:43,  2.10it/s] 51%|█████     | 1523/3000 [13:37<11:43,  2.10it/s] 51%|█████     | 1524/3000 [13:37<11:43,  2.10it/s] 51%|█████     | 1525/3000 [13:38<11:42,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:38:34,194 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:38:34,196 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:38:34,196 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:38:34,196 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 60.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.50it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.35it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:38:35 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 51%|█████     | 1525/3000 [13:39<11:42,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.674410879611969, 'eval_accuracy': 0.84, 'eval_runtime': 1.5282, 'eval_samples_per_second': 65.436, 'eval_steps_per_second': 8.507, 'epoch': 61.0}
12/07/2022 13:38:35 - INFO - training.trainer_base - ***** Epoch 60: Best results *****
12/07/2022 13:38:35 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:38:35 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:38:35 - INFO - training.trainer_base - epoch = 60.0
                                                    51%|█████     | 1525/3000 [13:39<11:42,  2.10it/s] 51%|█████     | 1526/3000 [13:40<22:59,  1.07it/s] 51%|█████     | 1527/3000 [13:40<19:34,  1.25it/s] 51%|█████     | 1528/3000 [13:41<17:12,  1.43it/s] 51%|█████     | 1529/3000 [13:41<15:33,  1.58it/s] 51%|█████     | 1530/3000 [13:42<14:22,  1.70it/s] 51%|█████     | 1531/3000 [13:42<13:32,  1.81it/s] 51%|█████     | 1532/3000 [13:43<12:56,  1.89it/s] 51%|█████     | 1533/3000 [13:43<12:32,  1.95it/s] 51%|█████     | 1534/3000 [13:44<12:15,  1.99it/s] 51%|█████     | 1535/3000 [13:44<12:04,  2.02it/s] 51%|█████     | 1536/3000 [13:44<11:53,  2.05it/s] 51%|█████     | 1537/3000 [13:45<11:46,  2.07it/s] 51%|█████▏    | 1538/3000 [13:45<11:42,  2.08it/s] 51%|█████▏    | 1539/3000 [13:46<11:39,  2.09it/s] 51%|█████▏    | 1540/3000 [13:46<11:37,  2.09it/s] 51%|█████▏    | 1541/3000 [13:47<11:36,  2.09it/s] 51%|█████▏    | 1542/3000 [13:47<11:34,  2.10it/s] 51%|█████▏    | 1543/3000 [13:48<11:32,  2.11it/s] 51%|█████▏    | 1544/3000 [13:48<11:32,  2.10it/s] 52%|█████▏    | 1545/3000 [13:49<11:32,  2.10it/s] 52%|█████▏    | 1546/3000 [13:49<11:33,  2.10it/s] 52%|█████▏    | 1547/3000 [13:50<11:32,  2.10it/s] 52%|█████▏    | 1548/3000 [13:50<11:31,  2.10it/s] 52%|█████▏    | 1549/3000 [13:51<11:30,  2.10it/s] 52%|█████▏    | 1550/3000 [13:51<11:29,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:38:47,608 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:38:47,610 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:38:47,610 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:38:47,610 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 61.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.55it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.39it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.30it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.67it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:38:49 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 52%|█████▏    | 1550/3000 [13:53<11:29,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6123290061950684, 'eval_accuracy': 0.84, 'eval_runtime': 1.5277, 'eval_samples_per_second': 65.456, 'eval_steps_per_second': 8.509, 'epoch': 62.0}
12/07/2022 13:38:49 - INFO - training.trainer_base - ***** Epoch 61: Best results *****
12/07/2022 13:38:49 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:38:49 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:38:49 - INFO - training.trainer_base - epoch = 61.0
                                                    52%|█████▏    | 1550/3000 [13:53<11:29,  2.10it/s] 52%|█████▏    | 1551/3000 [13:53<22:35,  1.07it/s] 52%|█████▏    | 1552/3000 [13:54<19:16,  1.25it/s] 52%|█████▏    | 1553/3000 [13:54<16:54,  1.43it/s] 52%|█████▏    | 1554/3000 [13:55<15:15,  1.58it/s] 52%|█████▏    | 1555/3000 [13:55<14:06,  1.71it/s] 52%|█████▏    | 1556/3000 [13:56<13:18,  1.81it/s] 52%|█████▏    | 1557/3000 [13:56<12:46,  1.88it/s] 52%|█████▏    | 1558/3000 [13:56<12:21,  1.95it/s] 52%|█████▏    | 1559/3000 [13:57<12:02,  1.99it/s] 52%|█████▏    | 1560/3000 [13:57<11:50,  2.03it/s] 52%|█████▏    | 1561/3000 [13:58<11:42,  2.05it/s] 52%|█████▏    | 1562/3000 [13:58<11:37,  2.06it/s] 52%|█████▏    | 1563/3000 [13:59<11:31,  2.08it/s] 52%|█████▏    | 1564/3000 [13:59<11:27,  2.09it/s] 52%|█████▏    | 1565/3000 [14:00<11:26,  2.09it/s] 52%|█████▏    | 1566/3000 [14:00<11:25,  2.09it/s] 52%|█████▏    | 1567/3000 [14:01<11:26,  2.09it/s] 52%|█████▏    | 1568/3000 [14:01<11:24,  2.09it/s] 52%|█████▏    | 1569/3000 [14:02<11:21,  2.10it/s] 52%|█████▏    | 1570/3000 [14:02<11:18,  2.11it/s] 52%|█████▏    | 1571/3000 [14:03<11:18,  2.11it/s] 52%|█████▏    | 1572/3000 [14:03<11:18,  2.10it/s] 52%|█████▏    | 1573/3000 [14:04<11:18,  2.10it/s] 52%|█████▏    | 1574/3000 [14:04<11:17,  2.11it/s] 52%|█████▎    | 1575/3000 [14:05<11:16,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:39:01,026 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:39:01,028 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:39:01,028 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:39:01,028 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 62.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.35it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.79it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.66it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.54it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.46it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.40it/s][A12/07/2022 13:39:02 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 52%|█████▎    | 1575/3000 [14:06<11:16,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.40it/s][A
                                               [A{'eval_loss': 0.6390150785446167, 'eval_accuracy': 0.85, 'eval_runtime': 1.5324, 'eval_samples_per_second': 65.257, 'eval_steps_per_second': 8.483, 'epoch': 63.0}
12/07/2022 13:39:02 - INFO - training.trainer_base - ***** Epoch 62: Best results *****
12/07/2022 13:39:02 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:39:02 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:39:02 - INFO - training.trainer_base - epoch = 62.0
                                                    52%|█████▎    | 1575/3000 [14:06<11:16,  2.11it/s] 53%|█████▎    | 1576/3000 [14:07<22:12,  1.07it/s] 53%|█████▎    | 1577/3000 [14:07<18:55,  1.25it/s] 53%|█████▎    | 1578/3000 [14:08<16:37,  1.42it/s] 53%|█████▎    | 1579/3000 [14:08<14:58,  1.58it/s] 53%|█████▎    | 1580/3000 [14:08<13:50,  1.71it/s] 53%|█████▎    | 1581/3000 [14:09<13:02,  1.81it/s] 53%|█████▎    | 1582/3000 [14:09<12:29,  1.89it/s] 53%|█████▎    | 1583/3000 [14:10<12:08,  1.95it/s] 53%|█████▎    | 1584/3000 [14:10<11:50,  1.99it/s] 53%|█████▎    | 1585/3000 [14:11<11:37,  2.03it/s] 53%|█████▎    | 1586/3000 [14:11<11:28,  2.05it/s] 53%|█████▎    | 1587/3000 [14:12<11:24,  2.06it/s] 53%|█████▎    | 1588/3000 [14:12<11:21,  2.07it/s] 53%|█████▎    | 1589/3000 [14:13<11:17,  2.08it/s] 53%|█████▎    | 1590/3000 [14:13<11:14,  2.09it/s] 53%|█████▎    | 1591/3000 [14:14<11:13,  2.09it/s] 53%|█████▎    | 1592/3000 [14:14<11:13,  2.09it/s] 53%|█████▎    | 1593/3000 [14:15<11:12,  2.09it/s] 53%|█████▎    | 1594/3000 [14:15<11:10,  2.10it/s] 53%|█████▎    | 1595/3000 [14:16<11:07,  2.11it/s] 53%|█████▎    | 1596/3000 [14:16<11:07,  2.10it/s] 53%|█████▎    | 1597/3000 [14:17<11:07,  2.10it/s] 53%|█████▎    | 1598/3000 [14:17<11:06,  2.10it/s] 53%|█████▎    | 1599/3000 [14:17<11:03,  2.11it/s] 53%|█████▎    | 1600/3000 [14:18<11:02,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:39:14,438 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:39:14,439 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:39:14,439 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:39:14,439 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 63.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.44it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:39:15 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 53%|█████▎    | 1600/3000 [14:19<11:02,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.7228042483329773, 'eval_accuracy': 0.83, 'eval_runtime': 1.53, 'eval_samples_per_second': 65.359, 'eval_steps_per_second': 8.497, 'epoch': 64.0}
12/07/2022 13:39:15 - INFO - training.trainer_base - ***** Epoch 63: Best results *****
12/07/2022 13:39:15 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:39:15 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:39:15 - INFO - training.trainer_base - epoch = 63.0
                                                    53%|█████▎    | 1600/3000 [14:19<11:02,  2.11it/s] 53%|█████▎    | 1601/3000 [14:20<21:46,  1.07it/s] 53%|█████▎    | 1602/3000 [14:20<18:34,  1.25it/s] 53%|█████▎    | 1603/3000 [14:21<16:19,  1.43it/s] 53%|█████▎    | 1604/3000 [14:21<14:45,  1.58it/s] 54%|█████▎    | 1605/3000 [14:22<13:35,  1.71it/s] 54%|█████▎    | 1606/3000 [14:22<12:48,  1.81it/s] 54%|█████▎    | 1607/3000 [14:23<12:15,  1.89it/s] 54%|█████▎    | 1608/3000 [14:23<11:54,  1.95it/s] 54%|█████▎    | 1609/3000 [14:24<11:38,  1.99it/s] 54%|█████▎    | 1610/3000 [14:24<11:27,  2.02it/s] 54%|█████▎    | 1611/3000 [14:25<11:17,  2.05it/s] 54%|█████▎    | 1612/3000 [14:25<11:11,  2.07it/s] 54%|█████▍    | 1613/3000 [14:26<11:07,  2.08it/s] 54%|█████▍    | 1614/3000 [14:26<11:05,  2.08it/s] 54%|█████▍    | 1615/3000 [14:27<11:01,  2.09it/s] 54%|█████▍    | 1616/3000 [14:27<10:58,  2.10it/s] 54%|█████▍    | 1617/3000 [14:28<10:57,  2.10it/s] 54%|█████▍    | 1618/3000 [14:28<10:55,  2.11it/s] 54%|█████▍    | 1619/3000 [14:29<10:55,  2.11it/s] 54%|█████▍    | 1620/3000 [14:29<10:54,  2.11it/s] 54%|█████▍    | 1621/3000 [14:29<10:52,  2.11it/s] 54%|█████▍    | 1622/3000 [14:30<10:52,  2.11it/s] 54%|█████▍    | 1623/3000 [14:30<10:52,  2.11it/s] 54%|█████▍    | 1624/3000 [14:31<10:53,  2.11it/s] 54%|█████▍    | 1625/3000 [14:31<10:53,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:39:27,839 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:39:27,840 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:39:27,840 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:39:27,841 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 64.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.44it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:39:29 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 54%|█████▍    | 1625/3000 [14:33<10:53,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.7064105272293091, 'eval_accuracy': 0.83, 'eval_runtime': 1.5286, 'eval_samples_per_second': 65.42, 'eval_steps_per_second': 8.505, 'epoch': 65.0}
12/07/2022 13:39:29 - INFO - training.trainer_base - ***** Epoch 64: Best results *****
12/07/2022 13:39:29 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:39:29 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:39:29 - INFO - training.trainer_base - epoch = 64.0
                                                    54%|█████▍    | 1625/3000 [14:33<10:53,  2.10it/s] 54%|█████▍    | 1626/3000 [14:33<21:26,  1.07it/s] 54%|█████▍    | 1627/3000 [14:34<18:15,  1.25it/s] 54%|█████▍    | 1628/3000 [14:34<16:00,  1.43it/s] 54%|█████▍    | 1629/3000 [14:35<14:27,  1.58it/s] 54%|█████▍    | 1630/3000 [14:35<13:22,  1.71it/s] 54%|█████▍    | 1631/3000 [14:36<12:37,  1.81it/s] 54%|█████▍    | 1632/3000 [14:36<12:07,  1.88it/s] 54%|█████▍    | 1633/3000 [14:37<11:42,  1.95it/s] 54%|█████▍    | 1634/3000 [14:37<11:25,  1.99it/s] 55%|█████▍    | 1635/3000 [14:38<11:13,  2.03it/s] 55%|█████▍    | 1636/3000 [14:38<11:06,  2.05it/s] 55%|█████▍    | 1637/3000 [14:39<11:00,  2.06it/s] 55%|█████▍    | 1638/3000 [14:39<10:57,  2.07it/s] 55%|█████▍    | 1639/3000 [14:40<10:52,  2.09it/s] 55%|█████▍    | 1640/3000 [14:40<10:49,  2.09it/s] 55%|█████▍    | 1641/3000 [14:41<10:48,  2.10it/s] 55%|█████▍    | 1642/3000 [14:41<10:48,  2.09it/s] 55%|█████▍    | 1643/3000 [14:41<10:46,  2.10it/s] 55%|█████▍    | 1644/3000 [14:42<10:44,  2.10it/s] 55%|█████▍    | 1645/3000 [14:42<10:43,  2.11it/s] 55%|█████▍    | 1646/3000 [14:43<10:43,  2.10it/s] 55%|█████▍    | 1647/3000 [14:43<10:43,  2.10it/s] 55%|█████▍    | 1648/3000 [14:44<10:43,  2.10it/s] 55%|█████▍    | 1649/3000 [14:44<10:42,  2.10it/s] 55%|█████▌    | 1650/3000 [14:45<10:42,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:39:41,258 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:39:41,260 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:39:41,260 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:39:41,260 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 65.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.35it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.34it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:39:42 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 55%|█████▌    | 1650/3000 [14:46<10:42,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6570207476615906, 'eval_accuracy': 0.84, 'eval_runtime': 1.5305, 'eval_samples_per_second': 65.34, 'eval_steps_per_second': 8.494, 'epoch': 66.0}
12/07/2022 13:39:42 - INFO - training.trainer_base - ***** Epoch 65: Best results *****
12/07/2022 13:39:42 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:39:42 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:39:42 - INFO - training.trainer_base - epoch = 65.0
                                                    55%|█████▌    | 1650/3000 [14:46<10:42,  2.10it/s] 55%|█████▌    | 1651/3000 [14:47<21:01,  1.07it/s] 55%|█████▌    | 1652/3000 [14:47<17:54,  1.25it/s] 55%|█████▌    | 1653/3000 [14:48<15:45,  1.42it/s] 55%|█████▌    | 1654/3000 [14:48<14:16,  1.57it/s] 55%|█████▌    | 1655/3000 [14:49<13:09,  1.70it/s] 55%|█████▌    | 1656/3000 [14:49<12:21,  1.81it/s] 55%|█████▌    | 1657/3000 [14:50<11:50,  1.89it/s] 55%|█████▌    | 1658/3000 [14:50<11:29,  1.95it/s] 55%|█████▌    | 1659/3000 [14:51<11:15,  1.99it/s] 55%|█████▌    | 1660/3000 [14:51<11:03,  2.02it/s] 55%|█████▌    | 1661/3000 [14:52<10:54,  2.04it/s] 55%|█████▌    | 1662/3000 [14:52<10:49,  2.06it/s] 55%|█████▌    | 1663/3000 [14:53<10:44,  2.07it/s] 55%|█████▌    | 1664/3000 [14:53<10:42,  2.08it/s] 56%|█████▌    | 1665/3000 [14:53<10:39,  2.09it/s] 56%|█████▌    | 1666/3000 [14:54<10:37,  2.09it/s] 56%|█████▌    | 1667/3000 [14:54<10:35,  2.10it/s] 56%|█████▌    | 1668/3000 [14:55<10:34,  2.10it/s] 56%|█████▌    | 1669/3000 [14:55<10:33,  2.10it/s] 56%|█████▌    | 1670/3000 [14:56<10:32,  2.10it/s] 56%|█████▌    | 1671/3000 [14:56<10:32,  2.10it/s] 56%|█████▌    | 1672/3000 [14:57<10:29,  2.11it/s] 56%|█████▌    | 1673/3000 [14:57<10:28,  2.11it/s] 56%|█████▌    | 1674/3000 [14:58<10:30,  2.10it/s] 56%|█████▌    | 1675/3000 [14:58<10:32,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:39:54,689 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:39:54,691 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:39:54,691 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:39:54,691 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 66.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.47it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.40it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.39it/s][A12/07/2022 13:39:56 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 56%|█████▌    | 1675/3000 [15:00<10:32,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.39it/s][A
                                               [A{'eval_loss': 0.6181795597076416, 'eval_accuracy': 0.85, 'eval_runtime': 1.5322, 'eval_samples_per_second': 65.264, 'eval_steps_per_second': 8.484, 'epoch': 67.0}
12/07/2022 13:39:56 - INFO - training.trainer_base - ***** Epoch 66: Best results *****
12/07/2022 13:39:56 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:39:56 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:39:56 - INFO - training.trainer_base - epoch = 66.0
                                                    56%|█████▌    | 1675/3000 [15:00<10:32,  2.10it/s] 56%|█████▌    | 1676/3000 [15:00<20:41,  1.07it/s] 56%|█████▌    | 1677/3000 [15:01<17:37,  1.25it/s] 56%|█████▌    | 1678/3000 [15:01<15:27,  1.42it/s] 56%|█████▌    | 1679/3000 [15:02<13:58,  1.58it/s] 56%|█████▌    | 1680/3000 [15:02<12:54,  1.70it/s] 56%|█████▌    | 1681/3000 [15:03<12:11,  1.80it/s] 56%|█████▌    | 1682/3000 [15:03<11:39,  1.88it/s] 56%|█████▌    | 1683/3000 [15:04<11:16,  1.95it/s] 56%|█████▌    | 1684/3000 [15:04<11:00,  1.99it/s] 56%|█████▌    | 1685/3000 [15:05<10:49,  2.02it/s] 56%|█████▌    | 1686/3000 [15:05<10:42,  2.04it/s] 56%|█████▌    | 1687/3000 [15:05<10:37,  2.06it/s] 56%|█████▋    | 1688/3000 [15:06<10:32,  2.07it/s] 56%|█████▋    | 1689/3000 [15:06<10:28,  2.09it/s] 56%|█████▋    | 1690/3000 [15:07<10:25,  2.09it/s] 56%|█████▋    | 1691/3000 [15:07<10:25,  2.09it/s] 56%|█████▋    | 1692/3000 [15:08<10:25,  2.09it/s] 56%|█████▋    | 1693/3000 [15:08<10:24,  2.09it/s] 56%|█████▋    | 1694/3000 [15:09<10:22,  2.10it/s] 56%|█████▋    | 1695/3000 [15:09<10:21,  2.10it/s] 57%|█████▋    | 1696/3000 [15:10<10:20,  2.10it/s] 57%|█████▋    | 1697/3000 [15:10<10:20,  2.10it/s] 57%|█████▋    | 1698/3000 [15:11<10:20,  2.10it/s] 57%|█████▋    | 1699/3000 [15:11<10:19,  2.10it/s] 57%|█████▋    | 1700/3000 [15:12<10:18,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:40:08,122 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:40:08,124 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:40:08,124 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:40:08,124 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 67.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.43it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.34it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.55it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.45it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.39it/s][A12/07/2022 13:40:09 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 57%|█████▋    | 1700/3000 [15:13<10:18,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.39it/s][A
                                               [A{'eval_loss': 0.5808408856391907, 'eval_accuracy': 0.85, 'eval_runtime': 1.535, 'eval_samples_per_second': 65.145, 'eval_steps_per_second': 8.469, 'epoch': 68.0}
12/07/2022 13:40:09 - INFO - training.trainer_base - ***** Epoch 67: Best results *****
12/07/2022 13:40:09 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:40:09 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:40:09 - INFO - training.trainer_base - epoch = 67.0
                                                    57%|█████▋    | 1700/3000 [15:13<10:18,  2.10it/s] 57%|█████▋    | 1701/3000 [15:14<20:17,  1.07it/s] 57%|█████▋    | 1702/3000 [15:14<17:17,  1.25it/s] 57%|█████▋    | 1703/3000 [15:15<15:11,  1.42it/s] 57%|█████▋    | 1704/3000 [15:15<13:42,  1.58it/s] 57%|█████▋    | 1705/3000 [15:16<12:40,  1.70it/s] 57%|█████▋    | 1706/3000 [15:16<11:57,  1.80it/s] 57%|█████▋    | 1707/3000 [15:17<11:27,  1.88it/s] 57%|█████▋    | 1708/3000 [15:17<11:06,  1.94it/s] 57%|█████▋    | 1709/3000 [15:17<10:50,  1.98it/s] 57%|█████▋    | 1710/3000 [15:18<10:39,  2.02it/s] 57%|█████▋    | 1711/3000 [15:18<10:31,  2.04it/s] 57%|█████▋    | 1712/3000 [15:19<10:26,  2.06it/s] 57%|█████▋    | 1713/3000 [15:19<10:21,  2.07it/s] 57%|█████▋    | 1714/3000 [15:20<10:17,  2.08it/s] 57%|█████▋    | 1715/3000 [15:20<10:15,  2.09it/s] 57%|█████▋    | 1716/3000 [15:21<10:14,  2.09it/s] 57%|█████▋    | 1717/3000 [15:21<10:13,  2.09it/s] 57%|█████▋    | 1718/3000 [15:22<10:10,  2.10it/s] 57%|█████▋    | 1719/3000 [15:22<10:08,  2.10it/s] 57%|█████▋    | 1720/3000 [15:23<10:08,  2.10it/s] 57%|█████▋    | 1721/3000 [15:23<10:08,  2.10it/s] 57%|█████▋    | 1722/3000 [15:24<10:09,  2.10it/s] 57%|█████▋    | 1723/3000 [15:24<10:07,  2.10it/s] 57%|█████▋    | 1724/3000 [15:25<10:05,  2.11it/s] 57%|█████▊    | 1725/3000 [15:25<10:03,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:40:21,559 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:40:21,561 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:40:21,561 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:40:21,561 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 68.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.47it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.34it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.72it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:40:23 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 57%|█████▊    | 1725/3000 [15:27<10:03,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.5902564525604248, 'eval_accuracy': 0.85, 'eval_runtime': 1.5266, 'eval_samples_per_second': 65.505, 'eval_steps_per_second': 8.516, 'epoch': 69.0}
12/07/2022 13:40:23 - INFO - training.trainer_base - ***** Epoch 68: Best results *****
12/07/2022 13:40:23 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:40:23 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:40:23 - INFO - training.trainer_base - epoch = 68.0
                                                    57%|█████▊    | 1725/3000 [15:27<10:03,  2.11it/s] 58%|█████▊    | 1726/3000 [15:27<19:48,  1.07it/s] 58%|█████▊    | 1727/3000 [15:28<16:52,  1.26it/s] 58%|█████▊    | 1728/3000 [15:28<14:49,  1.43it/s] 58%|█████▊    | 1729/3000 [15:29<13:23,  1.58it/s] 58%|█████▊    | 1730/3000 [15:29<12:21,  1.71it/s] 58%|█████▊    | 1731/3000 [15:29<11:38,  1.82it/s] 58%|█████▊    | 1732/3000 [15:30<11:10,  1.89it/s] 58%|█████▊    | 1733/3000 [15:30<10:49,  1.95it/s] 58%|█████▊    | 1734/3000 [15:31<10:35,  1.99it/s] 58%|█████▊    | 1735/3000 [15:31<10:24,  2.03it/s] 58%|█████▊    | 1736/3000 [15:32<10:15,  2.05it/s] 58%|█████▊    | 1737/3000 [15:32<10:10,  2.07it/s] 58%|█████▊    | 1738/3000 [15:33<10:07,  2.08it/s] 58%|█████▊    | 1739/3000 [15:33<10:06,  2.08it/s] 58%|█████▊    | 1740/3000 [15:34<10:03,  2.09it/s] 58%|█████▊    | 1741/3000 [15:34<10:00,  2.10it/s] 58%|█████▊    | 1742/3000 [15:35<09:59,  2.10it/s] 58%|█████▊    | 1743/3000 [15:35<09:58,  2.10it/s] 58%|█████▊    | 1744/3000 [15:36<09:58,  2.10it/s] 58%|█████▊    | 1745/3000 [15:36<09:58,  2.10it/s] 58%|█████▊    | 1746/3000 [15:37<09:56,  2.10it/s] 58%|█████▊    | 1747/3000 [15:37<09:55,  2.10it/s] 58%|█████▊    | 1748/3000 [15:38<09:55,  2.10it/s] 58%|█████▊    | 1749/3000 [15:38<09:55,  2.10it/s] 58%|█████▊    | 1750/3000 [15:38<09:55,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:40:34,970 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:40:34,971 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:40:34,971 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:40:34,971 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 69.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.58it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.39it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:40:36 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 58%|█████▊    | 1750/3000 [15:40<09:55,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6066359877586365, 'eval_accuracy': 0.85, 'eval_runtime': 1.5298, 'eval_samples_per_second': 65.37, 'eval_steps_per_second': 8.498, 'epoch': 70.0}
12/07/2022 13:40:36 - INFO - training.trainer_base - ***** Epoch 69: Best results *****
12/07/2022 13:40:36 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:40:36 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:40:36 - INFO - training.trainer_base - epoch = 69.0
                                                    58%|█████▊    | 1750/3000 [15:40<09:55,  2.10it/s] 58%|█████▊    | 1751/3000 [15:41<19:29,  1.07it/s] 58%|█████▊    | 1752/3000 [15:41<16:35,  1.25it/s] 58%|█████▊    | 1753/3000 [15:41<14:33,  1.43it/s] 58%|█████▊    | 1754/3000 [15:42<13:09,  1.58it/s] 58%|█████▊    | 1755/3000 [15:42<12:09,  1.71it/s] 59%|█████▊    | 1756/3000 [15:43<11:27,  1.81it/s] 59%|█████▊    | 1757/3000 [15:43<10:57,  1.89it/s] 59%|█████▊    | 1758/3000 [15:44<10:36,  1.95it/s] 59%|█████▊    | 1759/3000 [15:44<10:21,  2.00it/s] 59%|█████▊    | 1760/3000 [15:45<10:11,  2.03it/s] 59%|█████▊    | 1761/3000 [15:45<10:04,  2.05it/s] 59%|█████▊    | 1762/3000 [15:46<09:58,  2.07it/s] 59%|█████▉    | 1763/3000 [15:46<09:54,  2.08it/s] 59%|█████▉    | 1764/3000 [15:47<09:53,  2.08it/s] 59%|█████▉    | 1765/3000 [15:47<09:50,  2.09it/s] 59%|█████▉    | 1766/3000 [15:48<09:50,  2.09it/s] 59%|█████▉    | 1767/3000 [15:48<09:48,  2.09it/s] 59%|█████▉    | 1768/3000 [15:49<09:47,  2.10it/s] 59%|█████▉    | 1769/3000 [15:49<09:46,  2.10it/s] 59%|█████▉    | 1770/3000 [15:50<09:46,  2.10it/s] 59%|█████▉    | 1771/3000 [15:50<09:46,  2.10it/s] 59%|█████▉    | 1772/3000 [15:50<09:45,  2.10it/s] 59%|█████▉    | 1773/3000 [15:51<09:44,  2.10it/s] 59%|█████▉    | 1774/3000 [15:51<09:42,  2.10it/s] 59%|█████▉    | 1775/3000 [15:52<09:40,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:40:48,382 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:40:48,383 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:40:48,383 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:40:48,383 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 70.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.41it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.40it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:40:49 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 59%|█████▉    | 1775/3000 [15:53<09:40,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.60532146692276, 'eval_accuracy': 0.86, 'eval_runtime': 1.5306, 'eval_samples_per_second': 65.333, 'eval_steps_per_second': 8.493, 'epoch': 71.0}
12/07/2022 13:40:49 - INFO - training.trainer_base - ***** Epoch 70: Best results *****
12/07/2022 13:40:49 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:40:49 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:40:49 - INFO - training.trainer_base - epoch = 70.0
                                                    59%|█████▉    | 1775/3000 [15:53<09:40,  2.11it/s] 59%|█████▉    | 1776/3000 [15:54<19:03,  1.07it/s] 59%|█████▉    | 1777/3000 [15:54<16:13,  1.26it/s] 59%|█████▉    | 1778/3000 [15:55<14:15,  1.43it/s] 59%|█████▉    | 1779/3000 [15:55<12:51,  1.58it/s] 59%|█████▉    | 1780/3000 [15:56<11:53,  1.71it/s] 59%|█████▉    | 1781/3000 [15:56<11:12,  1.81it/s] 59%|█████▉    | 1782/3000 [15:57<10:44,  1.89it/s] 59%|█████▉    | 1783/3000 [15:57<10:26,  1.94it/s] 59%|█████▉    | 1784/3000 [15:58<10:11,  1.99it/s] 60%|█████▉    | 1785/3000 [15:58<10:01,  2.02it/s] 60%|█████▉    | 1786/3000 [15:59<09:53,  2.05it/s] 60%|█████▉    | 1787/3000 [15:59<09:47,  2.06it/s] 60%|█████▉    | 1788/3000 [16:00<09:44,  2.07it/s] 60%|█████▉    | 1789/3000 [16:00<09:42,  2.08it/s] 60%|█████▉    | 1790/3000 [16:01<09:40,  2.08it/s] 60%|█████▉    | 1791/3000 [16:01<09:37,  2.09it/s] 60%|█████▉    | 1792/3000 [16:02<09:35,  2.10it/s] 60%|█████▉    | 1793/3000 [16:02<09:34,  2.10it/s] 60%|█████▉    | 1794/3000 [16:02<09:33,  2.10it/s] 60%|█████▉    | 1795/3000 [16:03<09:34,  2.10it/s] 60%|█████▉    | 1796/3000 [16:03<09:33,  2.10it/s] 60%|█████▉    | 1797/3000 [16:04<09:32,  2.10it/s] 60%|█████▉    | 1798/3000 [16:04<09:31,  2.10it/s] 60%|█████▉    | 1799/3000 [16:05<09:30,  2.10it/s] 60%|██████    | 1800/3000 [16:05<09:31,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:41:01,805 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:41:01,806 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:41:01,807 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:41:01,807 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 71.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.49it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:41:03 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 60%|██████    | 1800/3000 [16:07<09:31,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.6162484288215637, 'eval_accuracy': 0.87, 'eval_runtime': 1.529, 'eval_samples_per_second': 65.404, 'eval_steps_per_second': 8.503, 'epoch': 72.0}
12/07/2022 13:41:03 - INFO - training.trainer_base - ***** Epoch 71: Best results *****
12/07/2022 13:41:03 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:41:03 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:41:03 - INFO - training.trainer_base - epoch = 71.0
                                                    60%|██████    | 1800/3000 [16:07<09:31,  2.10it/s] 60%|██████    | 1801/3000 [16:07<18:44,  1.07it/s] 60%|██████    | 1802/3000 [16:08<15:56,  1.25it/s] 60%|██████    | 1803/3000 [16:08<14:00,  1.42it/s] 60%|██████    | 1804/3000 [16:09<12:37,  1.58it/s] 60%|██████    | 1805/3000 [16:09<11:40,  1.71it/s] 60%|██████    | 1806/3000 [16:10<11:01,  1.80it/s] 60%|██████    | 1807/3000 [16:10<10:32,  1.89it/s] 60%|██████    | 1808/3000 [16:11<10:12,  1.95it/s] 60%|██████    | 1809/3000 [16:11<09:57,  1.99it/s] 60%|██████    | 1810/3000 [16:12<09:48,  2.02it/s] 60%|██████    | 1811/3000 [16:12<09:41,  2.04it/s] 60%|██████    | 1812/3000 [16:13<09:36,  2.06it/s] 60%|██████    | 1813/3000 [16:13<09:31,  2.08it/s] 60%|██████    | 1814/3000 [16:14<09:29,  2.08it/s] 60%|██████    | 1815/3000 [16:14<09:28,  2.08it/s] 61%|██████    | 1816/3000 [16:14<09:27,  2.09it/s] 61%|██████    | 1817/3000 [16:15<09:26,  2.09it/s] 61%|██████    | 1818/3000 [16:15<09:22,  2.10it/s] 61%|██████    | 1819/3000 [16:16<09:20,  2.11it/s] 61%|██████    | 1820/3000 [16:16<09:20,  2.11it/s] 61%|██████    | 1821/3000 [16:17<09:20,  2.10it/s] 61%|██████    | 1822/3000 [16:17<09:20,  2.10it/s] 61%|██████    | 1823/3000 [16:18<09:18,  2.11it/s] 61%|██████    | 1824/3000 [16:18<09:18,  2.11it/s] 61%|██████    | 1825/3000 [16:19<09:18,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:41:15,228 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:41:15,229 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:41:15,229 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:41:15,229 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 72.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.55it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.41it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:41:16 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 61%|██████    | 1825/3000 [16:20<09:18,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.6488208174705505, 'eval_accuracy': 0.86, 'eval_runtime': 1.5274, 'eval_samples_per_second': 65.469, 'eval_steps_per_second': 8.511, 'epoch': 73.0}
12/07/2022 13:41:16 - INFO - training.trainer_base - ***** Epoch 72: Best results *****
12/07/2022 13:41:16 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:41:16 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:41:16 - INFO - training.trainer_base - epoch = 72.0
                                                    61%|██████    | 1825/3000 [16:20<09:18,  2.11it/s] 61%|██████    | 1826/3000 [16:21<18:16,  1.07it/s] 61%|██████    | 1827/3000 [16:21<15:35,  1.25it/s] 61%|██████    | 1828/3000 [16:22<13:41,  1.43it/s] 61%|██████    | 1829/3000 [16:22<12:21,  1.58it/s] 61%|██████    | 1830/3000 [16:23<11:24,  1.71it/s] 61%|██████    | 1831/3000 [16:23<10:45,  1.81it/s] 61%|██████    | 1832/3000 [16:24<10:18,  1.89it/s] 61%|██████    | 1833/3000 [16:24<09:58,  1.95it/s] 61%|██████    | 1834/3000 [16:25<09:43,  2.00it/s] 61%|██████    | 1835/3000 [16:25<09:33,  2.03it/s] 61%|██████    | 1836/3000 [16:26<09:27,  2.05it/s] 61%|██████    | 1837/3000 [16:26<09:23,  2.06it/s] 61%|██████▏   | 1838/3000 [16:26<09:18,  2.08it/s] 61%|██████▏   | 1839/3000 [16:27<09:16,  2.09it/s] 61%|██████▏   | 1840/3000 [16:27<09:15,  2.09it/s] 61%|██████▏   | 1841/3000 [16:28<09:15,  2.09it/s] 61%|██████▏   | 1842/3000 [16:28<09:13,  2.09it/s] 61%|██████▏   | 1843/3000 [16:29<09:10,  2.10it/s] 61%|██████▏   | 1844/3000 [16:29<09:10,  2.10it/s] 62%|██████▏   | 1845/3000 [16:30<09:09,  2.10it/s] 62%|██████▏   | 1846/3000 [16:30<09:09,  2.10it/s] 62%|██████▏   | 1847/3000 [16:31<09:08,  2.10it/s] 62%|██████▏   | 1848/3000 [16:31<09:06,  2.11it/s] 62%|██████▏   | 1849/3000 [16:32<09:05,  2.11it/s] 62%|██████▏   | 1850/3000 [16:32<09:05,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:41:28,634 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:41:28,636 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:41:28,636 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:41:28,636 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 73.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.35it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.36it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:41:30 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 62%|██████▏   | 1850/3000 [16:34<09:05,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.6540676951408386, 'eval_accuracy': 0.87, 'eval_runtime': 1.5298, 'eval_samples_per_second': 65.367, 'eval_steps_per_second': 8.498, 'epoch': 74.0}
12/07/2022 13:41:30 - INFO - training.trainer_base - ***** Epoch 73: Best results *****
12/07/2022 13:41:30 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:41:30 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:41:30 - INFO - training.trainer_base - epoch = 73.0
                                                    62%|██████▏   | 1850/3000 [16:34<09:05,  2.11it/s] 62%|██████▏   | 1851/3000 [16:34<17:54,  1.07it/s] 62%|██████▏   | 1852/3000 [16:35<15:15,  1.25it/s] 62%|██████▏   | 1853/3000 [16:35<13:22,  1.43it/s] 62%|██████▏   | 1854/3000 [16:36<12:04,  1.58it/s] 62%|██████▏   | 1855/3000 [16:36<11:10,  1.71it/s] 62%|██████▏   | 1856/3000 [16:37<10:31,  1.81it/s] 62%|██████▏   | 1857/3000 [16:37<10:06,  1.88it/s] 62%|██████▏   | 1858/3000 [16:38<09:47,  1.94it/s] 62%|██████▏   | 1859/3000 [16:38<09:33,  1.99it/s] 62%|██████▏   | 1860/3000 [16:38<09:23,  2.02it/s] 62%|██████▏   | 1861/3000 [16:39<09:17,  2.04it/s] 62%|██████▏   | 1862/3000 [16:39<09:11,  2.06it/s] 62%|██████▏   | 1863/3000 [16:40<09:09,  2.07it/s] 62%|██████▏   | 1864/3000 [16:40<09:05,  2.08it/s] 62%|██████▏   | 1865/3000 [16:41<09:01,  2.09it/s] 62%|██████▏   | 1866/3000 [16:41<08:59,  2.10it/s] 62%|██████▏   | 1867/3000 [16:42<08:58,  2.10it/s] 62%|██████▏   | 1868/3000 [16:42<08:58,  2.10it/s] 62%|██████▏   | 1869/3000 [16:43<08:58,  2.10it/s] 62%|██████▏   | 1870/3000 [16:43<08:56,  2.11it/s] 62%|██████▏   | 1871/3000 [16:44<08:55,  2.11it/s] 62%|██████▏   | 1872/3000 [16:44<08:56,  2.10it/s] 62%|██████▏   | 1873/3000 [16:45<08:55,  2.10it/s] 62%|██████▏   | 1874/3000 [16:45<08:55,  2.10it/s] 62%|██████▎   | 1875/3000 [16:46<08:54,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:41:42,050 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:41:42,051 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:41:42,051 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:41:42,051 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 74.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.57it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.39it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.72it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.61it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:41:43 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 62%|██████▎   | 1875/3000 [16:47<08:54,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6518780589103699, 'eval_accuracy': 0.85, 'eval_runtime': 1.527, 'eval_samples_per_second': 65.486, 'eval_steps_per_second': 8.513, 'epoch': 75.0}
12/07/2022 13:41:43 - INFO - training.trainer_base - ***** Epoch 74: Best results *****
12/07/2022 13:41:43 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:41:43 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:41:43 - INFO - training.trainer_base - epoch = 74.0
                                                    62%|██████▎   | 1875/3000 [16:47<08:54,  2.10it/s] 63%|██████▎   | 1876/3000 [16:48<17:31,  1.07it/s] 63%|██████▎   | 1877/3000 [16:48<14:54,  1.26it/s] 63%|██████▎   | 1878/3000 [16:49<13:05,  1.43it/s] 63%|██████▎   | 1879/3000 [16:49<11:49,  1.58it/s] 63%|██████▎   | 1880/3000 [16:49<10:57,  1.70it/s] 63%|██████▎   | 1881/3000 [16:50<10:19,  1.81it/s] 63%|██████▎   | 1882/3000 [16:50<09:51,  1.89it/s] 63%|██████▎   | 1883/3000 [16:51<09:32,  1.95it/s] 63%|██████▎   | 1884/3000 [16:51<09:19,  1.99it/s] 63%|██████▎   | 1885/3000 [16:52<09:10,  2.02it/s] 63%|██████▎   | 1886/3000 [16:52<09:03,  2.05it/s] 63%|██████▎   | 1887/3000 [16:53<08:58,  2.07it/s] 63%|██████▎   | 1888/3000 [16:53<08:53,  2.08it/s] 63%|██████▎   | 1889/3000 [16:54<08:50,  2.09it/s] 63%|██████▎   | 1890/3000 [16:54<08:49,  2.10it/s] 63%|██████▎   | 1891/3000 [16:55<08:49,  2.09it/s] 63%|██████▎   | 1892/3000 [16:55<08:48,  2.10it/s] 63%|██████▎   | 1893/3000 [16:56<08:46,  2.10it/s] 63%|██████▎   | 1894/3000 [16:56<08:47,  2.10it/s] 63%|██████▎   | 1895/3000 [16:57<08:47,  2.10it/s] 63%|██████▎   | 1896/3000 [16:57<08:47,  2.09it/s] 63%|██████▎   | 1897/3000 [16:58<08:45,  2.10it/s] 63%|██████▎   | 1898/3000 [16:58<08:44,  2.10it/s] 63%|██████▎   | 1899/3000 [16:59<08:42,  2.11it/s] 63%|██████▎   | 1900/3000 [16:59<08:41,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:41:55,456 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:41:55,458 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:41:55,458 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:41:55,458 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 75.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.59it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.40it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:41:56 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 63%|██████▎   | 1900/3000 [17:01<08:41,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.6886391639709473, 'eval_accuracy': 0.82, 'eval_runtime': 1.5296, 'eval_samples_per_second': 65.377, 'eval_steps_per_second': 8.499, 'epoch': 76.0}
12/07/2022 13:41:56 - INFO - training.trainer_base - ***** Epoch 75: Best results *****
12/07/2022 13:41:56 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:41:56 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:41:56 - INFO - training.trainer_base - epoch = 75.0
                                                    63%|██████▎   | 1900/3000 [17:01<08:41,  2.11it/s] 63%|██████▎   | 1901/3000 [17:01<17:07,  1.07it/s] 63%|██████▎   | 1902/3000 [17:01<14:35,  1.25it/s] 63%|██████▎   | 1903/3000 [17:02<12:47,  1.43it/s] 63%|██████▎   | 1904/3000 [17:02<11:32,  1.58it/s] 64%|██████▎   | 1905/3000 [17:03<10:40,  1.71it/s] 64%|██████▎   | 1906/3000 [17:03<10:04,  1.81it/s] 64%|██████▎   | 1907/3000 [17:04<09:38,  1.89it/s] 64%|██████▎   | 1908/3000 [17:04<09:19,  1.95it/s] 64%|██████▎   | 1909/3000 [17:05<09:06,  2.00it/s] 64%|██████▎   | 1910/3000 [17:05<08:56,  2.03it/s] 64%|██████▎   | 1911/3000 [17:06<08:51,  2.05it/s] 64%|██████▎   | 1912/3000 [17:06<08:48,  2.06it/s] 64%|██████▍   | 1913/3000 [17:07<08:45,  2.07it/s] 64%|██████▍   | 1914/3000 [17:07<08:42,  2.08it/s] 64%|██████▍   | 1915/3000 [17:08<08:39,  2.09it/s] 64%|██████▍   | 1916/3000 [17:08<08:37,  2.09it/s] 64%|██████▍   | 1917/3000 [17:09<08:35,  2.10it/s] 64%|██████▍   | 1918/3000 [17:09<08:36,  2.10it/s] 64%|██████▍   | 1919/3000 [17:10<08:34,  2.10it/s] 64%|██████▍   | 1920/3000 [17:10<08:32,  2.11it/s] 64%|██████▍   | 1921/3000 [17:10<08:31,  2.11it/s] 64%|██████▍   | 1922/3000 [17:11<08:31,  2.11it/s] 64%|██████▍   | 1923/3000 [17:11<08:32,  2.10it/s] 64%|██████▍   | 1924/3000 [17:12<08:32,  2.10it/s] 64%|██████▍   | 1925/3000 [17:12<08:31,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:42:08,872 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:42:08,874 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:42:08,874 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:42:08,874 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 76.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.35it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.32it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.22it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.79it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.66it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:42:10 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 64%|██████▍   | 1925/3000 [17:14<08:31,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.6806381344795227, 'eval_accuracy': 0.82, 'eval_runtime': 1.5324, 'eval_samples_per_second': 65.259, 'eval_steps_per_second': 8.484, 'epoch': 77.0}
12/07/2022 13:42:10 - INFO - training.trainer_base - ***** Epoch 76: Best results *****
12/07/2022 13:42:10 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:42:10 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:42:10 - INFO - training.trainer_base - epoch = 76.0
                                                    64%|██████▍   | 1925/3000 [17:14<08:31,  2.10it/s] 64%|██████▍   | 1926/3000 [17:14<16:45,  1.07it/s] 64%|██████▍   | 1927/3000 [17:15<14:15,  1.25it/s] 64%|██████▍   | 1928/3000 [17:15<12:31,  1.43it/s] 64%|██████▍   | 1929/3000 [17:16<11:18,  1.58it/s] 64%|██████▍   | 1930/3000 [17:16<10:27,  1.70it/s] 64%|██████▍   | 1931/3000 [17:17<09:51,  1.81it/s] 64%|██████▍   | 1932/3000 [17:17<09:25,  1.89it/s] 64%|██████▍   | 1933/3000 [17:18<09:07,  1.95it/s] 64%|██████▍   | 1934/3000 [17:18<08:55,  1.99it/s] 64%|██████▍   | 1935/3000 [17:19<08:47,  2.02it/s] 65%|██████▍   | 1936/3000 [17:19<08:41,  2.04it/s] 65%|██████▍   | 1937/3000 [17:20<08:37,  2.05it/s] 65%|██████▍   | 1938/3000 [17:20<08:33,  2.07it/s] 65%|██████▍   | 1939/3000 [17:21<08:30,  2.08it/s] 65%|██████▍   | 1940/3000 [17:21<08:28,  2.08it/s] 65%|██████▍   | 1941/3000 [17:22<08:26,  2.09it/s] 65%|██████▍   | 1942/3000 [17:22<08:24,  2.10it/s] 65%|██████▍   | 1943/3000 [17:23<08:23,  2.10it/s] 65%|██████▍   | 1944/3000 [17:23<08:22,  2.10it/s] 65%|██████▍   | 1945/3000 [17:23<08:21,  2.10it/s] 65%|██████▍   | 1946/3000 [17:24<08:21,  2.10it/s] 65%|██████▍   | 1947/3000 [17:24<08:20,  2.10it/s] 65%|██████▍   | 1948/3000 [17:25<08:19,  2.11it/s] 65%|██████▍   | 1949/3000 [17:25<08:19,  2.11it/s] 65%|██████▌   | 1950/3000 [17:26<08:18,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:42:22,299 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:42:22,300 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:42:22,300 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:42:22,300 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 77.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.46it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.36it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:42:23 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 65%|██████▌   | 1950/3000 [17:27<08:18,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.6894330382347107, 'eval_accuracy': 0.83, 'eval_runtime': 1.5311, 'eval_samples_per_second': 65.311, 'eval_steps_per_second': 8.49, 'epoch': 78.0}
12/07/2022 13:42:23 - INFO - training.trainer_base - ***** Epoch 77: Best results *****
12/07/2022 13:42:23 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:42:23 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:42:23 - INFO - training.trainer_base - epoch = 77.0
                                                    65%|██████▌   | 1950/3000 [17:27<08:18,  2.11it/s] 65%|██████▌   | 1951/3000 [17:28<16:22,  1.07it/s] 65%|██████▌   | 1952/3000 [17:28<13:58,  1.25it/s] 65%|██████▌   | 1953/3000 [17:29<12:15,  1.42it/s] 65%|██████▌   | 1954/3000 [17:29<11:04,  1.58it/s] 65%|██████▌   | 1955/3000 [17:30<10:13,  1.70it/s] 65%|██████▌   | 1956/3000 [17:30<09:38,  1.80it/s] 65%|██████▌   | 1957/3000 [17:31<09:14,  1.88it/s] 65%|██████▌   | 1958/3000 [17:31<08:55,  1.95it/s] 65%|██████▌   | 1959/3000 [17:32<08:42,  1.99it/s] 65%|██████▌   | 1960/3000 [17:32<08:33,  2.02it/s] 65%|██████▌   | 1961/3000 [17:33<08:28,  2.04it/s] 65%|██████▌   | 1962/3000 [17:33<08:24,  2.06it/s] 65%|██████▌   | 1963/3000 [17:34<08:20,  2.07it/s] 65%|██████▌   | 1964/3000 [17:34<08:17,  2.08it/s] 66%|██████▌   | 1965/3000 [17:35<08:15,  2.09it/s] 66%|██████▌   | 1966/3000 [17:35<08:14,  2.09it/s] 66%|██████▌   | 1967/3000 [17:35<08:12,  2.10it/s] 66%|██████▌   | 1968/3000 [17:36<08:10,  2.10it/s] 66%|██████▌   | 1969/3000 [17:36<08:09,  2.11it/s] 66%|██████▌   | 1970/3000 [17:37<08:09,  2.11it/s] 66%|██████▌   | 1971/3000 [17:37<08:09,  2.10it/s] 66%|██████▌   | 1972/3000 [17:38<08:08,  2.10it/s] 66%|██████▌   | 1973/3000 [17:38<08:06,  2.11it/s] 66%|██████▌   | 1974/3000 [17:39<08:05,  2.11it/s] 66%|██████▌   | 1975/3000 [17:39<08:06,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:42:35,725 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:42:35,727 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:42:35,727 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:42:35,727 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 78.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.37it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.61it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.52it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:42:37 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 66%|██████▌   | 1975/3000 [17:41<08:06,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.7180622220039368, 'eval_accuracy': 0.83, 'eval_runtime': 1.5263, 'eval_samples_per_second': 65.519, 'eval_steps_per_second': 8.518, 'epoch': 79.0}
12/07/2022 13:42:37 - INFO - training.trainer_base - ***** Epoch 78: Best results *****
12/07/2022 13:42:37 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:42:37 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:42:37 - INFO - training.trainer_base - epoch = 78.0
                                                    66%|██████▌   | 1975/3000 [17:41<08:06,  2.11it/s] 66%|██████▌   | 1976/3000 [17:41<15:56,  1.07it/s] 66%|██████▌   | 1977/3000 [17:42<13:35,  1.25it/s] 66%|██████▌   | 1978/3000 [17:42<11:54,  1.43it/s] 66%|██████▌   | 1979/3000 [17:43<10:44,  1.58it/s] 66%|██████▌   | 1980/3000 [17:43<09:56,  1.71it/s] 66%|██████▌   | 1981/3000 [17:44<09:22,  1.81it/s] 66%|██████▌   | 1982/3000 [17:44<08:59,  1.89it/s] 66%|██████▌   | 1983/3000 [17:45<08:42,  1.95it/s] 66%|██████▌   | 1984/3000 [17:45<08:29,  2.00it/s] 66%|██████▌   | 1985/3000 [17:46<08:20,  2.03it/s] 66%|██████▌   | 1986/3000 [17:46<08:14,  2.05it/s] 66%|██████▌   | 1987/3000 [17:46<08:10,  2.07it/s] 66%|██████▋   | 1988/3000 [17:47<08:08,  2.07it/s] 66%|██████▋   | 1989/3000 [17:47<08:04,  2.09it/s] 66%|██████▋   | 1990/3000 [17:48<08:02,  2.09it/s] 66%|██████▋   | 1991/3000 [17:48<08:02,  2.09it/s] 66%|██████▋   | 1992/3000 [17:49<08:01,  2.09it/s] 66%|██████▋   | 1993/3000 [17:49<08:00,  2.09it/s] 66%|██████▋   | 1994/3000 [17:50<07:58,  2.10it/s] 66%|██████▋   | 1995/3000 [17:50<07:57,  2.11it/s] 67%|██████▋   | 1996/3000 [17:51<07:57,  2.10it/s] 67%|██████▋   | 1997/3000 [17:51<07:56,  2.11it/s] 67%|██████▋   | 1998/3000 [17:52<07:57,  2.10it/s] 67%|██████▋   | 1999/3000 [17:52<07:55,  2.10it/s] 67%|██████▋   | 2000/3000 [17:53<07:54,  2.11it/s]                                                    67%|██████▋   | 2000/3000 [17:53<07:54,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:42:49,133 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:42:49,135 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:42:49,135 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:42:49,135 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 79.0)])
{'loss': 0.0314, 'learning_rate': 0.0029999999999999996, 'epoch': 80.0}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.34it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.45it/s][A12/07/2022 13:42:50 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 67%|██████▋   | 2000/3000 [17:54<07:54,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.45it/s][A
                                               [A{'eval_loss': 0.7062069177627563, 'eval_accuracy': 0.83, 'eval_runtime': 1.5298, 'eval_samples_per_second': 65.368, 'eval_steps_per_second': 8.498, 'epoch': 80.0}
12/07/2022 13:42:50 - INFO - training.trainer_base - ***** Epoch 79: Best results *****
12/07/2022 13:42:50 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:42:50 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:42:50 - INFO - training.trainer_base - epoch = 79.0
                                                    67%|██████▋   | 2000/3000 [17:54<07:54,  2.11it/s] 67%|██████▋   | 2001/3000 [17:55<15:33,  1.07it/s] 67%|██████▋   | 2002/3000 [17:55<13:15,  1.25it/s] 67%|██████▋   | 2003/3000 [17:56<11:39,  1.43it/s] 67%|██████▋   | 2004/3000 [17:56<10:32,  1.58it/s] 67%|██████▋   | 2005/3000 [17:57<09:43,  1.71it/s] 67%|██████▋   | 2006/3000 [17:57<09:08,  1.81it/s] 67%|██████▋   | 2007/3000 [17:58<08:44,  1.89it/s] 67%|██████▋   | 2008/3000 [17:58<08:29,  1.95it/s] 67%|██████▋   | 2009/3000 [17:58<08:17,  1.99it/s] 67%|██████▋   | 2010/3000 [17:59<08:09,  2.02it/s] 67%|██████▋   | 2011/3000 [17:59<08:03,  2.05it/s] 67%|██████▋   | 2012/3000 [18:00<07:58,  2.07it/s] 67%|██████▋   | 2013/3000 [18:00<07:54,  2.08it/s] 67%|██████▋   | 2014/3000 [18:01<07:52,  2.08it/s] 67%|██████▋   | 2015/3000 [18:01<07:51,  2.09it/s] 67%|██████▋   | 2016/3000 [18:02<07:49,  2.10it/s] 67%|██████▋   | 2017/3000 [18:02<07:47,  2.10it/s] 67%|██████▋   | 2018/3000 [18:03<07:46,  2.11it/s] 67%|██████▋   | 2019/3000 [18:03<07:46,  2.10it/s] 67%|██████▋   | 2020/3000 [18:04<07:47,  2.10it/s] 67%|██████▋   | 2021/3000 [18:04<07:46,  2.10it/s] 67%|██████▋   | 2022/3000 [18:05<07:44,  2.10it/s] 67%|██████▋   | 2023/3000 [18:05<07:43,  2.11it/s] 67%|██████▋   | 2024/3000 [18:06<07:43,  2.11it/s] 68%|██████▊   | 2025/3000 [18:06<07:42,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:43:02,546 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:43:02,547 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:43:02,547 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:43:02,547 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 80.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.30it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.23it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.80it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.66it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:43:04 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 68%|██████▊   | 2025/3000 [18:08<07:42,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.7087011933326721, 'eval_accuracy': 0.84, 'eval_runtime': 1.5328, 'eval_samples_per_second': 65.241, 'eval_steps_per_second': 8.481, 'epoch': 81.0}
12/07/2022 13:43:04 - INFO - training.trainer_base - ***** Epoch 80: Best results *****
12/07/2022 13:43:04 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:43:04 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:43:04 - INFO - training.trainer_base - epoch = 80.0
                                                    68%|██████▊   | 2025/3000 [18:08<07:42,  2.11it/s] 68%|██████▊   | 2026/3000 [18:08<15:11,  1.07it/s] 68%|██████▊   | 2027/3000 [18:09<12:57,  1.25it/s] 68%|██████▊   | 2028/3000 [18:09<11:21,  1.43it/s] 68%|██████▊   | 2029/3000 [18:10<10:15,  1.58it/s] 68%|██████▊   | 2030/3000 [18:10<09:28,  1.71it/s] 68%|██████▊   | 2031/3000 [18:10<08:55,  1.81it/s] 68%|██████▊   | 2032/3000 [18:11<08:33,  1.88it/s] 68%|██████▊   | 2033/3000 [18:11<08:17,  1.95it/s] 68%|██████▊   | 2034/3000 [18:12<08:05,  1.99it/s] 68%|██████▊   | 2035/3000 [18:12<07:55,  2.03it/s] 68%|██████▊   | 2036/3000 [18:13<07:49,  2.05it/s] 68%|██████▊   | 2037/3000 [18:13<07:45,  2.07it/s] 68%|██████▊   | 2038/3000 [18:14<07:44,  2.07it/s] 68%|██████▊   | 2039/3000 [18:14<07:42,  2.08it/s] 68%|██████▊   | 2040/3000 [18:15<07:40,  2.09it/s] 68%|██████▊   | 2041/3000 [18:15<07:37,  2.09it/s] 68%|██████▊   | 2042/3000 [18:16<07:36,  2.10it/s] 68%|██████▊   | 2043/3000 [18:16<07:36,  2.09it/s] 68%|██████▊   | 2044/3000 [18:17<07:36,  2.10it/s] 68%|██████▊   | 2045/3000 [18:17<07:35,  2.10it/s] 68%|██████▊   | 2046/3000 [18:18<07:35,  2.10it/s] 68%|██████▊   | 2047/3000 [18:18<07:33,  2.10it/s] 68%|██████▊   | 2048/3000 [18:19<07:33,  2.10it/s] 68%|██████▊   | 2049/3000 [18:19<07:33,  2.10it/s] 68%|██████▊   | 2050/3000 [18:20<07:32,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:43:15,982 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:43:15,984 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:43:15,984 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:43:15,984 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 81.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.57it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.40it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.30it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.86it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.72it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.60it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.45it/s][A12/07/2022 13:43:17 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 68%|██████▊   | 2050/3000 [18:21<07:32,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.45it/s][A
                                               [A{'eval_loss': 0.7481544613838196, 'eval_accuracy': 0.84, 'eval_runtime': 1.5244, 'eval_samples_per_second': 65.601, 'eval_steps_per_second': 8.528, 'epoch': 82.0}
12/07/2022 13:43:17 - INFO - training.trainer_base - ***** Epoch 81: Best results *****
12/07/2022 13:43:17 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:43:17 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:43:17 - INFO - training.trainer_base - epoch = 81.0
                                                    68%|██████▊   | 2050/3000 [18:21<07:32,  2.10it/s] 68%|██████▊   | 2051/3000 [18:22<14:47,  1.07it/s] 68%|██████▊   | 2052/3000 [18:22<12:35,  1.25it/s] 68%|██████▊   | 2053/3000 [18:22<11:04,  1.42it/s] 68%|██████▊   | 2054/3000 [18:23<10:00,  1.58it/s] 68%|██████▊   | 2055/3000 [18:23<09:14,  1.70it/s] 69%|██████▊   | 2056/3000 [18:24<08:41,  1.81it/s] 69%|██████▊   | 2057/3000 [18:24<08:19,  1.89it/s] 69%|██████▊   | 2058/3000 [18:25<08:03,  1.95it/s] 69%|██████▊   | 2059/3000 [18:25<07:53,  1.99it/s] 69%|██████▊   | 2060/3000 [18:26<07:45,  2.02it/s] 69%|██████▊   | 2061/3000 [18:26<07:39,  2.04it/s] 69%|██████▊   | 2062/3000 [18:27<07:34,  2.07it/s] 69%|██████▉   | 2063/3000 [18:27<07:31,  2.08it/s] 69%|██████▉   | 2064/3000 [18:28<07:29,  2.08it/s] 69%|██████▉   | 2065/3000 [18:28<07:27,  2.09it/s] 69%|██████▉   | 2066/3000 [18:29<07:27,  2.09it/s] 69%|██████▉   | 2067/3000 [18:29<07:25,  2.09it/s] 69%|██████▉   | 2068/3000 [18:30<07:24,  2.10it/s] 69%|██████▉   | 2069/3000 [18:30<07:23,  2.10it/s] 69%|██████▉   | 2070/3000 [18:31<07:23,  2.10it/s] 69%|██████▉   | 2071/3000 [18:31<07:21,  2.10it/s] 69%|██████▉   | 2072/3000 [18:32<07:20,  2.11it/s] 69%|██████▉   | 2073/3000 [18:32<07:20,  2.11it/s] 69%|██████▉   | 2074/3000 [18:32<07:19,  2.11it/s] 69%|██████▉   | 2075/3000 [18:33<07:19,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:43:29,402 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:43:29,404 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:43:29,404 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:43:29,404 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 82.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:43:30 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 69%|██████▉   | 2075/3000 [18:34<07:19,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.6782359480857849, 'eval_accuracy': 0.83, 'eval_runtime': 1.5347, 'eval_samples_per_second': 65.161, 'eval_steps_per_second': 8.471, 'epoch': 83.0}
12/07/2022 13:43:30 - INFO - training.trainer_base - ***** Epoch 82: Best results *****
12/07/2022 13:43:30 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:43:30 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:43:30 - INFO - training.trainer_base - epoch = 82.0
                                                    69%|██████▉   | 2075/3000 [18:34<07:19,  2.11it/s] 69%|██████▉   | 2076/3000 [18:35<14:26,  1.07it/s] 69%|██████▉   | 2077/3000 [18:35<12:17,  1.25it/s] 69%|██████▉   | 2078/3000 [18:36<10:46,  1.43it/s] 69%|██████▉   | 2079/3000 [18:36<09:42,  1.58it/s] 69%|██████▉   | 2080/3000 [18:37<08:58,  1.71it/s] 69%|██████▉   | 2081/3000 [18:37<08:28,  1.81it/s] 69%|██████▉   | 2082/3000 [18:38<08:06,  1.89it/s] 69%|██████▉   | 2083/3000 [18:38<07:50,  1.95it/s] 69%|██████▉   | 2084/3000 [18:39<07:38,  2.00it/s] 70%|██████▉   | 2085/3000 [18:39<07:31,  2.03it/s] 70%|██████▉   | 2086/3000 [18:40<07:28,  2.04it/s] 70%|██████▉   | 2087/3000 [18:40<07:24,  2.05it/s] 70%|██████▉   | 2088/3000 [18:41<07:20,  2.07it/s] 70%|██████▉   | 2089/3000 [18:41<07:18,  2.08it/s] 70%|██████▉   | 2090/3000 [18:42<07:16,  2.08it/s] 70%|██████▉   | 2091/3000 [18:42<07:15,  2.09it/s] 70%|██████▉   | 2092/3000 [18:43<07:12,  2.10it/s] 70%|██████▉   | 2093/3000 [18:43<07:11,  2.10it/s] 70%|██████▉   | 2094/3000 [18:44<07:10,  2.10it/s] 70%|██████▉   | 2095/3000 [18:44<07:10,  2.10it/s] 70%|██████▉   | 2096/3000 [18:44<07:09,  2.10it/s] 70%|██████▉   | 2097/3000 [18:45<07:09,  2.10it/s] 70%|██████▉   | 2098/3000 [18:45<07:09,  2.10it/s] 70%|██████▉   | 2099/3000 [18:46<07:08,  2.10it/s] 70%|███████   | 2100/3000 [18:46<07:08,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:43:42,837 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:43:42,839 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:43:42,839 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:43:42,839 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 83.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.44it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.39it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.60it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:43:44 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 70%|███████   | 2100/3000 [18:48<07:08,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.6580595970153809, 'eval_accuracy': 0.83, 'eval_runtime': 1.528, 'eval_samples_per_second': 65.447, 'eval_steps_per_second': 8.508, 'epoch': 84.0}
12/07/2022 13:43:44 - INFO - training.trainer_base - ***** Epoch 83: Best results *****
12/07/2022 13:43:44 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:43:44 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:43:44 - INFO - training.trainer_base - epoch = 83.0
                                                    70%|███████   | 2100/3000 [18:48<07:08,  2.10it/s] 70%|███████   | 2101/3000 [18:48<14:01,  1.07it/s] 70%|███████   | 2102/3000 [18:49<11:56,  1.25it/s] 70%|███████   | 2103/3000 [18:49<10:28,  1.43it/s] 70%|███████   | 2104/3000 [18:50<09:26,  1.58it/s] 70%|███████   | 2105/3000 [18:50<08:42,  1.71it/s] 70%|███████   | 2106/3000 [18:51<08:13,  1.81it/s] 70%|███████   | 2107/3000 [18:51<07:52,  1.89it/s] 70%|███████   | 2108/3000 [18:52<07:37,  1.95it/s] 70%|███████   | 2109/3000 [18:52<07:25,  2.00it/s] 70%|███████   | 2110/3000 [18:53<07:19,  2.03it/s] 70%|███████   | 2111/3000 [18:53<07:14,  2.05it/s] 70%|███████   | 2112/3000 [18:54<07:11,  2.06it/s] 70%|███████   | 2113/3000 [18:54<07:08,  2.07it/s] 70%|███████   | 2114/3000 [18:55<07:05,  2.08it/s] 70%|███████   | 2115/3000 [18:55<07:03,  2.09it/s] 71%|███████   | 2116/3000 [18:56<07:02,  2.09it/s] 71%|███████   | 2117/3000 [18:56<07:00,  2.10it/s] 71%|███████   | 2118/3000 [18:56<07:00,  2.10it/s] 71%|███████   | 2119/3000 [18:57<06:58,  2.10it/s] 71%|███████   | 2120/3000 [18:57<06:57,  2.11it/s] 71%|███████   | 2121/3000 [18:58<06:56,  2.11it/s] 71%|███████   | 2122/3000 [18:58<06:55,  2.11it/s] 71%|███████   | 2123/3000 [18:59<06:56,  2.11it/s] 71%|███████   | 2124/3000 [18:59<06:56,  2.11it/s] 71%|███████   | 2125/3000 [19:00<06:54,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:43:56,240 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:43:56,241 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:43:56,242 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:43:56,242 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 84.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.50it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.40it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:43:57 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 71%|███████   | 2125/3000 [19:01<06:54,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.6901969313621521, 'eval_accuracy': 0.84, 'eval_runtime': 1.5296, 'eval_samples_per_second': 65.377, 'eval_steps_per_second': 8.499, 'epoch': 85.0}
12/07/2022 13:43:57 - INFO - training.trainer_base - ***** Epoch 84: Best results *****
12/07/2022 13:43:57 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:43:57 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:43:57 - INFO - training.trainer_base - epoch = 84.0
                                                    71%|███████   | 2125/3000 [19:01<06:54,  2.11it/s] 71%|███████   | 2126/3000 [19:02<13:36,  1.07it/s] 71%|███████   | 2127/3000 [19:02<11:35,  1.26it/s] 71%|███████   | 2128/3000 [19:03<10:10,  1.43it/s] 71%|███████   | 2129/3000 [19:03<09:11,  1.58it/s] 71%|███████   | 2130/3000 [19:04<08:29,  1.71it/s] 71%|███████   | 2131/3000 [19:04<08:00,  1.81it/s] 71%|███████   | 2132/3000 [19:05<07:39,  1.89it/s] 71%|███████   | 2133/3000 [19:05<07:24,  1.95it/s] 71%|███████   | 2134/3000 [19:06<07:14,  1.99it/s] 71%|███████   | 2135/3000 [19:06<07:07,  2.02it/s] 71%|███████   | 2136/3000 [19:07<07:02,  2.05it/s] 71%|███████   | 2137/3000 [19:07<06:57,  2.07it/s] 71%|███████▏  | 2138/3000 [19:07<06:54,  2.08it/s] 71%|███████▏  | 2139/3000 [19:08<06:52,  2.09it/s] 71%|███████▏  | 2140/3000 [19:08<06:51,  2.09it/s] 71%|███████▏  | 2141/3000 [19:09<06:50,  2.09it/s] 71%|███████▏  | 2142/3000 [19:09<06:49,  2.09it/s] 71%|███████▏  | 2143/3000 [19:10<06:48,  2.10it/s] 71%|███████▏  | 2144/3000 [19:10<06:47,  2.10it/s] 72%|███████▏  | 2145/3000 [19:11<06:47,  2.10it/s] 72%|███████▏  | 2146/3000 [19:11<06:46,  2.10it/s] 72%|███████▏  | 2147/3000 [19:12<06:46,  2.10it/s] 72%|███████▏  | 2148/3000 [19:12<06:45,  2.10it/s] 72%|███████▏  | 2149/3000 [19:13<06:44,  2.10it/s] 72%|███████▏  | 2150/3000 [19:13<06:44,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:44:09,664 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:44:09,665 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:44:09,665 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:44:09,665 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 85.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.48it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.36it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:44:11 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 72%|███████▏  | 2150/3000 [19:15<06:44,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.7254497408866882, 'eval_accuracy': 0.84, 'eval_runtime': 1.5275, 'eval_samples_per_second': 65.466, 'eval_steps_per_second': 8.511, 'epoch': 86.0}
12/07/2022 13:44:11 - INFO - training.trainer_base - ***** Epoch 85: Best results *****
12/07/2022 13:44:11 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:44:11 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:44:11 - INFO - training.trainer_base - epoch = 85.0
                                                    72%|███████▏  | 2150/3000 [19:15<06:44,  2.10it/s] 72%|███████▏  | 2151/3000 [19:15<13:14,  1.07it/s] 72%|███████▏  | 2152/3000 [19:16<11:18,  1.25it/s] 72%|███████▏  | 2153/3000 [19:16<09:55,  1.42it/s] 72%|███████▏  | 2154/3000 [19:17<08:56,  1.58it/s] 72%|███████▏  | 2155/3000 [19:17<08:15,  1.71it/s] 72%|███████▏  | 2156/3000 [19:18<07:47,  1.81it/s] 72%|███████▏  | 2157/3000 [19:18<07:27,  1.88it/s] 72%|███████▏  | 2158/3000 [19:19<07:12,  1.94it/s] 72%|███████▏  | 2159/3000 [19:19<07:01,  2.00it/s] 72%|███████▏  | 2160/3000 [19:19<06:53,  2.03it/s] 72%|███████▏  | 2161/3000 [19:20<06:48,  2.05it/s] 72%|███████▏  | 2162/3000 [19:20<06:45,  2.07it/s] 72%|███████▏  | 2163/3000 [19:21<06:43,  2.08it/s] 72%|███████▏  | 2164/3000 [19:21<06:41,  2.08it/s] 72%|███████▏  | 2165/3000 [19:22<06:39,  2.09it/s] 72%|███████▏  | 2166/3000 [19:22<06:37,  2.10it/s] 72%|███████▏  | 2167/3000 [19:23<06:37,  2.10it/s] 72%|███████▏  | 2168/3000 [19:23<06:36,  2.10it/s] 72%|███████▏  | 2169/3000 [19:24<06:35,  2.10it/s] 72%|███████▏  | 2170/3000 [19:24<06:33,  2.11it/s] 72%|███████▏  | 2171/3000 [19:25<06:33,  2.11it/s] 72%|███████▏  | 2172/3000 [19:25<06:32,  2.11it/s] 72%|███████▏  | 2173/3000 [19:26<06:33,  2.10it/s] 72%|███████▏  | 2174/3000 [19:26<06:34,  2.10it/s] 72%|███████▎  | 2175/3000 [19:27<06:33,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:44:23,088 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:44:23,089 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:44:23,089 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:44:23,089 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 86.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.41it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.35it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.79it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.66it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:44:24 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 72%|███████▎  | 2175/3000 [19:28<06:33,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.7375567555427551, 'eval_accuracy': 0.85, 'eval_runtime': 1.5309, 'eval_samples_per_second': 65.32, 'eval_steps_per_second': 8.492, 'epoch': 87.0}
12/07/2022 13:44:24 - INFO - training.trainer_base - ***** Epoch 86: Best results *****
12/07/2022 13:44:24 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:44:24 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:44:24 - INFO - training.trainer_base - epoch = 86.0
                                                    72%|███████▎  | 2175/3000 [19:28<06:33,  2.10it/s] 73%|███████▎  | 2176/3000 [19:29<12:52,  1.07it/s] 73%|███████▎  | 2177/3000 [19:29<10:57,  1.25it/s] 73%|███████▎  | 2178/3000 [19:30<09:36,  1.43it/s] 73%|███████▎  | 2179/3000 [19:30<08:40,  1.58it/s] 73%|███████▎  | 2180/3000 [19:31<08:00,  1.71it/s] 73%|███████▎  | 2181/3000 [19:31<07:32,  1.81it/s] 73%|███████▎  | 2182/3000 [19:31<07:12,  1.89it/s] 73%|███████▎  | 2183/3000 [19:32<06:58,  1.95it/s] 73%|███████▎  | 2184/3000 [19:32<06:48,  2.00it/s] 73%|███████▎  | 2185/3000 [19:33<06:42,  2.02it/s] 73%|███████▎  | 2186/3000 [19:33<06:37,  2.05it/s] 73%|███████▎  | 2187/3000 [19:34<06:33,  2.07it/s] 73%|███████▎  | 2188/3000 [19:34<06:30,  2.08it/s] 73%|███████▎  | 2189/3000 [19:35<06:28,  2.09it/s] 73%|███████▎  | 2190/3000 [19:35<06:27,  2.09it/s] 73%|███████▎  | 2191/3000 [19:36<06:26,  2.09it/s] 73%|███████▎  | 2192/3000 [19:36<06:25,  2.10it/s] 73%|███████▎  | 2193/3000 [19:37<06:24,  2.10it/s] 73%|███████▎  | 2194/3000 [19:37<06:24,  2.10it/s] 73%|███████▎  | 2195/3000 [19:38<06:24,  2.09it/s] 73%|███████▎  | 2196/3000 [19:38<06:24,  2.09it/s] 73%|███████▎  | 2197/3000 [19:39<06:23,  2.09it/s] 73%|███████▎  | 2198/3000 [19:39<06:22,  2.10it/s] 73%|███████▎  | 2199/3000 [19:40<06:21,  2.10it/s] 73%|███████▎  | 2200/3000 [19:40<06:21,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:44:36,516 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:44:36,518 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:44:36,518 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:44:36,518 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 87.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.50it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:44:38 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 73%|███████▎  | 2200/3000 [19:42<06:21,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.7519900798797607, 'eval_accuracy': 0.85, 'eval_runtime': 1.5311, 'eval_samples_per_second': 65.314, 'eval_steps_per_second': 8.491, 'epoch': 88.0}
12/07/2022 13:44:38 - INFO - training.trainer_base - ***** Epoch 87: Best results *****
12/07/2022 13:44:38 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:44:38 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:44:38 - INFO - training.trainer_base - epoch = 87.0
                                                    73%|███████▎  | 2200/3000 [19:42<06:21,  2.10it/s] 73%|███████▎  | 2201/3000 [19:42<12:28,  1.07it/s] 73%|███████▎  | 2202/3000 [19:43<10:37,  1.25it/s] 73%|███████▎  | 2203/3000 [19:43<09:19,  1.42it/s] 73%|███████▎  | 2204/3000 [19:43<08:24,  1.58it/s] 74%|███████▎  | 2205/3000 [19:44<07:46,  1.71it/s] 74%|███████▎  | 2206/3000 [19:44<07:19,  1.81it/s] 74%|███████▎  | 2207/3000 [19:45<07:01,  1.88it/s] 74%|███████▎  | 2208/3000 [19:45<06:47,  1.95it/s] 74%|███████▎  | 2209/3000 [19:46<06:37,  1.99it/s] 74%|███████▎  | 2210/3000 [19:46<06:30,  2.02it/s] 74%|███████▎  | 2211/3000 [19:47<06:26,  2.04it/s] 74%|███████▎  | 2212/3000 [19:47<06:22,  2.06it/s] 74%|███████▍  | 2213/3000 [19:48<06:18,  2.08it/s] 74%|███████▍  | 2214/3000 [19:48<06:16,  2.09it/s] 74%|███████▍  | 2215/3000 [19:49<06:15,  2.09it/s] 74%|███████▍  | 2216/3000 [19:49<06:14,  2.09it/s] 74%|███████▍  | 2217/3000 [19:50<06:13,  2.10it/s] 74%|███████▍  | 2218/3000 [19:50<06:12,  2.10it/s] 74%|███████▍  | 2219/3000 [19:51<06:12,  2.10it/s] 74%|███████▍  | 2220/3000 [19:51<06:12,  2.09it/s] 74%|███████▍  | 2221/3000 [19:52<06:12,  2.09it/s] 74%|███████▍  | 2222/3000 [19:52<06:10,  2.10it/s] 74%|███████▍  | 2223/3000 [19:53<06:08,  2.11it/s] 74%|███████▍  | 2224/3000 [19:53<06:08,  2.11it/s] 74%|███████▍  | 2225/3000 [19:53<06:08,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:44:49,942 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:44:49,944 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:44:49,944 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:44:49,944 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 88.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.35it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:44:51 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 74%|███████▍  | 2225/3000 [19:55<06:08,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.7451955676078796, 'eval_accuracy': 0.86, 'eval_runtime': 1.5296, 'eval_samples_per_second': 65.376, 'eval_steps_per_second': 8.499, 'epoch': 89.0}
12/07/2022 13:44:51 - INFO - training.trainer_base - ***** Epoch 88: Best results *****
12/07/2022 13:44:51 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:44:51 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:44:51 - INFO - training.trainer_base - epoch = 88.0
                                                    74%|███████▍  | 2225/3000 [19:55<06:08,  2.10it/s] 74%|███████▍  | 2226/3000 [19:55<12:04,  1.07it/s] 74%|███████▍  | 2227/3000 [19:56<10:17,  1.25it/s] 74%|███████▍  | 2228/3000 [19:56<09:01,  1.43it/s] 74%|███████▍  | 2229/3000 [19:57<08:07,  1.58it/s] 74%|███████▍  | 2230/3000 [19:57<07:31,  1.71it/s] 74%|███████▍  | 2231/3000 [19:58<07:05,  1.81it/s] 74%|███████▍  | 2232/3000 [19:58<06:47,  1.88it/s] 74%|███████▍  | 2233/3000 [19:59<06:34,  1.94it/s] 74%|███████▍  | 2234/3000 [19:59<06:24,  1.99it/s] 74%|███████▍  | 2235/3000 [20:00<06:17,  2.03it/s] 75%|███████▍  | 2236/3000 [20:00<06:12,  2.05it/s] 75%|███████▍  | 2237/3000 [20:01<06:09,  2.06it/s] 75%|███████▍  | 2238/3000 [20:01<06:07,  2.07it/s] 75%|███████▍  | 2239/3000 [20:02<06:05,  2.08it/s] 75%|███████▍  | 2240/3000 [20:02<06:04,  2.09it/s] 75%|███████▍  | 2241/3000 [20:03<06:03,  2.09it/s] 75%|███████▍  | 2242/3000 [20:03<06:02,  2.09it/s] 75%|███████▍  | 2243/3000 [20:04<06:01,  2.09it/s] 75%|███████▍  | 2244/3000 [20:04<06:01,  2.09it/s] 75%|███████▍  | 2245/3000 [20:05<05:59,  2.10it/s] 75%|███████▍  | 2246/3000 [20:05<05:58,  2.10it/s] 75%|███████▍  | 2247/3000 [20:05<05:58,  2.10it/s] 75%|███████▍  | 2248/3000 [20:06<05:58,  2.10it/s] 75%|███████▍  | 2249/3000 [20:06<05:57,  2.10it/s] 75%|███████▌  | 2250/3000 [20:07<05:56,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:45:03,375 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:45:03,377 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:45:03,377 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:45:03,377 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 89.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.52it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:45:04 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 75%|███████▌  | 2250/3000 [20:08<05:56,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.7409019470214844, 'eval_accuracy': 0.85, 'eval_runtime': 1.5314, 'eval_samples_per_second': 65.298, 'eval_steps_per_second': 8.489, 'epoch': 90.0}
12/07/2022 13:45:04 - INFO - training.trainer_base - ***** Epoch 89: Best results *****
12/07/2022 13:45:04 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:45:04 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:45:04 - INFO - training.trainer_base - epoch = 89.0
                                                    75%|███████▌  | 2250/3000 [20:08<05:56,  2.10it/s] 75%|███████▌  | 2251/3000 [20:09<11:41,  1.07it/s] 75%|███████▌  | 2252/3000 [20:09<09:56,  1.25it/s] 75%|███████▌  | 2253/3000 [20:10<08:43,  1.43it/s] 75%|███████▌  | 2254/3000 [20:10<07:52,  1.58it/s] 75%|███████▌  | 2255/3000 [20:11<07:17,  1.70it/s] 75%|███████▌  | 2256/3000 [20:11<06:51,  1.81it/s] 75%|███████▌  | 2257/3000 [20:12<06:32,  1.89it/s] 75%|███████▌  | 2258/3000 [20:12<06:20,  1.95it/s] 75%|███████▌  | 2259/3000 [20:13<06:12,  1.99it/s] 75%|███████▌  | 2260/3000 [20:13<06:06,  2.02it/s] 75%|███████▌  | 2261/3000 [20:14<06:02,  2.04it/s] 75%|███████▌  | 2262/3000 [20:14<05:57,  2.06it/s] 75%|███████▌  | 2263/3000 [20:15<05:54,  2.08it/s] 75%|███████▌  | 2264/3000 [20:15<05:53,  2.08it/s] 76%|███████▌  | 2265/3000 [20:16<05:52,  2.09it/s] 76%|███████▌  | 2266/3000 [20:16<05:50,  2.09it/s] 76%|███████▌  | 2267/3000 [20:17<05:49,  2.10it/s] 76%|███████▌  | 2268/3000 [20:17<05:47,  2.10it/s] 76%|███████▌  | 2269/3000 [20:17<05:47,  2.10it/s] 76%|███████▌  | 2270/3000 [20:18<05:47,  2.10it/s] 76%|███████▌  | 2271/3000 [20:18<05:46,  2.10it/s] 76%|███████▌  | 2272/3000 [20:19<05:45,  2.11it/s] 76%|███████▌  | 2273/3000 [20:19<05:44,  2.11it/s] 76%|███████▌  | 2274/3000 [20:20<05:44,  2.11it/s] 76%|███████▌  | 2275/3000 [20:20<05:44,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:45:16,790 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:45:16,791 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:45:16,792 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:45:16,792 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 90.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.27it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.33it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.24it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:45:18 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 76%|███████▌  | 2275/3000 [20:22<05:44,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.7478438019752502, 'eval_accuracy': 0.84, 'eval_runtime': 1.5303, 'eval_samples_per_second': 65.346, 'eval_steps_per_second': 8.495, 'epoch': 91.0}
12/07/2022 13:45:18 - INFO - training.trainer_base - ***** Epoch 90: Best results *****
12/07/2022 13:45:18 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:45:18 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:45:18 - INFO - training.trainer_base - epoch = 90.0
                                                    76%|███████▌  | 2275/3000 [20:22<05:44,  2.11it/s] 76%|███████▌  | 2276/3000 [20:22<11:17,  1.07it/s] 76%|███████▌  | 2277/3000 [20:23<09:37,  1.25it/s] 76%|███████▌  | 2278/3000 [20:23<08:25,  1.43it/s] 76%|███████▌  | 2279/3000 [20:24<07:36,  1.58it/s] 76%|███████▌  | 2280/3000 [20:24<07:01,  1.71it/s] 76%|███████▌  | 2281/3000 [20:25<06:37,  1.81it/s] 76%|███████▌  | 2282/3000 [20:25<06:20,  1.89it/s] 76%|███████▌  | 2283/3000 [20:26<06:09,  1.94it/s] 76%|███████▌  | 2284/3000 [20:26<05:59,  1.99it/s] 76%|███████▌  | 2285/3000 [20:27<05:53,  2.02it/s] 76%|███████▌  | 2286/3000 [20:27<05:48,  2.05it/s] 76%|███████▌  | 2287/3000 [20:28<05:45,  2.06it/s] 76%|███████▋  | 2288/3000 [20:28<05:44,  2.07it/s] 76%|███████▋  | 2289/3000 [20:29<05:41,  2.08it/s] 76%|███████▋  | 2290/3000 [20:29<05:39,  2.09it/s] 76%|███████▋  | 2291/3000 [20:29<05:38,  2.10it/s] 76%|███████▋  | 2292/3000 [20:30<05:37,  2.10it/s] 76%|███████▋  | 2293/3000 [20:30<05:37,  2.10it/s] 76%|███████▋  | 2294/3000 [20:31<05:37,  2.09it/s] 76%|███████▋  | 2295/3000 [20:31<05:36,  2.10it/s] 77%|███████▋  | 2296/3000 [20:32<05:34,  2.10it/s] 77%|███████▋  | 2297/3000 [20:32<05:34,  2.10it/s] 77%|███████▋  | 2298/3000 [20:33<05:34,  2.10it/s] 77%|███████▋  | 2299/3000 [20:33<05:34,  2.10it/s] 77%|███████▋  | 2300/3000 [20:34<05:33,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:45:30,221 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:45:30,222 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:45:30,223 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:45:30,223 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 91.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.54it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.72it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.60it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:45:31 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 77%|███████▋  | 2300/3000 [20:35<05:33,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.7682397961616516, 'eval_accuracy': 0.83, 'eval_runtime': 1.5271, 'eval_samples_per_second': 65.483, 'eval_steps_per_second': 8.513, 'epoch': 92.0}
12/07/2022 13:45:31 - INFO - training.trainer_base - ***** Epoch 91: Best results *****
12/07/2022 13:45:31 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:45:31 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:45:31 - INFO - training.trainer_base - epoch = 91.0
                                                    77%|███████▋  | 2300/3000 [20:35<05:33,  2.10it/s] 77%|███████▋  | 2301/3000 [20:36<10:53,  1.07it/s] 77%|███████▋  | 2302/3000 [20:36<09:16,  1.25it/s] 77%|███████▋  | 2303/3000 [20:37<08:08,  1.43it/s] 77%|███████▋  | 2304/3000 [20:37<07:21,  1.58it/s] 77%|███████▋  | 2305/3000 [20:38<06:48,  1.70it/s] 77%|███████▋  | 2306/3000 [20:38<06:24,  1.81it/s] 77%|███████▋  | 2307/3000 [20:39<06:06,  1.89it/s] 77%|███████▋  | 2308/3000 [20:39<05:55,  1.95it/s] 77%|███████▋  | 2309/3000 [20:40<05:47,  1.99it/s] 77%|███████▋  | 2310/3000 [20:40<05:41,  2.02it/s] 77%|███████▋  | 2311/3000 [20:41<05:36,  2.05it/s] 77%|███████▋  | 2312/3000 [20:41<05:32,  2.07it/s] 77%|███████▋  | 2313/3000 [20:41<05:29,  2.08it/s] 77%|███████▋  | 2314/3000 [20:42<05:27,  2.09it/s] 77%|███████▋  | 2315/3000 [20:42<05:27,  2.09it/s] 77%|███████▋  | 2316/3000 [20:43<05:25,  2.10it/s] 77%|███████▋  | 2317/3000 [20:43<05:24,  2.10it/s] 77%|███████▋  | 2318/3000 [20:44<05:24,  2.10it/s] 77%|███████▋  | 2319/3000 [20:44<05:24,  2.10it/s] 77%|███████▋  | 2320/3000 [20:45<05:24,  2.10it/s] 77%|███████▋  | 2321/3000 [20:45<05:23,  2.10it/s] 77%|███████▋  | 2322/3000 [20:46<05:22,  2.10it/s] 77%|███████▋  | 2323/3000 [20:46<05:21,  2.11it/s] 77%|███████▋  | 2324/3000 [20:47<05:22,  2.09it/s] 78%|███████▊  | 2325/3000 [20:47<05:24,  2.08it/s][INFO|trainer.py:540] 2022-12-07 13:45:43,651 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:45:43,653 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:45:43,653 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:45:43,653 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 92.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.54it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.39it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:45:45 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 78%|███████▊  | 2325/3000 [20:49<05:24,  2.08it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.7905158400535583, 'eval_accuracy': 0.83, 'eval_runtime': 1.5278, 'eval_samples_per_second': 65.454, 'eval_steps_per_second': 8.509, 'epoch': 93.0}
12/07/2022 13:45:45 - INFO - training.trainer_base - ***** Epoch 92: Best results *****
12/07/2022 13:45:45 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:45:45 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:45:45 - INFO - training.trainer_base - epoch = 92.0
                                                    78%|███████▊  | 2325/3000 [20:49<05:24,  2.08it/s] 78%|███████▊  | 2326/3000 [20:49<10:32,  1.07it/s] 78%|███████▊  | 2327/3000 [20:50<08:57,  1.25it/s] 78%|███████▊  | 2328/3000 [20:50<07:51,  1.43it/s] 78%|███████▊  | 2329/3000 [20:51<07:04,  1.58it/s] 78%|███████▊  | 2330/3000 [20:51<06:32,  1.71it/s] 78%|███████▊  | 2331/3000 [20:52<06:10,  1.81it/s] 78%|███████▊  | 2332/3000 [20:52<05:54,  1.89it/s] 78%|███████▊  | 2333/3000 [20:53<05:42,  1.95it/s] 78%|███████▊  | 2334/3000 [20:53<05:34,  1.99it/s] 78%|███████▊  | 2335/3000 [20:53<05:28,  2.03it/s] 78%|███████▊  | 2336/3000 [20:54<05:25,  2.04it/s] 78%|███████▊  | 2337/3000 [20:54<05:21,  2.06it/s] 78%|███████▊  | 2338/3000 [20:55<05:18,  2.08it/s] 78%|███████▊  | 2339/3000 [20:55<05:17,  2.08it/s] 78%|███████▊  | 2340/3000 [20:56<05:16,  2.09it/s] 78%|███████▊  | 2341/3000 [20:56<05:14,  2.09it/s] 78%|███████▊  | 2342/3000 [20:57<05:13,  2.10it/s] 78%|███████▊  | 2343/3000 [20:57<05:12,  2.10it/s] 78%|███████▊  | 2344/3000 [20:58<05:12,  2.10it/s] 78%|███████▊  | 2345/3000 [20:58<05:12,  2.10it/s] 78%|███████▊  | 2346/3000 [20:59<05:10,  2.11it/s] 78%|███████▊  | 2347/3000 [20:59<05:09,  2.11it/s] 78%|███████▊  | 2348/3000 [21:00<05:09,  2.11it/s] 78%|███████▊  | 2349/3000 [21:00<05:08,  2.11it/s] 78%|███████▊  | 2350/3000 [21:01<05:08,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:45:57,060 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:45:57,062 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:45:57,062 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:45:57,062 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 93.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.43it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.30it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.81it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:45:58 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 78%|███████▊  | 2350/3000 [21:02<05:08,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.8309404253959656, 'eval_accuracy': 0.83, 'eval_runtime': 1.5313, 'eval_samples_per_second': 65.304, 'eval_steps_per_second': 8.49, 'epoch': 94.0}
12/07/2022 13:45:58 - INFO - training.trainer_base - ***** Epoch 93: Best results *****
12/07/2022 13:45:58 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:45:58 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:45:58 - INFO - training.trainer_base - epoch = 93.0
                                                    78%|███████▊  | 2350/3000 [21:02<05:08,  2.11it/s] 78%|███████▊  | 2351/3000 [21:03<10:06,  1.07it/s] 78%|███████▊  | 2352/3000 [21:03<08:36,  1.26it/s] 78%|███████▊  | 2353/3000 [21:04<07:32,  1.43it/s] 78%|███████▊  | 2354/3000 [21:04<06:48,  1.58it/s] 78%|███████▊  | 2355/3000 [21:04<06:17,  1.71it/s] 79%|███████▊  | 2356/3000 [21:05<05:56,  1.81it/s] 79%|███████▊  | 2357/3000 [21:05<05:39,  1.89it/s] 79%|███████▊  | 2358/3000 [21:06<05:28,  1.96it/s] 79%|███████▊  | 2359/3000 [21:06<05:20,  2.00it/s] 79%|███████▊  | 2360/3000 [21:07<05:15,  2.03it/s] 79%|███████▊  | 2361/3000 [21:07<05:12,  2.04it/s] 79%|███████▊  | 2362/3000 [21:08<05:08,  2.07it/s] 79%|███████▉  | 2363/3000 [21:08<05:06,  2.08it/s] 79%|███████▉  | 2364/3000 [21:09<05:04,  2.09it/s] 79%|███████▉  | 2365/3000 [21:09<05:03,  2.09it/s] 79%|███████▉  | 2366/3000 [21:10<05:02,  2.09it/s] 79%|███████▉  | 2367/3000 [21:10<05:02,  2.09it/s] 79%|███████▉  | 2368/3000 [21:11<05:00,  2.10it/s] 79%|███████▉  | 2369/3000 [21:11<04:59,  2.11it/s] 79%|███████▉  | 2370/3000 [21:12<04:58,  2.11it/s] 79%|███████▉  | 2371/3000 [21:12<04:58,  2.11it/s] 79%|███████▉  | 2372/3000 [21:13<04:58,  2.10it/s] 79%|███████▉  | 2373/3000 [21:13<04:57,  2.11it/s] 79%|███████▉  | 2374/3000 [21:14<04:56,  2.11it/s] 79%|███████▉  | 2375/3000 [21:14<04:56,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:46:10,460 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:46:10,462 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:46:10,462 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:46:10,462 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 94.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.43it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:46:11 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 79%|███████▉  | 2375/3000 [21:16<04:56,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.8552302718162537, 'eval_accuracy': 0.84, 'eval_runtime': 1.5292, 'eval_samples_per_second': 65.396, 'eval_steps_per_second': 8.501, 'epoch': 95.0}
12/07/2022 13:46:11 - INFO - training.trainer_base - ***** Epoch 94: Best results *****
12/07/2022 13:46:11 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:46:11 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:46:11 - INFO - training.trainer_base - epoch = 94.0
                                                    79%|███████▉  | 2375/3000 [21:16<04:56,  2.11it/s] 79%|███████▉  | 2376/3000 [21:16<09:43,  1.07it/s] 79%|███████▉  | 2377/3000 [21:16<08:16,  1.25it/s] 79%|███████▉  | 2378/3000 [21:17<07:17,  1.42it/s] 79%|███████▉  | 2379/3000 [21:17<06:34,  1.57it/s] 79%|███████▉  | 2380/3000 [21:18<06:03,  1.71it/s] 79%|███████▉  | 2381/3000 [21:18<05:41,  1.81it/s] 79%|███████▉  | 2382/3000 [21:19<05:27,  1.89it/s] 79%|███████▉  | 2383/3000 [21:19<05:16,  1.95it/s] 79%|███████▉  | 2384/3000 [21:20<05:09,  1.99it/s] 80%|███████▉  | 2385/3000 [21:20<05:03,  2.03it/s] 80%|███████▉  | 2386/3000 [21:21<04:59,  2.05it/s] 80%|███████▉  | 2387/3000 [21:21<04:56,  2.07it/s] 80%|███████▉  | 2388/3000 [21:22<04:54,  2.08it/s] 80%|███████▉  | 2389/3000 [21:22<04:53,  2.08it/s] 80%|███████▉  | 2390/3000 [21:23<04:51,  2.10it/s] 80%|███████▉  | 2391/3000 [21:23<04:50,  2.10it/s] 80%|███████▉  | 2392/3000 [21:24<04:49,  2.10it/s] 80%|███████▉  | 2393/3000 [21:24<04:49,  2.09it/s] 80%|███████▉  | 2394/3000 [21:25<04:49,  2.09it/s] 80%|███████▉  | 2395/3000 [21:25<04:48,  2.10it/s] 80%|███████▉  | 2396/3000 [21:26<04:47,  2.10it/s] 80%|███████▉  | 2397/3000 [21:26<04:46,  2.11it/s] 80%|███████▉  | 2398/3000 [21:26<04:45,  2.11it/s] 80%|███████▉  | 2399/3000 [21:27<04:45,  2.10it/s] 80%|████████  | 2400/3000 [21:27<04:45,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:46:23,880 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:46:23,881 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:46:23,881 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:46:23,881 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 95.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.51it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.39it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.86it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:46:25 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 80%|████████  | 2400/3000 [21:29<04:45,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.8626183867454529, 'eval_accuracy': 0.84, 'eval_runtime': 1.5287, 'eval_samples_per_second': 65.416, 'eval_steps_per_second': 8.504, 'epoch': 96.0}
12/07/2022 13:46:25 - INFO - training.trainer_base - ***** Epoch 95: Best results *****
12/07/2022 13:46:25 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:46:25 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:46:25 - INFO - training.trainer_base - epoch = 95.0
                                                    80%|████████  | 2400/3000 [21:29<04:45,  2.10it/s] 80%|████████  | 2401/3000 [21:29<09:23,  1.06it/s] 80%|████████  | 2402/3000 [21:30<07:58,  1.25it/s] 80%|████████  | 2403/3000 [21:30<06:59,  1.42it/s] 80%|████████  | 2404/3000 [21:31<06:17,  1.58it/s] 80%|████████  | 2405/3000 [21:31<05:49,  1.70it/s] 80%|████████  | 2406/3000 [21:32<05:28,  1.81it/s] 80%|████████  | 2407/3000 [21:32<05:14,  1.89it/s] 80%|████████  | 2408/3000 [21:33<05:04,  1.95it/s] 80%|████████  | 2409/3000 [21:33<04:56,  1.99it/s] 80%|████████  | 2410/3000 [21:34<04:51,  2.03it/s] 80%|████████  | 2411/3000 [21:34<04:48,  2.04it/s] 80%|████████  | 2412/3000 [21:35<04:45,  2.06it/s] 80%|████████  | 2413/3000 [21:35<04:43,  2.07it/s] 80%|████████  | 2414/3000 [21:36<04:40,  2.09it/s] 80%|████████  | 2415/3000 [21:36<04:38,  2.10it/s] 81%|████████  | 2416/3000 [21:37<04:38,  2.10it/s] 81%|████████  | 2417/3000 [21:37<04:37,  2.10it/s] 81%|████████  | 2418/3000 [21:38<04:37,  2.10it/s] 81%|████████  | 2419/3000 [21:38<04:35,  2.11it/s] 81%|████████  | 2420/3000 [21:38<04:34,  2.11it/s] 81%|████████  | 2421/3000 [21:39<04:34,  2.11it/s] 81%|████████  | 2422/3000 [21:39<04:33,  2.11it/s] 81%|████████  | 2423/3000 [21:40<04:33,  2.11it/s] 81%|████████  | 2424/3000 [21:40<04:33,  2.10it/s] 81%|████████  | 2425/3000 [21:41<04:32,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:46:37,294 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:46:37,296 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:46:37,296 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:46:37,296 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 96.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.56it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.36it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.30it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.72it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.60it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.45it/s][A12/07/2022 13:46:38 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 81%|████████  | 2425/3000 [21:42<04:32,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.45it/s][A
                                               [A{'eval_loss': 0.8547823429107666, 'eval_accuracy': 0.84, 'eval_runtime': 1.5307, 'eval_samples_per_second': 65.33, 'eval_steps_per_second': 8.493, 'epoch': 97.0}
12/07/2022 13:46:38 - INFO - training.trainer_base - ***** Epoch 96: Best results *****
12/07/2022 13:46:38 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:46:38 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:46:38 - INFO - training.trainer_base - epoch = 96.0
                                                    81%|████████  | 2425/3000 [21:42<04:32,  2.11it/s] 81%|████████  | 2426/3000 [21:43<08:58,  1.07it/s] 81%|████████  | 2427/3000 [21:43<07:37,  1.25it/s] 81%|████████  | 2428/3000 [21:44<06:41,  1.42it/s] 81%|████████  | 2429/3000 [21:44<06:02,  1.57it/s] 81%|████████  | 2430/3000 [21:45<05:35,  1.70it/s] 81%|████████  | 2431/3000 [21:45<05:14,  1.81it/s] 81%|████████  | 2432/3000 [21:46<05:00,  1.89it/s] 81%|████████  | 2433/3000 [21:46<04:50,  1.95it/s] 81%|████████  | 2434/3000 [21:47<04:43,  1.99it/s] 81%|████████  | 2435/3000 [21:47<04:39,  2.02it/s] 81%|████████  | 2436/3000 [21:48<04:35,  2.05it/s] 81%|████████  | 2437/3000 [21:48<04:32,  2.07it/s] 81%|████████▏ | 2438/3000 [21:49<04:30,  2.08it/s] 81%|████████▏ | 2439/3000 [21:49<04:29,  2.08it/s] 81%|████████▏ | 2440/3000 [21:50<04:28,  2.09it/s] 81%|████████▏ | 2441/3000 [21:50<04:26,  2.10it/s] 81%|████████▏ | 2442/3000 [21:50<04:25,  2.10it/s] 81%|████████▏ | 2443/3000 [21:51<04:24,  2.10it/s] 81%|████████▏ | 2444/3000 [21:51<04:24,  2.10it/s] 82%|████████▏ | 2445/3000 [21:52<04:24,  2.10it/s] 82%|████████▏ | 2446/3000 [21:52<04:23,  2.11it/s] 82%|████████▏ | 2447/3000 [21:53<04:22,  2.11it/s] 82%|████████▏ | 2448/3000 [21:53<04:21,  2.11it/s] 82%|████████▏ | 2449/3000 [21:54<04:21,  2.11it/s] 82%|████████▏ | 2450/3000 [21:54<04:21,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:46:50,720 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:46:50,722 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:46:50,722 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:46:50,722 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 97.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.53it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.40it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.38it/s][A12/07/2022 13:46:52 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 82%|████████▏ | 2450/3000 [21:56<04:21,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.38it/s][A
                                               [A{'eval_loss': 0.8291898369789124, 'eval_accuracy': 0.83, 'eval_runtime': 1.5368, 'eval_samples_per_second': 65.071, 'eval_steps_per_second': 8.459, 'epoch': 98.0}
12/07/2022 13:46:52 - INFO - training.trainer_base - ***** Epoch 97: Best results *****
12/07/2022 13:46:52 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:46:52 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:46:52 - INFO - training.trainer_base - epoch = 97.0
                                                    82%|████████▏ | 2450/3000 [21:56<04:21,  2.10it/s] 82%|████████▏ | 2451/3000 [21:56<08:35,  1.07it/s] 82%|████████▏ | 2452/3000 [21:57<07:17,  1.25it/s] 82%|████████▏ | 2453/3000 [21:57<06:23,  1.42it/s] 82%|████████▏ | 2454/3000 [21:58<05:46,  1.58it/s] 82%|████████▏ | 2455/3000 [21:58<05:19,  1.70it/s] 82%|████████▏ | 2456/3000 [21:59<05:01,  1.81it/s] 82%|████████▏ | 2457/3000 [21:59<04:47,  1.89it/s] 82%|████████▏ | 2458/3000 [22:00<04:38,  1.95it/s] 82%|████████▏ | 2459/3000 [22:00<04:31,  1.99it/s] 82%|████████▏ | 2460/3000 [22:01<04:27,  2.02it/s] 82%|████████▏ | 2461/3000 [22:01<04:23,  2.05it/s] 82%|████████▏ | 2462/3000 [22:01<04:20,  2.07it/s] 82%|████████▏ | 2463/3000 [22:02<04:18,  2.08it/s] 82%|████████▏ | 2464/3000 [22:02<04:16,  2.09it/s] 82%|████████▏ | 2465/3000 [22:03<04:15,  2.10it/s] 82%|████████▏ | 2466/3000 [22:03<04:14,  2.10it/s] 82%|████████▏ | 2467/3000 [22:04<04:13,  2.10it/s] 82%|████████▏ | 2468/3000 [22:04<04:12,  2.10it/s] 82%|████████▏ | 2469/3000 [22:05<04:12,  2.10it/s] 82%|████████▏ | 2470/3000 [22:05<04:11,  2.11it/s] 82%|████████▏ | 2471/3000 [22:06<04:10,  2.11it/s] 82%|████████▏ | 2472/3000 [22:06<04:10,  2.11it/s] 82%|████████▏ | 2473/3000 [22:07<04:10,  2.10it/s] 82%|████████▏ | 2474/3000 [22:07<04:10,  2.10it/s] 82%|████████▎ | 2475/3000 [22:08<04:09,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:47:04,135 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:47:04,137 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:47:04,137 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:47:04,137 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 98.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.56it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:47:05 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 82%|████████▎ | 2475/3000 [22:09<04:09,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.8294476866722107, 'eval_accuracy': 0.83, 'eval_runtime': 1.5265, 'eval_samples_per_second': 65.508, 'eval_steps_per_second': 8.516, 'epoch': 99.0}
12/07/2022 13:47:05 - INFO - training.trainer_base - ***** Epoch 98: Best results *****
12/07/2022 13:47:05 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:47:05 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:47:05 - INFO - training.trainer_base - epoch = 98.0
                                                    82%|████████▎ | 2475/3000 [22:09<04:09,  2.10it/s] 83%|████████▎ | 2476/3000 [22:10<08:09,  1.07it/s] 83%|████████▎ | 2477/3000 [22:10<06:56,  1.25it/s] 83%|████████▎ | 2478/3000 [22:11<06:05,  1.43it/s] 83%|████████▎ | 2479/3000 [22:11<05:29,  1.58it/s] 83%|████████▎ | 2480/3000 [22:12<05:04,  1.71it/s] 83%|████████▎ | 2481/3000 [22:12<04:46,  1.81it/s] 83%|████████▎ | 2482/3000 [22:13<04:33,  1.89it/s] 83%|████████▎ | 2483/3000 [22:13<04:25,  1.95it/s] 83%|████████▎ | 2484/3000 [22:13<04:19,  1.99it/s] 83%|████████▎ | 2485/3000 [22:14<04:14,  2.02it/s] 83%|████████▎ | 2486/3000 [22:14<04:10,  2.05it/s] 83%|████████▎ | 2487/3000 [22:15<04:08,  2.07it/s] 83%|████████▎ | 2488/3000 [22:15<04:06,  2.08it/s] 83%|████████▎ | 2489/3000 [22:16<04:05,  2.08it/s] 83%|████████▎ | 2490/3000 [22:16<04:04,  2.09it/s] 83%|████████▎ | 2491/3000 [22:17<04:02,  2.10it/s] 83%|████████▎ | 2492/3000 [22:17<04:01,  2.10it/s] 83%|████████▎ | 2493/3000 [22:18<04:01,  2.10it/s] 83%|████████▎ | 2494/3000 [22:18<04:00,  2.10it/s] 83%|████████▎ | 2495/3000 [22:19<04:00,  2.10it/s] 83%|████████▎ | 2496/3000 [22:19<03:59,  2.10it/s] 83%|████████▎ | 2497/3000 [22:20<03:58,  2.11it/s] 83%|████████▎ | 2498/3000 [22:20<03:58,  2.10it/s] 83%|████████▎ | 2499/3000 [22:21<03:58,  2.10it/s] 83%|████████▎ | 2500/3000 [22:21<03:58,  2.10it/s]                                                    83%|████████▎ | 2500/3000 [22:21<03:58,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:47:17,551 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:47:17,553 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:47:17,553 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:47:17,553 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 99.0)])
{'loss': 0.019, 'learning_rate': 0.0014999999999999998, 'epoch': 100.0}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.46it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.60it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:47:19 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 83%|████████▎ | 2500/3000 [22:23<03:58,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.839273989200592, 'eval_accuracy': 0.84, 'eval_runtime': 1.5256, 'eval_samples_per_second': 65.548, 'eval_steps_per_second': 8.521, 'epoch': 100.0}
12/07/2022 13:47:19 - INFO - training.trainer_base - ***** Epoch 99: Best results *****
12/07/2022 13:47:19 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:47:19 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:47:19 - INFO - training.trainer_base - epoch = 99.0
                                                    83%|████████▎ | 2500/3000 [22:23<03:58,  2.10it/s] 83%|████████▎ | 2501/3000 [22:23<07:47,  1.07it/s] 83%|████████▎ | 2502/3000 [22:24<06:37,  1.25it/s] 83%|████████▎ | 2503/3000 [22:24<05:48,  1.43it/s] 83%|████████▎ | 2504/3000 [22:25<05:14,  1.58it/s] 84%|████████▎ | 2505/3000 [22:25<04:49,  1.71it/s] 84%|████████▎ | 2506/3000 [22:25<04:32,  1.81it/s] 84%|████████▎ | 2507/3000 [22:26<04:20,  1.89it/s] 84%|████████▎ | 2508/3000 [22:26<04:11,  1.96it/s] 84%|████████▎ | 2509/3000 [22:27<04:05,  2.00it/s] 84%|████████▎ | 2510/3000 [22:27<04:01,  2.03it/s] 84%|████████▎ | 2511/3000 [22:28<03:58,  2.05it/s] 84%|████████▎ | 2512/3000 [22:28<03:56,  2.06it/s] 84%|████████▍ | 2513/3000 [22:29<03:54,  2.08it/s] 84%|████████▍ | 2514/3000 [22:29<03:52,  2.09it/s] 84%|████████▍ | 2515/3000 [22:30<03:51,  2.09it/s] 84%|████████▍ | 2516/3000 [22:30<03:50,  2.10it/s] 84%|████████▍ | 2517/3000 [22:31<03:50,  2.09it/s] 84%|████████▍ | 2518/3000 [22:31<03:50,  2.09it/s] 84%|████████▍ | 2519/3000 [22:32<03:48,  2.10it/s] 84%|████████▍ | 2520/3000 [22:32<03:47,  2.11it/s] 84%|████████▍ | 2521/3000 [22:33<03:47,  2.10it/s] 84%|████████▍ | 2522/3000 [22:33<03:47,  2.10it/s] 84%|████████▍ | 2523/3000 [22:34<03:47,  2.09it/s] 84%|████████▍ | 2524/3000 [22:34<03:46,  2.10it/s] 84%|████████▍ | 2525/3000 [22:34<03:45,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:47:30,960 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:47:30,961 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:47:30,961 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:47:30,961 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 100.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.44it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.35it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.60it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.45it/s][A12/07/2022 13:47:32 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 84%|████████▍ | 2525/3000 [22:36<03:45,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.45it/s][A
                                               [A{'eval_loss': 0.8424355983734131, 'eval_accuracy': 0.83, 'eval_runtime': 1.5268, 'eval_samples_per_second': 65.497, 'eval_steps_per_second': 8.515, 'epoch': 101.0}
12/07/2022 13:47:32 - INFO - training.trainer_base - ***** Epoch 100: Best results *****
12/07/2022 13:47:32 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:47:32 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:47:32 - INFO - training.trainer_base - epoch = 100.0
                                                    84%|████████▍ | 2525/3000 [22:36<03:45,  2.10it/s] 84%|████████▍ | 2526/3000 [22:36<07:22,  1.07it/s] 84%|████████▍ | 2527/3000 [22:37<06:16,  1.26it/s] 84%|████████▍ | 2528/3000 [22:37<05:30,  1.43it/s] 84%|████████▍ | 2529/3000 [22:38<04:58,  1.58it/s] 84%|████████▍ | 2530/3000 [22:38<04:34,  1.71it/s] 84%|████████▍ | 2531/3000 [22:39<04:18,  1.82it/s] 84%|████████▍ | 2532/3000 [22:39<04:07,  1.89it/s] 84%|████████▍ | 2533/3000 [22:40<03:59,  1.95it/s] 84%|████████▍ | 2534/3000 [22:40<03:54,  1.99it/s] 84%|████████▍ | 2535/3000 [22:41<03:50,  2.02it/s] 85%|████████▍ | 2536/3000 [22:41<03:46,  2.05it/s] 85%|████████▍ | 2537/3000 [22:42<03:43,  2.07it/s] 85%|████████▍ | 2538/3000 [22:42<03:42,  2.08it/s] 85%|████████▍ | 2539/3000 [22:43<03:41,  2.08it/s] 85%|████████▍ | 2540/3000 [22:43<03:40,  2.09it/s] 85%|████████▍ | 2541/3000 [22:44<03:39,  2.09it/s] 85%|████████▍ | 2542/3000 [22:44<03:38,  2.10it/s] 85%|████████▍ | 2543/3000 [22:45<03:37,  2.10it/s] 85%|████████▍ | 2544/3000 [22:45<03:37,  2.10it/s] 85%|████████▍ | 2545/3000 [22:46<03:37,  2.09it/s] 85%|████████▍ | 2546/3000 [22:46<03:35,  2.10it/s] 85%|████████▍ | 2547/3000 [22:46<03:35,  2.11it/s] 85%|████████▍ | 2548/3000 [22:47<03:34,  2.11it/s] 85%|████████▍ | 2549/3000 [22:47<03:33,  2.11it/s] 85%|████████▌ | 2550/3000 [22:48<03:33,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:47:44,370 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:47:44,372 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:47:44,372 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:47:44,372 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 101.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:47:45 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 85%|████████▌ | 2550/3000 [22:49<03:33,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.8631656169891357, 'eval_accuracy': 0.83, 'eval_runtime': 1.5287, 'eval_samples_per_second': 65.417, 'eval_steps_per_second': 8.504, 'epoch': 102.0}
12/07/2022 13:47:45 - INFO - training.trainer_base - ***** Epoch 101: Best results *****
12/07/2022 13:47:45 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:47:45 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:47:45 - INFO - training.trainer_base - epoch = 101.0
                                                    85%|████████▌ | 2550/3000 [22:49<03:33,  2.10it/s] 85%|████████▌ | 2551/3000 [22:50<07:00,  1.07it/s] 85%|████████▌ | 2552/3000 [22:50<05:57,  1.25it/s] 85%|████████▌ | 2553/3000 [22:51<05:12,  1.43it/s] 85%|████████▌ | 2554/3000 [22:51<04:42,  1.58it/s] 85%|████████▌ | 2555/3000 [22:52<04:20,  1.71it/s] 85%|████████▌ | 2556/3000 [22:52<04:05,  1.81it/s] 85%|████████▌ | 2557/3000 [22:53<03:54,  1.89it/s] 85%|████████▌ | 2558/3000 [22:53<03:46,  1.95it/s] 85%|████████▌ | 2559/3000 [22:54<03:40,  2.00it/s] 85%|████████▌ | 2560/3000 [22:54<03:37,  2.03it/s] 85%|████████▌ | 2561/3000 [22:55<03:34,  2.05it/s] 85%|████████▌ | 2562/3000 [22:55<03:32,  2.06it/s] 85%|████████▌ | 2563/3000 [22:56<03:29,  2.08it/s] 85%|████████▌ | 2564/3000 [22:56<03:28,  2.09it/s] 86%|████████▌ | 2565/3000 [22:57<03:27,  2.10it/s] 86%|████████▌ | 2566/3000 [22:57<03:26,  2.10it/s] 86%|████████▌ | 2567/3000 [22:57<03:25,  2.10it/s] 86%|████████▌ | 2568/3000 [22:58<03:25,  2.10it/s] 86%|████████▌ | 2569/3000 [22:58<03:24,  2.11it/s] 86%|████████▌ | 2570/3000 [22:59<03:24,  2.11it/s] 86%|████████▌ | 2571/3000 [22:59<03:23,  2.10it/s] 86%|████████▌ | 2572/3000 [23:00<03:23,  2.11it/s] 86%|████████▌ | 2573/3000 [23:00<03:22,  2.11it/s] 86%|████████▌ | 2574/3000 [23:01<03:22,  2.10it/s] 86%|████████▌ | 2575/3000 [23:01<03:22,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:47:57,770 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:47:57,772 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:47:57,772 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:47:57,772 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 102.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.47it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.81it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:47:59 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 86%|████████▌ | 2575/3000 [23:03<03:22,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.863024115562439, 'eval_accuracy': 0.83, 'eval_runtime': 1.5283, 'eval_samples_per_second': 65.432, 'eval_steps_per_second': 8.506, 'epoch': 103.0}
12/07/2022 13:47:59 - INFO - training.trainer_base - ***** Epoch 102: Best results *****
12/07/2022 13:47:59 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:47:59 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:47:59 - INFO - training.trainer_base - epoch = 102.0
                                                    86%|████████▌ | 2575/3000 [23:03<03:22,  2.10it/s] 86%|████████▌ | 2576/3000 [23:03<06:36,  1.07it/s] 86%|████████▌ | 2577/3000 [23:04<05:37,  1.25it/s] 86%|████████▌ | 2578/3000 [23:04<04:55,  1.43it/s] 86%|████████▌ | 2579/3000 [23:05<04:26,  1.58it/s] 86%|████████▌ | 2580/3000 [23:05<04:05,  1.71it/s] 86%|████████▌ | 2581/3000 [23:06<03:51,  1.81it/s] 86%|████████▌ | 2582/3000 [23:06<03:41,  1.88it/s] 86%|████████▌ | 2583/3000 [23:07<03:34,  1.95it/s] 86%|████████▌ | 2584/3000 [23:07<03:28,  1.99it/s] 86%|████████▌ | 2585/3000 [23:08<03:25,  2.02it/s] 86%|████████▌ | 2586/3000 [23:08<03:22,  2.04it/s] 86%|████████▌ | 2587/3000 [23:09<03:20,  2.06it/s] 86%|████████▋ | 2588/3000 [23:09<03:18,  2.07it/s] 86%|████████▋ | 2589/3000 [23:09<03:16,  2.09it/s] 86%|████████▋ | 2590/3000 [23:10<03:15,  2.09it/s] 86%|████████▋ | 2591/3000 [23:10<03:15,  2.09it/s] 86%|████████▋ | 2592/3000 [23:11<03:14,  2.09it/s] 86%|████████▋ | 2593/3000 [23:11<03:13,  2.10it/s] 86%|████████▋ | 2594/3000 [23:12<03:12,  2.11it/s] 86%|████████▋ | 2595/3000 [23:12<03:12,  2.10it/s] 87%|████████▋ | 2596/3000 [23:13<03:12,  2.10it/s] 87%|████████▋ | 2597/3000 [23:13<03:11,  2.10it/s] 87%|████████▋ | 2598/3000 [23:14<03:10,  2.11it/s] 87%|████████▋ | 2599/3000 [23:14<03:10,  2.11it/s] 87%|████████▋ | 2600/3000 [23:15<03:09,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:48:11,182 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:48:11,184 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:48:11,184 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:48:11,184 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 103.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.48it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.41it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:48:12 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 87%|████████▋ | 2600/3000 [23:16<03:09,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.8495875000953674, 'eval_accuracy': 0.83, 'eval_runtime': 1.5285, 'eval_samples_per_second': 65.425, 'eval_steps_per_second': 8.505, 'epoch': 104.0}
12/07/2022 13:48:12 - INFO - training.trainer_base - ***** Epoch 103: Best results *****
12/07/2022 13:48:12 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:48:12 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:48:12 - INFO - training.trainer_base - epoch = 103.0
                                                    87%|████████▋ | 2600/3000 [23:16<03:09,  2.11it/s] 87%|████████▋ | 2601/3000 [23:17<06:12,  1.07it/s] 87%|████████▋ | 2602/3000 [23:17<05:16,  1.26it/s] 87%|████████▋ | 2603/3000 [23:18<04:37,  1.43it/s] 87%|████████▋ | 2604/3000 [23:18<04:09,  1.58it/s] 87%|████████▋ | 2605/3000 [23:19<03:50,  1.71it/s] 87%|████████▋ | 2606/3000 [23:19<03:37,  1.81it/s] 87%|████████▋ | 2607/3000 [23:20<03:28,  1.89it/s] 87%|████████▋ | 2608/3000 [23:20<03:21,  1.95it/s] 87%|████████▋ | 2609/3000 [23:21<03:15,  2.00it/s] 87%|████████▋ | 2610/3000 [23:21<03:12,  2.03it/s] 87%|████████▋ | 2611/3000 [23:21<03:09,  2.05it/s] 87%|████████▋ | 2612/3000 [23:22<03:07,  2.07it/s] 87%|████████▋ | 2613/3000 [23:22<03:06,  2.08it/s] 87%|████████▋ | 2614/3000 [23:23<03:04,  2.09it/s] 87%|████████▋ | 2615/3000 [23:23<03:03,  2.09it/s] 87%|████████▋ | 2616/3000 [23:24<03:03,  2.10it/s] 87%|████████▋ | 2617/3000 [23:24<03:02,  2.10it/s] 87%|████████▋ | 2618/3000 [23:25<03:02,  2.10it/s] 87%|████████▋ | 2619/3000 [23:25<03:01,  2.10it/s] 87%|████████▋ | 2620/3000 [23:26<03:00,  2.11it/s] 87%|████████▋ | 2621/3000 [23:26<03:00,  2.10it/s] 87%|████████▋ | 2622/3000 [23:27<02:59,  2.10it/s] 87%|████████▋ | 2623/3000 [23:27<02:59,  2.10it/s] 87%|████████▋ | 2624/3000 [23:28<02:58,  2.11it/s] 88%|████████▊ | 2625/3000 [23:28<02:57,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:48:24,579 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:48:24,581 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:48:24,581 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:48:24,581 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 104.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.34it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.45it/s][A12/07/2022 13:48:26 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 88%|████████▊ | 2625/3000 [23:30<02:57,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.45it/s][A
                                               [A{'eval_loss': 0.82353675365448, 'eval_accuracy': 0.84, 'eval_runtime': 1.5281, 'eval_samples_per_second': 65.44, 'eval_steps_per_second': 8.507, 'epoch': 105.0}
12/07/2022 13:48:26 - INFO - training.trainer_base - ***** Epoch 104: Best results *****
12/07/2022 13:48:26 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:48:26 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:48:26 - INFO - training.trainer_base - epoch = 104.0
                                                    88%|████████▊ | 2625/3000 [23:30<02:57,  2.11it/s] 88%|████████▊ | 2626/3000 [23:30<05:49,  1.07it/s] 88%|████████▊ | 2627/3000 [23:31<04:57,  1.26it/s] 88%|████████▊ | 2628/3000 [23:31<04:20,  1.43it/s] 88%|████████▊ | 2629/3000 [23:32<03:55,  1.58it/s] 88%|████████▊ | 2630/3000 [23:32<03:36,  1.71it/s] 88%|████████▊ | 2631/3000 [23:32<03:23,  1.81it/s] 88%|████████▊ | 2632/3000 [23:33<03:14,  1.89it/s] 88%|████████▊ | 2633/3000 [23:33<03:08,  1.95it/s] 88%|████████▊ | 2634/3000 [23:34<03:03,  1.99it/s] 88%|████████▊ | 2635/3000 [23:34<03:00,  2.02it/s] 88%|████████▊ | 2636/3000 [23:35<02:57,  2.05it/s] 88%|████████▊ | 2637/3000 [23:35<02:55,  2.07it/s] 88%|████████▊ | 2638/3000 [23:36<02:54,  2.08it/s] 88%|████████▊ | 2639/3000 [23:36<02:53,  2.08it/s] 88%|████████▊ | 2640/3000 [23:37<02:52,  2.09it/s] 88%|████████▊ | 2641/3000 [23:37<02:51,  2.09it/s] 88%|████████▊ | 2642/3000 [23:38<02:50,  2.10it/s] 88%|████████▊ | 2643/3000 [23:38<02:50,  2.10it/s] 88%|████████▊ | 2644/3000 [23:39<02:49,  2.10it/s] 88%|████████▊ | 2645/3000 [23:39<02:49,  2.10it/s] 88%|████████▊ | 2646/3000 [23:40<02:48,  2.11it/s] 88%|████████▊ | 2647/3000 [23:40<02:47,  2.11it/s] 88%|████████▊ | 2648/3000 [23:41<02:47,  2.11it/s] 88%|████████▊ | 2649/3000 [23:41<02:46,  2.10it/s] 88%|████████▊ | 2650/3000 [23:42<02:46,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:48:37,994 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:48:37,995 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:48:37,995 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:48:37,995 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 105.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.37it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.35it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.81it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:48:39 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 88%|████████▊ | 2650/3000 [23:43<02:46,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.8248945474624634, 'eval_accuracy': 0.84, 'eval_runtime': 1.5315, 'eval_samples_per_second': 65.293, 'eval_steps_per_second': 8.488, 'epoch': 106.0}
12/07/2022 13:48:39 - INFO - training.trainer_base - ***** Epoch 105: Best results *****
12/07/2022 13:48:39 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:48:39 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:48:39 - INFO - training.trainer_base - epoch = 105.0
                                                    88%|████████▊ | 2650/3000 [23:43<02:46,  2.10it/s] 88%|████████▊ | 2651/3000 [23:44<05:26,  1.07it/s] 88%|████████▊ | 2652/3000 [23:44<04:37,  1.26it/s] 88%|████████▊ | 2653/3000 [23:44<04:02,  1.43it/s] 88%|████████▊ | 2654/3000 [23:45<03:38,  1.58it/s] 88%|████████▊ | 2655/3000 [23:45<03:21,  1.71it/s] 89%|████████▊ | 2656/3000 [23:46<03:09,  1.81it/s] 89%|████████▊ | 2657/3000 [23:46<03:01,  1.89it/s] 89%|████████▊ | 2658/3000 [23:47<02:55,  1.95it/s] 89%|████████▊ | 2659/3000 [23:47<02:50,  2.00it/s] 89%|████████▊ | 2660/3000 [23:48<02:47,  2.03it/s] 89%|████████▊ | 2661/3000 [23:48<02:45,  2.05it/s] 89%|████████▊ | 2662/3000 [23:49<02:43,  2.06it/s] 89%|████████▉ | 2663/3000 [23:49<02:42,  2.08it/s] 89%|████████▉ | 2664/3000 [23:50<02:40,  2.09it/s] 89%|████████▉ | 2665/3000 [23:50<02:39,  2.09it/s] 89%|████████▉ | 2666/3000 [23:51<02:39,  2.10it/s] 89%|████████▉ | 2667/3000 [23:51<02:38,  2.10it/s] 89%|████████▉ | 2668/3000 [23:52<02:38,  2.10it/s] 89%|████████▉ | 2669/3000 [23:52<02:37,  2.10it/s] 89%|████████▉ | 2670/3000 [23:53<02:36,  2.11it/s] 89%|████████▉ | 2671/3000 [23:53<02:36,  2.11it/s] 89%|████████▉ | 2672/3000 [23:53<02:35,  2.10it/s] 89%|████████▉ | 2673/3000 [23:54<02:35,  2.10it/s] 89%|████████▉ | 2674/3000 [23:54<02:34,  2.10it/s] 89%|████████▉ | 2675/3000 [23:55<02:34,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:48:51,396 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:48:51,397 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:48:51,397 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:48:51,397 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 106.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.36it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.32it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.68it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.55it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:48:52 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 89%|████████▉ | 2675/3000 [23:56<02:34,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.8353897929191589, 'eval_accuracy': 0.84, 'eval_runtime': 1.5308, 'eval_samples_per_second': 65.325, 'eval_steps_per_second': 8.492, 'epoch': 107.0}
12/07/2022 13:48:52 - INFO - training.trainer_base - ***** Epoch 106: Best results *****
12/07/2022 13:48:52 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:48:52 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:48:52 - INFO - training.trainer_base - epoch = 106.0
                                                    89%|████████▉ | 2675/3000 [23:56<02:34,  2.11it/s] 89%|████████▉ | 2676/3000 [23:57<05:02,  1.07it/s] 89%|████████▉ | 2677/3000 [23:57<04:17,  1.26it/s] 89%|████████▉ | 2678/3000 [23:58<03:45,  1.43it/s] 89%|████████▉ | 2679/3000 [23:58<03:23,  1.58it/s] 89%|████████▉ | 2680/3000 [23:59<03:07,  1.71it/s] 89%|████████▉ | 2681/3000 [23:59<02:56,  1.81it/s] 89%|████████▉ | 2682/3000 [24:00<02:48,  1.89it/s] 89%|████████▉ | 2683/3000 [24:00<02:42,  1.95it/s] 89%|████████▉ | 2684/3000 [24:01<02:39,  1.98it/s] 90%|████████▉ | 2685/3000 [24:01<02:35,  2.02it/s] 90%|████████▉ | 2686/3000 [24:02<02:33,  2.05it/s] 90%|████████▉ | 2687/3000 [24:02<02:31,  2.06it/s] 90%|████████▉ | 2688/3000 [24:03<02:30,  2.07it/s] 90%|████████▉ | 2689/3000 [24:03<02:29,  2.08it/s] 90%|████████▉ | 2690/3000 [24:04<02:28,  2.08it/s] 90%|████████▉ | 2691/3000 [24:04<02:27,  2.09it/s] 90%|████████▉ | 2692/3000 [24:05<02:26,  2.10it/s] 90%|████████▉ | 2693/3000 [24:05<02:26,  2.10it/s] 90%|████████▉ | 2694/3000 [24:05<02:25,  2.10it/s] 90%|████████▉ | 2695/3000 [24:06<02:25,  2.10it/s] 90%|████████▉ | 2696/3000 [24:06<02:24,  2.11it/s] 90%|████████▉ | 2697/3000 [24:07<02:23,  2.11it/s] 90%|████████▉ | 2698/3000 [24:07<02:23,  2.11it/s] 90%|████████▉ | 2699/3000 [24:08<02:22,  2.11it/s] 90%|█████████ | 2700/3000 [24:08<02:22,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:49:04,815 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:49:04,817 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:49:04,817 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:49:04,817 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 107.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.48it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:49:06 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 90%|█████████ | 2700/3000 [24:10<02:22,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.859844446182251, 'eval_accuracy': 0.84, 'eval_runtime': 1.5275, 'eval_samples_per_second': 65.466, 'eval_steps_per_second': 8.511, 'epoch': 108.0}
12/07/2022 13:49:06 - INFO - training.trainer_base - ***** Epoch 107: Best results *****
12/07/2022 13:49:06 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:49:06 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:49:06 - INFO - training.trainer_base - epoch = 107.0
                                                    90%|█████████ | 2700/3000 [24:10<02:22,  2.11it/s] 90%|█████████ | 2701/3000 [24:10<04:39,  1.07it/s] 90%|█████████ | 2702/3000 [24:11<03:56,  1.26it/s] 90%|█████████ | 2703/3000 [24:11<03:27,  1.43it/s] 90%|█████████ | 2704/3000 [24:12<03:06,  1.58it/s] 90%|█████████ | 2705/3000 [24:12<02:52,  1.71it/s] 90%|█████████ | 2706/3000 [24:13<02:42,  1.81it/s] 90%|█████████ | 2707/3000 [24:13<02:34,  1.90it/s] 90%|█████████ | 2708/3000 [24:14<02:29,  1.96it/s] 90%|█████████ | 2709/3000 [24:14<02:25,  2.00it/s] 90%|█████████ | 2710/3000 [24:15<02:23,  2.03it/s] 90%|█████████ | 2711/3000 [24:15<02:21,  2.05it/s] 90%|█████████ | 2712/3000 [24:16<02:19,  2.07it/s] 90%|█████████ | 2713/3000 [24:16<02:17,  2.08it/s] 90%|█████████ | 2714/3000 [24:17<02:16,  2.09it/s] 90%|█████████ | 2715/3000 [24:17<02:16,  2.09it/s] 91%|█████████ | 2716/3000 [24:17<02:15,  2.10it/s] 91%|█████████ | 2717/3000 [24:18<02:14,  2.10it/s] 91%|█████████ | 2718/3000 [24:18<02:14,  2.10it/s] 91%|█████████ | 2719/3000 [24:19<02:13,  2.10it/s] 91%|█████████ | 2720/3000 [24:19<02:12,  2.11it/s] 91%|█████████ | 2721/3000 [24:20<02:12,  2.11it/s] 91%|█████████ | 2722/3000 [24:20<02:11,  2.11it/s] 91%|█████████ | 2723/3000 [24:21<02:11,  2.11it/s] 91%|█████████ | 2724/3000 [24:21<02:11,  2.10it/s] 91%|█████████ | 2725/3000 [24:22<02:10,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:49:18,202 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:49:18,203 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:49:18,203 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:49:18,203 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 108.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.47it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.36it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.47it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:49:19 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 91%|█████████ | 2725/3000 [24:23<02:10,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.869375467300415, 'eval_accuracy': 0.83, 'eval_runtime': 1.5303, 'eval_samples_per_second': 65.347, 'eval_steps_per_second': 8.495, 'epoch': 109.0}
12/07/2022 13:49:19 - INFO - training.trainer_base - ***** Epoch 108: Best results *****
12/07/2022 13:49:19 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:49:19 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:49:19 - INFO - training.trainer_base - epoch = 108.0
                                                    91%|█████████ | 2725/3000 [24:23<02:10,  2.11it/s] 91%|█████████ | 2726/3000 [24:24<04:15,  1.07it/s] 91%|█████████ | 2727/3000 [24:24<03:37,  1.26it/s] 91%|█████████ | 2728/3000 [24:25<03:10,  1.43it/s] 91%|█████████ | 2729/3000 [24:25<02:51,  1.58it/s] 91%|█████████ | 2730/3000 [24:26<02:38,  1.71it/s] 91%|█████████ | 2731/3000 [24:26<02:28,  1.81it/s] 91%|█████████ | 2732/3000 [24:27<02:21,  1.89it/s] 91%|█████████ | 2733/3000 [24:27<02:16,  1.95it/s] 91%|█████████ | 2734/3000 [24:28<02:13,  1.99it/s] 91%|█████████ | 2735/3000 [24:28<02:10,  2.02it/s] 91%|█████████ | 2736/3000 [24:28<02:08,  2.05it/s] 91%|█████████ | 2737/3000 [24:29<02:07,  2.07it/s] 91%|█████████▏| 2738/3000 [24:29<02:05,  2.08it/s] 91%|█████████▏| 2739/3000 [24:30<02:04,  2.09it/s] 91%|█████████▏| 2740/3000 [24:30<02:04,  2.09it/s] 91%|█████████▏| 2741/3000 [24:31<02:03,  2.10it/s] 91%|█████████▏| 2742/3000 [24:31<02:02,  2.10it/s] 91%|█████████▏| 2743/3000 [24:32<02:01,  2.11it/s] 91%|█████████▏| 2744/3000 [24:32<02:01,  2.11it/s] 92%|█████████▏| 2745/3000 [24:33<02:01,  2.10it/s] 92%|█████████▏| 2746/3000 [24:33<02:00,  2.10it/s] 92%|█████████▏| 2747/3000 [24:34<02:00,  2.10it/s] 92%|█████████▏| 2748/3000 [24:34<01:59,  2.11it/s] 92%|█████████▏| 2749/3000 [24:35<01:59,  2.11it/s] 92%|█████████▏| 2750/3000 [24:35<01:58,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:49:31,608 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:49:31,609 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:49:31,609 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:49:31,609 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 109.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.41it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:49:33 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 92%|█████████▏| 2750/3000 [24:37<01:58,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.8692001104354858, 'eval_accuracy': 0.84, 'eval_runtime': 1.5309, 'eval_samples_per_second': 65.32, 'eval_steps_per_second': 8.492, 'epoch': 110.0}
12/07/2022 13:49:33 - INFO - training.trainer_base - ***** Epoch 109: Best results *****
12/07/2022 13:49:33 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:49:33 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:49:33 - INFO - training.trainer_base - epoch = 109.0
                                                    92%|█████████▏| 2750/3000 [24:37<01:58,  2.10it/s] 92%|█████████▏| 2751/3000 [24:37<03:53,  1.07it/s] 92%|█████████▏| 2752/3000 [24:38<03:18,  1.25it/s] 92%|█████████▏| 2753/3000 [24:38<02:53,  1.42it/s] 92%|█████████▏| 2754/3000 [24:39<02:35,  1.58it/s] 92%|█████████▏| 2755/3000 [24:39<02:23,  1.71it/s] 92%|█████████▏| 2756/3000 [24:40<02:14,  1.81it/s] 92%|█████████▏| 2757/3000 [24:40<02:08,  1.89it/s] 92%|█████████▏| 2758/3000 [24:40<02:04,  1.95it/s] 92%|█████████▏| 2759/3000 [24:41<02:00,  1.99it/s] 92%|█████████▏| 2760/3000 [24:41<01:58,  2.03it/s] 92%|█████████▏| 2761/3000 [24:42<01:56,  2.05it/s] 92%|█████████▏| 2762/3000 [24:42<01:55,  2.07it/s] 92%|█████████▏| 2763/3000 [24:43<01:54,  2.07it/s] 92%|█████████▏| 2764/3000 [24:43<01:53,  2.08it/s] 92%|█████████▏| 2765/3000 [24:44<01:52,  2.09it/s] 92%|█████████▏| 2766/3000 [24:44<01:51,  2.09it/s] 92%|█████████▏| 2767/3000 [24:45<01:51,  2.09it/s] 92%|█████████▏| 2768/3000 [24:45<01:50,  2.09it/s] 92%|█████████▏| 2769/3000 [24:46<01:50,  2.09it/s] 92%|█████████▏| 2770/3000 [24:46<01:49,  2.10it/s] 92%|█████████▏| 2771/3000 [24:47<01:48,  2.10it/s] 92%|█████████▏| 2772/3000 [24:47<01:48,  2.10it/s] 92%|█████████▏| 2773/3000 [24:48<01:48,  2.10it/s] 92%|█████████▏| 2774/3000 [24:48<01:47,  2.10it/s] 92%|█████████▎| 2775/3000 [24:49<01:47,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:49:45,040 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:49:45,042 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:49:45,042 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:49:45,042 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 110.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.45it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.34it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:49:46 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 92%|█████████▎| 2775/3000 [24:50<01:47,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.8714244961738586, 'eval_accuracy': 0.83, 'eval_runtime': 1.5273, 'eval_samples_per_second': 65.475, 'eval_steps_per_second': 8.512, 'epoch': 111.0}
12/07/2022 13:49:46 - INFO - training.trainer_base - ***** Epoch 110: Best results *****
12/07/2022 13:49:46 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:49:46 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:49:46 - INFO - training.trainer_base - epoch = 110.0
                                                    92%|█████████▎| 2775/3000 [24:50<01:47,  2.10it/s] 93%|█████████▎| 2776/3000 [24:51<03:29,  1.07it/s] 93%|█████████▎| 2777/3000 [24:51<02:57,  1.26it/s] 93%|█████████▎| 2778/3000 [24:52<02:35,  1.43it/s] 93%|█████████▎| 2779/3000 [24:52<02:19,  1.58it/s] 93%|█████████▎| 2780/3000 [24:52<02:09,  1.70it/s] 93%|█████████▎| 2781/3000 [24:53<02:01,  1.81it/s] 93%|█████████▎| 2782/3000 [24:53<01:55,  1.89it/s] 93%|█████████▎| 2783/3000 [24:54<01:50,  1.96it/s] 93%|█████████▎| 2784/3000 [24:54<01:48,  2.00it/s] 93%|█████████▎| 2785/3000 [24:55<01:46,  2.03it/s] 93%|█████████▎| 2786/3000 [24:55<01:44,  2.05it/s] 93%|█████████▎| 2787/3000 [24:56<01:43,  2.07it/s] 93%|█████████▎| 2788/3000 [24:56<01:41,  2.08it/s] 93%|█████████▎| 2789/3000 [24:57<01:41,  2.09it/s] 93%|█████████▎| 2790/3000 [24:57<01:40,  2.09it/s] 93%|█████████▎| 2791/3000 [24:58<01:39,  2.09it/s] 93%|█████████▎| 2792/3000 [24:58<01:39,  2.10it/s] 93%|█████████▎| 2793/3000 [24:59<01:38,  2.10it/s] 93%|█████████▎| 2794/3000 [24:59<01:37,  2.11it/s] 93%|█████████▎| 2795/3000 [25:00<01:37,  2.11it/s] 93%|█████████▎| 2796/3000 [25:00<01:36,  2.11it/s] 93%|█████████▎| 2797/3000 [25:01<01:36,  2.11it/s] 93%|█████████▎| 2798/3000 [25:01<01:35,  2.11it/s] 93%|█████████▎| 2799/3000 [25:01<01:35,  2.11it/s] 93%|█████████▎| 2800/3000 [25:02<01:34,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:49:58,433 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:49:58,435 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:49:58,435 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:49:58,435 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 111.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.56it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.50it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:49:59 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 93%|█████████▎| 2800/3000 [25:03<01:34,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.8665196895599365, 'eval_accuracy': 0.83, 'eval_runtime': 1.5273, 'eval_samples_per_second': 65.475, 'eval_steps_per_second': 8.512, 'epoch': 112.0}
12/07/2022 13:49:59 - INFO - training.trainer_base - ***** Epoch 111: Best results *****
12/07/2022 13:49:59 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:49:59 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:49:59 - INFO - training.trainer_base - epoch = 111.0
                                                    93%|█████████▎| 2800/3000 [25:03<01:34,  2.11it/s] 93%|█████████▎| 2801/3000 [25:04<03:05,  1.07it/s] 93%|█████████▎| 2802/3000 [25:04<02:37,  1.25it/s] 93%|█████████▎| 2803/3000 [25:05<02:17,  1.43it/s] 93%|█████████▎| 2804/3000 [25:05<02:03,  1.58it/s] 94%|█████████▎| 2805/3000 [25:06<01:53,  1.71it/s] 94%|█████████▎| 2806/3000 [25:06<01:46,  1.81it/s] 94%|█████████▎| 2807/3000 [25:07<01:42,  1.89it/s] 94%|█████████▎| 2808/3000 [25:07<01:38,  1.94it/s] 94%|█████████▎| 2809/3000 [25:08<01:35,  1.99it/s] 94%|█████████▎| 2810/3000 [25:08<01:33,  2.03it/s] 94%|█████████▎| 2811/3000 [25:09<01:32,  2.05it/s] 94%|█████████▎| 2812/3000 [25:09<01:31,  2.06it/s] 94%|█████████▍| 2813/3000 [25:10<01:30,  2.07it/s] 94%|█████████▍| 2814/3000 [25:10<01:29,  2.08it/s] 94%|█████████▍| 2815/3000 [25:11<01:28,  2.09it/s] 94%|█████████▍| 2816/3000 [25:11<01:27,  2.09it/s] 94%|█████████▍| 2817/3000 [25:12<01:27,  2.09it/s] 94%|█████████▍| 2818/3000 [25:12<01:27,  2.09it/s] 94%|█████████▍| 2819/3000 [25:13<01:26,  2.09it/s] 94%|█████████▍| 2820/3000 [25:13<01:25,  2.10it/s] 94%|█████████▍| 2821/3000 [25:13<01:25,  2.10it/s] 94%|█████████▍| 2822/3000 [25:14<01:24,  2.10it/s] 94%|█████████▍| 2823/3000 [25:14<01:24,  2.10it/s] 94%|█████████▍| 2824/3000 [25:15<01:23,  2.10it/s] 94%|█████████▍| 2825/3000 [25:15<01:23,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:50:11,863 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:50:11,864 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:50:11,864 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:50:11,864 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 112.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.43it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.23it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.79it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.66it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.55it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.46it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.39it/s][A12/07/2022 13:50:13 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 94%|█████████▍| 2825/3000 [25:17<01:23,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.39it/s][A
                                               [A{'eval_loss': 0.8604099750518799, 'eval_accuracy': 0.83, 'eval_runtime': 1.535, 'eval_samples_per_second': 65.146, 'eval_steps_per_second': 8.469, 'epoch': 113.0}
12/07/2022 13:50:13 - INFO - training.trainer_base - ***** Epoch 112: Best results *****
12/07/2022 13:50:13 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:50:13 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:50:13 - INFO - training.trainer_base - epoch = 112.0
                                                    94%|█████████▍| 2825/3000 [25:17<01:23,  2.10it/s] 94%|█████████▍| 2826/3000 [25:17<02:43,  1.07it/s] 94%|█████████▍| 2827/3000 [25:18<02:18,  1.25it/s] 94%|█████████▍| 2828/3000 [25:18<02:00,  1.42it/s] 94%|█████████▍| 2829/3000 [25:19<01:48,  1.58it/s] 94%|█████████▍| 2830/3000 [25:19<01:39,  1.70it/s] 94%|█████████▍| 2831/3000 [25:20<01:33,  1.81it/s] 94%|█████████▍| 2832/3000 [25:20<01:28,  1.89it/s] 94%|█████████▍| 2833/3000 [25:21<01:25,  1.95it/s] 94%|█████████▍| 2834/3000 [25:21<01:23,  1.99it/s] 94%|█████████▍| 2835/3000 [25:22<01:21,  2.02it/s] 95%|█████████▍| 2836/3000 [25:22<01:19,  2.05it/s] 95%|█████████▍| 2837/3000 [25:23<01:18,  2.07it/s] 95%|█████████▍| 2838/3000 [25:23<01:17,  2.08it/s] 95%|█████████▍| 2839/3000 [25:24<01:17,  2.08it/s] 95%|█████████▍| 2840/3000 [25:24<01:16,  2.09it/s] 95%|█████████▍| 2841/3000 [25:25<01:15,  2.10it/s] 95%|█████████▍| 2842/3000 [25:25<01:15,  2.11it/s] 95%|█████████▍| 2843/3000 [25:25<01:14,  2.11it/s] 95%|█████████▍| 2844/3000 [25:26<01:14,  2.10it/s] 95%|█████████▍| 2845/3000 [25:26<01:13,  2.10it/s] 95%|█████████▍| 2846/3000 [25:27<01:13,  2.11it/s] 95%|█████████▍| 2847/3000 [25:27<01:12,  2.11it/s] 95%|█████████▍| 2848/3000 [25:28<01:12,  2.10it/s] 95%|█████████▍| 2849/3000 [25:28<01:11,  2.10it/s] 95%|█████████▌| 2850/3000 [25:29<01:11,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:50:25,274 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:50:25,275 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:50:25,275 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:50:25,275 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 113.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.46it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.83it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.43it/s][A12/07/2022 13:50:26 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 95%|█████████▌| 2850/3000 [25:30<01:11,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.43it/s][A
                                               [A{'eval_loss': 0.8605570793151855, 'eval_accuracy': 0.83, 'eval_runtime': 1.5324, 'eval_samples_per_second': 65.258, 'eval_steps_per_second': 8.484, 'epoch': 114.0}
12/07/2022 13:50:26 - INFO - training.trainer_base - ***** Epoch 113: Best results *****
12/07/2022 13:50:26 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:50:26 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:50:26 - INFO - training.trainer_base - epoch = 113.0
                                                    95%|█████████▌| 2850/3000 [25:30<01:11,  2.10it/s] 95%|█████████▌| 2851/3000 [25:31<02:20,  1.06it/s] 95%|█████████▌| 2852/3000 [25:31<01:58,  1.25it/s] 95%|█████████▌| 2853/3000 [25:32<01:43,  1.42it/s] 95%|█████████▌| 2854/3000 [25:32<01:32,  1.57it/s] 95%|█████████▌| 2855/3000 [25:33<01:25,  1.70it/s] 95%|█████████▌| 2856/3000 [25:33<01:19,  1.81it/s] 95%|█████████▌| 2857/3000 [25:34<01:15,  1.89it/s] 95%|█████████▌| 2858/3000 [25:34<01:12,  1.95it/s] 95%|█████████▌| 2859/3000 [25:35<01:10,  1.99it/s] 95%|█████████▌| 2860/3000 [25:35<01:09,  2.02it/s] 95%|█████████▌| 2861/3000 [25:36<01:08,  2.04it/s] 95%|█████████▌| 2862/3000 [25:36<01:06,  2.06it/s] 95%|█████████▌| 2863/3000 [25:37<01:05,  2.08it/s] 95%|█████████▌| 2864/3000 [25:37<01:05,  2.08it/s] 96%|█████████▌| 2865/3000 [25:37<01:04,  2.09it/s] 96%|█████████▌| 2866/3000 [25:38<01:03,  2.09it/s] 96%|█████████▌| 2867/3000 [25:38<01:03,  2.10it/s] 96%|█████████▌| 2868/3000 [25:39<01:02,  2.10it/s] 96%|█████████▌| 2869/3000 [25:39<01:02,  2.10it/s] 96%|█████████▌| 2870/3000 [25:40<01:01,  2.10it/s] 96%|█████████▌| 2871/3000 [25:40<01:01,  2.10it/s] 96%|█████████▌| 2872/3000 [25:41<01:00,  2.11it/s] 96%|█████████▌| 2873/3000 [25:41<01:00,  2.11it/s] 96%|█████████▌| 2874/3000 [25:42<00:59,  2.11it/s] 96%|█████████▌| 2875/3000 [25:42<00:59,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:50:38,699 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:50:38,700 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:50:38,700 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:50:38,700 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 114.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.51it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.38it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.56it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.48it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:50:40 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 96%|█████████▌| 2875/3000 [25:44<00:59,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.8605561256408691, 'eval_accuracy': 0.83, 'eval_runtime': 1.5307, 'eval_samples_per_second': 65.329, 'eval_steps_per_second': 8.493, 'epoch': 115.0}
12/07/2022 13:50:40 - INFO - training.trainer_base - ***** Epoch 114: Best results *****
12/07/2022 13:50:40 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:50:40 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:50:40 - INFO - training.trainer_base - epoch = 114.0
                                                    96%|█████████▌| 2875/3000 [25:44<00:59,  2.11it/s] 96%|█████████▌| 2876/3000 [25:44<01:56,  1.07it/s] 96%|█████████▌| 2877/3000 [25:45<01:38,  1.25it/s] 96%|█████████▌| 2878/3000 [25:45<01:25,  1.43it/s] 96%|█████████▌| 2879/3000 [25:46<01:16,  1.58it/s] 96%|█████████▌| 2880/3000 [25:46<01:10,  1.71it/s] 96%|█████████▌| 2881/3000 [25:47<01:05,  1.81it/s] 96%|█████████▌| 2882/3000 [25:47<01:02,  1.89it/s] 96%|█████████▌| 2883/3000 [25:48<01:00,  1.95it/s] 96%|█████████▌| 2884/3000 [25:48<00:58,  1.99it/s] 96%|█████████▌| 2885/3000 [25:49<00:56,  2.03it/s] 96%|█████████▌| 2886/3000 [25:49<00:55,  2.05it/s] 96%|█████████▌| 2887/3000 [25:49<00:54,  2.06it/s] 96%|█████████▋| 2888/3000 [25:50<00:54,  2.07it/s] 96%|█████████▋| 2889/3000 [25:50<00:53,  2.08it/s] 96%|█████████▋| 2890/3000 [25:51<00:52,  2.09it/s] 96%|█████████▋| 2891/3000 [25:51<00:51,  2.10it/s] 96%|█████████▋| 2892/3000 [25:52<00:51,  2.10it/s] 96%|█████████▋| 2893/3000 [25:52<00:50,  2.10it/s] 96%|█████████▋| 2894/3000 [25:53<00:50,  2.10it/s] 96%|█████████▋| 2895/3000 [25:53<00:49,  2.11it/s] 97%|█████████▋| 2896/3000 [25:54<00:49,  2.11it/s] 97%|█████████▋| 2897/3000 [25:54<00:48,  2.11it/s] 97%|█████████▋| 2898/3000 [25:55<00:48,  2.11it/s] 97%|█████████▋| 2899/3000 [25:55<00:47,  2.11it/s] 97%|█████████▋| 2900/3000 [25:56<00:47,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:50:52,108 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:50:52,110 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:50:52,110 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:50:52,110 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 115.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.57it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.33it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.25it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.82it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.45it/s][A12/07/2022 13:50:53 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 97%|█████████▋| 2900/3000 [25:57<00:47,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.45it/s][A
                                               [A{'eval_loss': 0.8565900325775146, 'eval_accuracy': 0.83, 'eval_runtime': 1.5285, 'eval_samples_per_second': 65.424, 'eval_steps_per_second': 8.505, 'epoch': 116.0}
12/07/2022 13:50:53 - INFO - training.trainer_base - ***** Epoch 115: Best results *****
12/07/2022 13:50:53 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:50:53 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:50:53 - INFO - training.trainer_base - epoch = 115.0
                                                    97%|█████████▋| 2900/3000 [25:57<00:47,  2.11it/s] 97%|█████████▋| 2901/3000 [25:58<01:32,  1.07it/s] 97%|█████████▋| 2902/3000 [25:58<01:17,  1.26it/s] 97%|█████████▋| 2903/3000 [25:59<01:07,  1.43it/s] 97%|█████████▋| 2904/3000 [25:59<01:00,  1.58it/s] 97%|█████████▋| 2905/3000 [26:00<00:55,  1.71it/s] 97%|█████████▋| 2906/3000 [26:00<00:51,  1.81it/s] 97%|█████████▋| 2907/3000 [26:00<00:49,  1.89it/s] 97%|█████████▋| 2908/3000 [26:01<00:47,  1.95it/s] 97%|█████████▋| 2909/3000 [26:01<00:45,  1.99it/s] 97%|█████████▋| 2910/3000 [26:02<00:44,  2.02it/s] 97%|█████████▋| 2911/3000 [26:02<00:43,  2.05it/s] 97%|█████████▋| 2912/3000 [26:03<00:42,  2.07it/s] 97%|█████████▋| 2913/3000 [26:03<00:41,  2.08it/s] 97%|█████████▋| 2914/3000 [26:04<00:41,  2.08it/s] 97%|█████████▋| 2915/3000 [26:04<00:40,  2.09it/s] 97%|█████████▋| 2916/3000 [26:05<00:40,  2.09it/s] 97%|█████████▋| 2917/3000 [26:05<00:39,  2.09it/s] 97%|█████████▋| 2918/3000 [26:06<00:39,  2.09it/s] 97%|█████████▋| 2919/3000 [26:06<00:38,  2.10it/s] 97%|█████████▋| 2920/3000 [26:07<00:38,  2.09it/s] 97%|█████████▋| 2921/3000 [26:07<00:37,  2.10it/s] 97%|█████████▋| 2922/3000 [26:08<00:37,  2.09it/s] 97%|█████████▋| 2923/3000 [26:08<00:36,  2.10it/s] 97%|█████████▋| 2924/3000 [26:09<00:36,  2.10it/s] 98%|█████████▊| 2925/3000 [26:09<00:35,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:51:05,530 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:51:05,532 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:51:05,532 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:51:05,532 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 116.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.37it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.28it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.59it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.45it/s][A12/07/2022 13:51:07 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 98%|█████████▊| 2925/3000 [26:11<00:35,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.45it/s][A
                                               [A{'eval_loss': 0.8519296050071716, 'eval_accuracy': 0.84, 'eval_runtime': 1.5269, 'eval_samples_per_second': 65.493, 'eval_steps_per_second': 8.514, 'epoch': 117.0}
12/07/2022 13:51:07 - INFO - training.trainer_base - ***** Epoch 116: Best results *****
12/07/2022 13:51:07 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:51:07 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:51:07 - INFO - training.trainer_base - epoch = 116.0
                                                    98%|█████████▊| 2925/3000 [26:11<00:35,  2.11it/s] 98%|█████████▊| 2926/3000 [26:11<01:09,  1.07it/s] 98%|█████████▊| 2927/3000 [26:12<00:58,  1.25it/s] 98%|█████████▊| 2928/3000 [26:12<00:50,  1.42it/s] 98%|█████████▊| 2929/3000 [26:13<00:45,  1.57it/s] 98%|█████████▊| 2930/3000 [26:13<00:41,  1.70it/s] 98%|█████████▊| 2931/3000 [26:13<00:38,  1.81it/s] 98%|█████████▊| 2932/3000 [26:14<00:36,  1.88it/s] 98%|█████████▊| 2933/3000 [26:14<00:34,  1.94it/s] 98%|█████████▊| 2934/3000 [26:15<00:33,  1.99it/s] 98%|█████████▊| 2935/3000 [26:15<00:32,  2.03it/s] 98%|█████████▊| 2936/3000 [26:16<00:31,  2.05it/s] 98%|█████████▊| 2937/3000 [26:16<00:30,  2.07it/s] 98%|█████████▊| 2938/3000 [26:17<00:29,  2.08it/s] 98%|█████████▊| 2939/3000 [26:17<00:29,  2.08it/s] 98%|█████████▊| 2940/3000 [26:18<00:28,  2.09it/s] 98%|█████████▊| 2941/3000 [26:18<00:28,  2.09it/s] 98%|█████████▊| 2942/3000 [26:19<00:27,  2.10it/s] 98%|█████████▊| 2943/3000 [26:19<00:27,  2.09it/s] 98%|█████████▊| 2944/3000 [26:20<00:26,  2.09it/s] 98%|█████████▊| 2945/3000 [26:20<00:26,  2.10it/s] 98%|█████████▊| 2946/3000 [26:21<00:25,  2.11it/s] 98%|█████████▊| 2947/3000 [26:21<00:25,  2.11it/s] 98%|█████████▊| 2948/3000 [26:22<00:24,  2.11it/s] 98%|█████████▊| 2949/3000 [26:22<00:24,  2.11it/s] 98%|█████████▊| 2950/3000 [26:22<00:23,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:51:18,959 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:51:18,960 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:51:18,960 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:51:18,960 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 117.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.49it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.41it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.30it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.86it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.72it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.60it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.51it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s][A12/07/2022 13:51:20 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 98%|█████████▊| 2950/3000 [26:24<00:23,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.44it/s][A
                                               [A{'eval_loss': 0.8488287329673767, 'eval_accuracy': 0.84, 'eval_runtime': 1.5249, 'eval_samples_per_second': 65.58, 'eval_steps_per_second': 8.525, 'epoch': 118.0}
12/07/2022 13:51:20 - INFO - training.trainer_base - ***** Epoch 117: Best results *****
12/07/2022 13:51:20 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:51:20 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:51:20 - INFO - training.trainer_base - epoch = 117.0
                                                    98%|█████████▊| 2950/3000 [26:24<00:23,  2.11it/s] 98%|█████████▊| 2951/3000 [26:24<00:45,  1.07it/s] 98%|█████████▊| 2952/3000 [26:25<00:38,  1.26it/s] 98%|█████████▊| 2953/3000 [26:25<00:32,  1.43it/s] 98%|█████████▊| 2954/3000 [26:26<00:29,  1.58it/s] 98%|█████████▊| 2955/3000 [26:26<00:26,  1.70it/s] 99%|█████████▊| 2956/3000 [26:27<00:24,  1.80it/s] 99%|█████████▊| 2957/3000 [26:27<00:22,  1.89it/s] 99%|█████████▊| 2958/3000 [26:28<00:21,  1.95it/s] 99%|█████████▊| 2959/3000 [26:28<00:20,  1.99it/s] 99%|█████████▊| 2960/3000 [26:29<00:19,  2.02it/s] 99%|█████████▊| 2961/3000 [26:29<00:19,  2.04it/s] 99%|█████████▊| 2962/3000 [26:30<00:18,  2.06it/s] 99%|█████████▉| 2963/3000 [26:30<00:17,  2.07it/s] 99%|█████████▉| 2964/3000 [26:31<00:17,  2.08it/s] 99%|█████████▉| 2965/3000 [26:31<00:16,  2.08it/s] 99%|█████████▉| 2966/3000 [26:32<00:16,  2.09it/s] 99%|█████████▉| 2967/3000 [26:32<00:15,  2.09it/s] 99%|█████████▉| 2968/3000 [26:33<00:15,  2.09it/s] 99%|█████████▉| 2969/3000 [26:33<00:14,  2.09it/s] 99%|█████████▉| 2970/3000 [26:34<00:14,  2.09it/s] 99%|█████████▉| 2971/3000 [26:34<00:13,  2.10it/s] 99%|█████████▉| 2972/3000 [26:34<00:13,  2.10it/s] 99%|█████████▉| 2973/3000 [26:35<00:12,  2.10it/s] 99%|█████████▉| 2974/3000 [26:35<00:12,  2.10it/s] 99%|█████████▉| 2975/3000 [26:36<00:11,  2.10it/s][INFO|trainer.py:540] 2022-12-07 13:51:32,391 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:51:32,392 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:51:32,392 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:51:32,392 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 118.0)])

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.28it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.33it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.27it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.81it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.69it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.57it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.41it/s][A12/07/2022 13:51:33 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A 99%|█████████▉| 2975/3000 [26:37<00:11,  2.10it/s]
100%|██████████| 13/13 [00:01<00:00,  8.41it/s][A
                                               [A{'eval_loss': 0.8476012349128723, 'eval_accuracy': 0.84, 'eval_runtime': 1.5334, 'eval_samples_per_second': 65.213, 'eval_steps_per_second': 8.478, 'epoch': 119.0}
12/07/2022 13:51:33 - INFO - training.trainer_base - ***** Epoch 118: Best results *****
12/07/2022 13:51:33 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:51:33 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:51:33 - INFO - training.trainer_base - epoch = 118.0
                                                    99%|█████████▉| 2975/3000 [26:37<00:11,  2.10it/s] 99%|█████████▉| 2976/3000 [26:38<00:22,  1.06it/s] 99%|█████████▉| 2977/3000 [26:38<00:18,  1.25it/s] 99%|█████████▉| 2978/3000 [26:39<00:15,  1.42it/s] 99%|█████████▉| 2979/3000 [26:39<00:13,  1.57it/s] 99%|█████████▉| 2980/3000 [26:40<00:11,  1.70it/s] 99%|█████████▉| 2981/3000 [26:40<00:10,  1.80it/s] 99%|█████████▉| 2982/3000 [26:41<00:09,  1.89it/s] 99%|█████████▉| 2983/3000 [26:41<00:08,  1.95it/s] 99%|█████████▉| 2984/3000 [26:42<00:08,  2.00it/s]100%|█████████▉| 2985/3000 [26:42<00:07,  2.03it/s]100%|█████████▉| 2986/3000 [26:43<00:06,  2.05it/s]100%|█████████▉| 2987/3000 [26:43<00:06,  2.06it/s]100%|█████████▉| 2988/3000 [26:44<00:05,  2.08it/s]100%|█████████▉| 2989/3000 [26:44<00:05,  2.09it/s]100%|█████████▉| 2990/3000 [26:45<00:04,  2.09it/s]100%|█████████▉| 2991/3000 [26:45<00:04,  2.09it/s]100%|█████████▉| 2992/3000 [26:46<00:03,  2.10it/s]100%|█████████▉| 2993/3000 [26:46<00:03,  2.10it/s]100%|█████████▉| 2994/3000 [26:46<00:02,  2.11it/s]100%|█████████▉| 2995/3000 [26:47<00:02,  2.11it/s]100%|█████████▉| 2996/3000 [26:47<00:01,  2.10it/s]100%|█████████▉| 2997/3000 [26:48<00:01,  2.10it/s]100%|█████████▉| 2998/3000 [26:48<00:00,  2.11it/s]100%|█████████▉| 2999/3000 [26:49<00:00,  2.11it/s]100%|██████████| 3000/3000 [26:49<00:00,  2.11it/s]                                                   100%|██████████| 3000/3000 [26:49<00:00,  2.11it/s][INFO|trainer.py:540] 2022-12-07 13:51:45,810 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:51:45,812 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:51:45,812 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:51:45,812 >>   Batch size = 8
OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 119.0)])
{'loss': 0.0141, 'learning_rate': 0.0, 'epoch': 120.0}

  0%|          | 0/13 [00:00<?, ?it/s][A
 15%|█▌        | 2/13 [00:00<00:00, 16.42it/s][A
 31%|███       | 4/13 [00:00<00:00, 10.41it/s][A
 46%|████▌     | 6/13 [00:00<00:00,  9.29it/s][A
 62%|██████▏   | 8/13 [00:00<00:00,  8.85it/s][A
 69%|██████▉   | 9/13 [00:00<00:00,  8.70it/s][A
 77%|███████▋  | 10/13 [00:01<00:00,  8.58it/s][A
 85%|████████▍ | 11/13 [00:01<00:00,  8.49it/s][A
 92%|█████████▏| 12/13 [00:01<00:00,  8.42it/s][A12/07/2022 13:51:47 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
                                                   
                                               [A100%|██████████| 3000/3000 [26:51<00:00,  2.11it/s]
100%|██████████| 13/13 [00:01<00:00,  8.42it/s][A
                                               [A{'eval_loss': 0.8471391797065735, 'eval_accuracy': 0.84, 'eval_runtime': 1.5277, 'eval_samples_per_second': 65.459, 'eval_steps_per_second': 8.51, 'epoch': 120.0}
12/07/2022 13:51:47 - INFO - training.trainer_base - ***** Epoch 119: Best results *****
12/07/2022 13:51:47 - INFO - training.trainer_base - best_epoch = 27
12/07/2022 13:51:47 - INFO - training.trainer_base - best_eval_accuracy = 0.88
12/07/2022 13:51:47 - INFO - training.trainer_base - epoch = 119.0
                                                   100%|██████████| 3000/3000 [26:51<00:00,  2.11it/s][INFO|trainer.py:1409] 2022-12-07 13:51:47,340 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   100%|██████████| 3000/3000 [26:51<00:00,  2.11it/s]100%|██████████| 3000/3000 [26:51<00:00,  1.86it/s]OrderedDict([('best_epoch', 27), ('best_eval_accuracy', 0.88), ('epoch', 120.0)])
{'train_runtime': 1611.3711, 'train_samples_per_second': 29.788, 'train_steps_per_second': 1.862, 'train_loss': 0.16602195851008097, 'epoch': 120.0}
***** train metrics *****
  epoch                    =      120.0
  train_loss               =      0.166
  train_runtime            = 0:26:51.37
  train_samples_per_second =     29.788
  train_steps_per_second   =      1.862
***** best metrics *****
  best_epoch         =    27
  best_eval_accuracy =  0.88
  epoch              = 120.0
12/07/2022 13:51:47 - INFO - __main__ - *** Evaluate ***

[INFO|trainer.py:540] 2022-12-07 13:51:47,365 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaPrefixForMultipleChoice.forward` and have been ignored: choice2, text_a, question, idx, premise, choice1.
[INFO|trainer.py:2243] 2022-12-07 13:51:47,366 >> ***** Running Evaluation *****
[INFO|trainer.py:2245] 2022-12-07 13:51:47,366 >>   Num examples = 100
[INFO|trainer.py:2248] 2022-12-07 13:51:47,366 >>   Batch size = 8
  0%|          | 0/13 [00:00<?, ?it/s] 15%|█▌        | 2/13 [00:00<00:00, 16.51it/s] 31%|███       | 4/13 [00:00<00:00, 10.36it/s] 46%|████▌     | 6/13 [00:00<00:00,  9.26it/s] 62%|██████▏   | 8/13 [00:00<00:00,  8.84it/s] 69%|██████▉   | 9/13 [00:00<00:00,  8.71it/s] 77%|███████▋  | 10/13 [00:01<00:00,  8.61it/s] 85%|████████▍ | 11/13 [00:01<00:00,  8.53it/s] 92%|█████████▏| 12/13 [00:01<00:00,  8.44it/s]12/07/2022 13:51:48 - INFO - datasets.metric - Removing /users/PAS2318/evanhuang117/.cache/huggingface/metrics/super_glue/copa/default_experiment-1-0.arrow
100%|██████████| 13/13 [00:01<00:00,  9.22it/s]
***** eval metrics *****
  epoch                   =      120.0
  eval_accuracy           =       0.84
  eval_loss               =     0.8471
  eval_runtime            = 0:00:01.53
  eval_samples_per_second =     65.307
  eval_steps_per_second   =       8.49
JobId=14007132 JobName=job.sh
   UserId=evanhuang117(40404) GroupId=PAS2318(7675) MCS_label=N/A
   Priority=200070721 Nice=0 Account=pas2318 QOS=pitzer-default
   JobState=RUNNING Reason=None Dependency=(null)
   Requeue=1 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:27:26 TimeLimit=05:00:00 TimeMin=N/A
   SubmitTime=2022-12-07T13:09:17 EligibleTime=2022-12-07T13:09:17
   AccrueTime=2022-12-07T13:09:17
   StartTime=2022-12-07T13:24:24 EndTime=2022-12-07T18:24:24 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2022-12-07T13:24:24 Scheduler=Backfill
   Partition=gpuserial-48core AllocNode:Sid=pitzer-login01:161063
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=p0304
   BatchHost=p0304
   NumNodes=1 NumCPUs=4 NumTasks=1 CPUs/Task=4 ReqB:S:C:T=0:0:*:*
   TRES=cpu=4,mem=30976M,node=1,billing=4,gres/gpu=2,gres/gpu:v100-32g=2
   Socks/Node=* NtasksPerN:B:S:C=0:0:*:1 CoreSpec=*
   MinCPUsNode=4 MinMemoryCPU=7744M MinTmpDiskNode=0
   Features=(null) DelayBoot=00:00:00
   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)
   Command=/users/PAS2318/evanhuang117/cse5525-research-project/job.sh
   WorkDir=/users/PAS2318/evanhuang117/cse5525-research-project
   Comment=stdout=/users/PAS2318/evanhuang117/cse5525-research-project/slurm-14007132.out 
   StdErr=/users/PAS2318/evanhuang117/cse5525-research-project/slurm-14007132.out
   StdIn=/dev/null
   StdOut=/users/PAS2318/evanhuang117/cse5525-research-project/slurm-14007132.out
   Power=
   TresPerNode=gres:gpu:2
   MailUser=evanhuang117 MailType=INVALID_DEPEND,BEGIN,END,FAIL,REQUEUE,STAGE_OUT
   

